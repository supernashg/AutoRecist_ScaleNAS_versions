{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘/mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_9Slices/tools/cache/inference_gt_roidb.pkl’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -v /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_9Slices/tools/cache/inference_gt_roidb.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating output/Lesion/superscalenet_seg/Lesion_Q5_9Slices_scalenet_seg_test/data_patch_valtest\n",
      "=> creating log/Lesion/superscalenet_seg/data_patch_valtest/Lesion_Q5_9Slices_scalenet_seg_test_2022-01-10-15-38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> init weights from normal distribution\n",
      "=> loading model from ../output/Lesion/superscalenet_seg/Lesion_Q5_9Slices_superscalenet/data_patch_train/best.pth\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/ipykernel/__main__.py:227: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "Missing keys in pretrained_dict: set()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.criterion.weight\n",
      "Current time cost is 10.898160934448242 sec\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Licensed under the MIT License.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import _init_paths\n",
    "import models\n",
    "import dataset\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.seg_function import validate_seg_wo_loss as validate\n",
    "from core.oneshot_function import calib_bn_seg as calib_bn\n",
    "from utils.utils import get_model_summary\n",
    "from utils.utils import create_logger, FullModel\n",
    "\n",
    "from dataset.roidb import combined_roidb_for_training\n",
    "from roi_data.loader import RoiDataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, name = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.makedirs(sv_path)\n",
    "                save_pred(pred, sv_path, name)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d batches' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc\n",
    "\n",
    "\n",
    "def parse_args(l):\n",
    "    parser = argparse.ArgumentParser(description='Test segmentation network')\n",
    "\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        required=True,\n",
    "                        type=str)\n",
    "    parser.add_argument('opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "    parser.add_argument('--bn_calib',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--mask_path',\n",
    "                        help='the path of a mask.npy',\n",
    "                        default=None,\n",
    "                        type=str)\n",
    "    args = parser.parse_args(l)\n",
    "    update_config(cfg, args)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# arglist = ['--cfg', '../experiments/cityscapes/scalenet_seg_w32_test.yaml' ,  \n",
    "#            '--bn_calib',\n",
    "#            '--mask_path', '../experiments/searched_masks/cityscapes/seg_w32_S1.npy' ,  \n",
    "#            'TEST.MODEL_FILE', '../models/pytorch/seg_cityscapes/superscalenet_seg_w32.pth',\n",
    "#            'DATASET.ROOT','../data/']\n",
    "\n",
    "\n",
    "experiment_name = 'Lesion_Q5_9Slices_scalenet_seg_test'\n",
    "mask_name = 'mask_1988'\n",
    "arglist = ['--cfg', '../experiments/lesion_Q5/%s.yaml'%experiment_name ,  \n",
    "           '--mask_path', '../evo_files/masks/%s.npy'%mask_name,  \n",
    "           'TEST.MODEL_FILE', '../output/Lesion/superscalenet_seg/Lesion_Q5_9Slices_superscalenet/data_patch_train/best.pth',\n",
    "           'DATASET.ROOT','',\n",
    "           'TRAIN.USE_FLIPPED',False]\n",
    "\n",
    "args = parse_args(arglist)\n",
    "\n",
    "logger, final_output_dir, tb_log_dir = create_logger(\n",
    "    cfg, args.cfg, 'valtest')\n",
    "\n",
    "writer_dict = {\n",
    "    'writer': SummaryWriter(tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "cudnn.enabled = cfg.CUDNN.ENABLED\n",
    "\n",
    "# build model\n",
    "model = eval('models.' + cfg.MODEL.NAME +\n",
    "             '.get_seg_model')(cfg)\n",
    "\n",
    "input_shape = (1, 3, cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "dump_input = torch.rand(\n",
    "    input_shape\n",
    ")\n",
    "\n",
    "if cfg.TEST.MODEL_FILE:\n",
    "    model_state_file = cfg.TEST.MODEL_FILE\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    model_state_file = os.path.join(final_output_dir,\n",
    "                                    'final_state.pth')\n",
    "logger.info('=> loading model from {}'.format(model_state_file))\n",
    "\n",
    "pretrained_dict = torch.load(model_state_file)\n",
    "\n",
    "D2= {}\n",
    "for key in pretrained_dict.keys():\n",
    "    if key[:6] == 'model.':\n",
    "        new_key = key[6:]\n",
    "        D2[new_key] = pretrained_dict[key]\n",
    "    else:\n",
    "        print(key)\n",
    "        D2[key] = pretrained_dict[key]\n",
    "\n",
    "pretrained_dict = D2      \n",
    "model_dict = model.state_dict()\n",
    "\n",
    "model_keys = set(model_dict.keys())\n",
    "pretrained_keys = set(pretrained_dict.keys())\n",
    "missing_keys = model_keys - pretrained_keys\n",
    "logger.warn('Missing keys in pretrained_dict: {}'.format(missing_keys))\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "\n",
    "# do stuff\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache ground truth roidb to /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_9Slices/tools/cache/inference_gt_roidb.pkl\n",
      "Loaded dataset: inference\n",
      "Computing image aspect ratios and ordering the ratios...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 288\n",
      "2 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done\n",
      "Computing bounding-box regression targets...\n",
      "done\n",
      "GPU list is [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 288\n",
      "class_weights are:\n",
      "tensor([0.4000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> setting mask from ../evo_files/masks/mask_1988.npy\n",
      "[{'d': array([[4],\n",
      "       [3]]), 'f': array([[list([1, 1]), list([1, 1]), list([1, 1]), list([1, 1]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1]), list([1, 1]), list([1, 1]), list([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[5],\n",
      "       [4],\n",
      "       [5]]), 'f': array([[list([1, 1, 1]), list([1, 0, 1]), list([1, 0, 1]),\n",
      "        list([1, 1, 1]), list([1, 1, 1])],\n",
      "       [list([0, 1, 1]), list([0, 1, 0]), list([0, 1, 0]),\n",
      "        list([0, 1, 1]), list([0, 0, 0])],\n",
      "       [list([0, 0, 1]), list([0, 0, 1]), list([1, 1, 1]),\n",
      "        list([1, 0, 1]), list([1, 1, 1])]], dtype=object)}\n",
      " {'d': array([[5],\n",
      "       [4],\n",
      "       [4]]), 'f': array([[list([1, 0, 0]), list([1, 0, 1]), list([1, 0, 1]),\n",
      "        list([1, 0, 0]), list([1, 1, 1])],\n",
      "       [list([0, 1, 0]), list([1, 1, 1]), list([0, 1, 1]),\n",
      "        list([1, 1, 1]), list([0, 0, 0])],\n",
      "       [list([1, 1, 1]), list([0, 1, 1]), list([0, 1, 1]),\n",
      "        list([0, 1, 1]), list([0, 0, 0])]], dtype=object)}\n",
      " {'d': array([[4],\n",
      "       [5],\n",
      "       [4]]), 'f': array([[list([1, 0, 0]), list([1, 1, 1]), list([1, 1, 0]),\n",
      "        list([1, 0, 1]), list([0, 0, 0])],\n",
      "       [list([0, 1, 0]), list([1, 1, 0]), list([0, 1, 0]),\n",
      "        list([0, 1, 1]), list([0, 1, 0])],\n",
      "       [list([0, 1, 1]), list([1, 1, 1]), list([1, 1, 1]),\n",
      "        list([0, 1, 1]), list([0, 0, 0])]], dtype=object)}\n",
      " {'d': array([[3],\n",
      "       [3],\n",
      "       [4]]), 'f': array([[list([1, 1, 0]), list([1, 1, 1]), list([1, 0, 1]),\n",
      "        list([0, 0, 0]), array([0, 0])],\n",
      "       [list([0, 1, 0]), list([1, 1, 1]), list([0, 1, 1]),\n",
      "        list([0, 0, 0]), array([0, 0])],\n",
      "       [list([1, 1, 1]), list([0, 0, 1]), list([0, 1, 1]),\n",
      "        list([0, 0, 1]), array([0, 0])]], dtype=object)}\n",
      " {'d': array([[5],\n",
      "       [4],\n",
      "       [5],\n",
      "       [5]]), 'f': array([[list([1, 0, 0, 1]), list([1, 0, 1, 0]), list([1, 1, 1, 1]),\n",
      "        list([1, 0, 0, 0]), list([1, 1, 0, 1])],\n",
      "       [list([1, 1, 0, 0]), list([0, 1, 1, 1]), list([1, 1, 0, 0]),\n",
      "        list([0, 1, 0, 0]), list([0, 0, 0, 0])],\n",
      "       [list([0, 0, 1, 1]), list([0, 0, 1, 1]), list([0, 1, 1, 0]),\n",
      "        list([1, 0, 1, 0]), list([1, 0, 1, 1])],\n",
      "       [list([1, 0, 1, 1]), list([1, 0, 0, 1]), list([0, 0, 1, 1]),\n",
      "        list([0, 1, 0, 1]), list([1, 0, 1, 1])]], dtype=object)}\n",
      " {'d': array([[3],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2]]), 'f': array([[list([1, 1, 1, 1]), list([1, 1, 1, 0]), list([1, 0, 1, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 1, 0, 0]), list([0, 1, 1, 0]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 0, 1, 0]), list([0, 0, 1, 1]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([0, 0, 0, 1]), list([1, 1, 1, 1]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])]], dtype=object)}\n",
      " {'d': array([[4],\n",
      "       [4],\n",
      "       [5],\n",
      "       [5]]), 'f': array([[list([1, 1, 1, 1]), list([1, 0, 0, 1]), list([1, 0, 0, 1]),\n",
      "        list([1, 1, 0, 1]), list([0, 0, 0, 0])],\n",
      "       [list([1, 1, 1, 1]), list([1, 1, 1, 1]), list([1, 1, 1, 0]),\n",
      "        list([1, 1, 0, 1]), list([0, 0, 0, 0])],\n",
      "       [list([1, 0, 1, 0]), list([1, 0, 1, 1]), list([0, 1, 1, 1]),\n",
      "        list([0, 0, 1, 1]), list([1, 0, 1, 0])],\n",
      "       [list([1, 1, 1, 1]), list([1, 1, 1, 1]), list([1, 0, 1, 1]),\n",
      "        list([1, 1, 1, 1]), list([1, 1, 1, 1])]], dtype=object)}]\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "processing: 0 batches\n",
      "mIoU: 0.0454\n",
      "MeanIU:  0.0450, Pixel_Acc:  0.9898,    Mean_Acc:  0.0450, Class IoU: \n",
      "[0.98979163 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time cost is 62.54081177711487 sec\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "test_size = (cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "\n",
    "# manully select from below.\n",
    "# ('PDS_AMGEN_20020408_22Cat_test',)\n",
    "# ('PDS_Q2_A&C_22Cat_train',)\n",
    "# ('PDS_CUIMC_22Cat_test',)\n",
    "\n",
    "test_roidb, test_ratio_list, test_ratio_index = combined_roidb_for_training(\n",
    "        ('inference',) , cfg.VAL.PROPOSAL_FILES)\n",
    "\n",
    "test_dataset = RoiDataLoader(\n",
    "    test_roidb,\n",
    "    cfg.MODEL.NUM_CLASSES,\n",
    "    training=True)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.TEST.BATCH_SIZE_PER_GPU,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "\n",
    "\n",
    "\n",
    "gpus = list(cfg.GPUS)\n",
    "logger.info('GPU list is {}'.format(gpus))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "if args.mask_path and os.path.exists(args.mask_path):\n",
    "    masks = np.load(args.mask_path, allow_pickle=True)\n",
    "    model.module.set_active_subnet(masks)\n",
    "    logger.info('=> setting mask from {}'.format(args.mask_path))\n",
    "    logger.info(masks)\n",
    "else:\n",
    "    masks=None\n",
    "    logger.info('No model mask')\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "mean_IoU, IoU_array, pixel_acc, mean_acc = testval_lesion(cfg, \n",
    "                                                  test_dataset, \n",
    "                                                  testloader, \n",
    "                                                  model.cuda(),\n",
    "                                                  sv_dir=mask_name, \n",
    "                                                  device=None)\n",
    "\n",
    "msg = 'MeanIU: {: 4.4f}, Pixel_Acc: {: 4.4f},    Mean_Acc: {: 4.4f}, Class IoU: '.format(mean_IoU, \n",
    "   pixel_acc, mean_acc)\n",
    "logging.info(msg)\n",
    "logging.info(IoU_array)\n",
    "\n",
    "# do stuff\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

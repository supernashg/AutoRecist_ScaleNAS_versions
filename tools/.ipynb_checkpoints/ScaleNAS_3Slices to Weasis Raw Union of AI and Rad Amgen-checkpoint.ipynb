{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PatientID                                    Image File Path  \\\n",
      "0     METNET0001  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0001\\D...   \n",
      "1     METNET0001  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0001\\D...   \n",
      "2     METNET0001  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0001\\D...   \n",
      "3     METNET0001  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0001\\D...   \n",
      "4     METNET0001  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0001\\D...   \n",
      "...          ...                                                ...   \n",
      "1158  METNET0298  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0298\\D...   \n",
      "1159  METNET0298  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0298\\D...   \n",
      "1160  METNET0299  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0299\\D...   \n",
      "1161  METNET0299  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0299\\D...   \n",
      "1162  METNET0299  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0299\\D...   \n",
      "\n",
      "                                      Contour File Path     Location      Uni  \\\n",
      "0     X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...        liver  23.1054   \n",
      "1     X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...       kidney  50.1518   \n",
      "2     X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...       kidney  16.9172   \n",
      "3     X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...       kidney  49.2908   \n",
      "4     X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...       kidney  14.8374   \n",
      "...                                                 ...          ...      ...   \n",
      "1158  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...  soft tissue  26.2772   \n",
      "1159  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...  soft tissue  16.3200   \n",
      "1160  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...       kidney  12.9653   \n",
      "1161  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...  axillary LN  16.9047   \n",
      "1162  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...  axillary LN  19.4912   \n",
      "\n",
      "         Perp          Bi     Volume  \n",
      "0     15.4036   355.90634   3473.460  \n",
      "1     40.6414  2038.23930  41519.400  \n",
      "2     15.8343   267.87200   2828.300  \n",
      "3     43.1874  2128.74150  54385.900  \n",
      "4     14.0977   209.17322   1761.190  \n",
      "...       ...         ...        ...  \n",
      "1158  18.9797   498.73340   5296.880  \n",
      "1159  11.5975   189.27120   1278.440  \n",
      "1160   8.2000   106.31545    679.124  \n",
      "1161  14.5304   245.63205   1539.800  \n",
      "1162  11.1532   217.38925   2158.400  \n",
      "\n",
      "[1163 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "CT_EXCEL_FILE = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AMGEN_20020408_CIA-LAB_Image_And_Contour_2022-01-10.xlsx'\n",
    "# CT_EXCEL_FILE = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AUTO_RECIST CIA-LAB Image and Contour 2020-10-01.xlsx'\n",
    "SAVE_PATH = '/mnt/fast-disk1/refine_gt/'\n",
    "\n",
    "import pandas as pd\n",
    "df_all = pd.read_excel(CT_EXCEL_FILE)\n",
    "\n",
    "print(df_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PatientID                                    Image File Path  \\\n",
      "0     METNET0001  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0001\\D...   \n",
      "7     METNET0002  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0002\\D...   \n",
      "21    METNET0003  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0003\\D...   \n",
      "28    METNET0004  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0004\\D...   \n",
      "30    METNET0005  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0005\\D...   \n",
      "...          ...                                                ...   \n",
      "1154  METNET0296  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0296\\D...   \n",
      "1157  METNET0297  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0297\\D...   \n",
      "1158  METNET0298  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0298\\D...   \n",
      "1160  METNET0299  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0299\\D...   \n",
      "1161  METNET0299  X:\\ClinicalTrials\\PDS_AUTO_RECIST\\METNET0299\\D...   \n",
      "\n",
      "                                      Contour File Path     Location  \\\n",
      "0     X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...        liver   \n",
      "7     X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...        liver   \n",
      "21    X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...        liver   \n",
      "28    X:\\ConvWeasisToRaw\\PDS_AUTO_RECIST\\pg2343_METN...        liver   \n",
      "30    X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...         bone   \n",
      "...                                                 ...          ...   \n",
      "1154  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...       kidney   \n",
      "1157  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...       kidney   \n",
      "1158  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...  soft tissue   \n",
      "1160  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...       kidney   \n",
      "1161  X:\\ConvWeasisToMatlab\\PDS_AUTO_RECIST_RAW\\pg23...  axillary LN   \n",
      "\n",
      "           Uni      Perp           Bi      Volume  \n",
      "0      23.1054  15.40360    355.90634    3473.460  \n",
      "7      30.2391  24.39400    737.65260   14084.300  \n",
      "21     20.0674  10.58950    212.50374    1762.590  \n",
      "28    115.5010  97.57490  11269.99800  546696.000  \n",
      "30     21.0358   9.61802    202.32275    1659.390  \n",
      "...        ...       ...          ...         ...  \n",
      "1154   19.7272  14.30720    282.24100    2634.550  \n",
      "1157   19.7231   9.68890    191.09515     768.359  \n",
      "1158   26.2772  18.97970    498.73340    5296.880  \n",
      "1160   12.9653   8.20000    106.31545     679.124  \n",
      "1161   16.9047  14.53040    245.63205    1539.800  \n",
      "\n",
      "[282 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df_all # a liver lesions case\n",
    "\n",
    "df = df.drop_duplicates(subset=['Image File Path'], keep='first')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from math import ceil, floor\n",
    "import cv2\n",
    "import sys\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def window_image(img, window_center,window_width, intercept, slope):\n",
    "    \n",
    "#     window_center,window_width = 50 ,100\n",
    "    img = (img*slope +intercept)\n",
    "    img_min = window_center - window_width//2\n",
    "    img_max = window_center + window_width//2\n",
    "    img[img<img_min] = img_min\n",
    "    img[img>img_max] = img_max\n",
    "    return img \n",
    "\n",
    "\n",
    "def get_first_of_dicom_field_as_int(x):\n",
    "    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n",
    "    if type(x) == pydicom.multival.MultiValue:\n",
    "        return int(x[0])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def get_windowing(data):\n",
    "    dicom_fields = [data[('0028','1050')].value, #window center\n",
    "                    data[('0028','1051')].value, #window width\n",
    "                    data[('0028','1052')].value, #intercept\n",
    "                    data[('0028','1053')].value] #slope\n",
    "    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]\n",
    "\n",
    "def _normalize(img):\n",
    "    if img.max() == img.min():\n",
    "        return np.zeros(img.shape)-1\n",
    "    return 2 * (img - img.min())/(img.max() - img.min()) - 1\n",
    "\n",
    "def normalize_minmax(img):\n",
    "    mi, ma = img.min(), img.max()\n",
    "    if mi == ma:\n",
    "        return np.zeros(img.shape)-1\n",
    "    return 2*(img - mi) / (ma - mi) - 1\n",
    "\n",
    "def getName(s):\n",
    "    ix1 = s.rfind('/')\n",
    "    ix2 = s.rfind('.')\n",
    "    return s[ix1:ix2]\n",
    "\n",
    "\n",
    "def _read(path, desired_size = (512,512)):\n",
    "    \"\"\"Will be used in DataGenerator\"\"\"\n",
    "\n",
    "    try:\n",
    "        data = pydicom.read_file(path)\n",
    "        image = data.pixel_array\n",
    "        window_center , window_width, intercept, slope = get_windowing(data)\n",
    "        \n",
    "        image_windowed = window_image(image, window_center, window_width, intercept, slope)\n",
    "        img = normalize_minmax(image_windowed)\n",
    "\n",
    "    except:\n",
    "        img = np.zeros(desired_size[:2])-1\n",
    "    \n",
    "    if img.shape[:2] != desired_size[:2]:\n",
    "        print(\"image shape is not desired size. Interpolation is done.\")\n",
    "        img = cv2.resize(img, desired_size[:2], interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "\n",
    "D_dir2header_df = {}\n",
    "\n",
    "\n",
    "def get_dicom_header_df(image_dir , labels = []):\n",
    "    global D_dir2header_df\n",
    "    if image_dir in D_dir2header_df:\n",
    "        return D_dir2header_df[image_dir]\n",
    "\n",
    "    # image_dir = row['Image File Path']\n",
    "\n",
    "\n",
    "    labels = ['ImageName','InstanceNumber',\n",
    "            'BitsAllocated', 'BitsStored', 'Columns', 'HighBit', \n",
    "            'ImageOrientationPatient_0', 'ImageOrientationPatient_1', 'ImageOrientationPatient_2',\n",
    "            'ImageOrientationPatient_3', 'ImageOrientationPatient_4', 'ImageOrientationPatient_5',\n",
    "            'ImagePositionPatient_0', 'ImagePositionPatient_1', 'ImagePositionPatient_2',\n",
    "            'Modality', 'PatientID', 'PhotometricInterpretation', 'PixelRepresentation',\n",
    "            'PixelSpacing_0', 'PixelSpacing_1', 'RescaleIntercept', 'RescaleSlope', 'Rows', 'SOPInstanceUID',\n",
    "            'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID', 'StudyInstanceUID', \n",
    "            'WindowCenter', 'WindowWidth', \n",
    "        ] if not labels else labels\n",
    "\n",
    "    data = {l: [] for l in labels}\n",
    "    \n",
    "    ctList = os.listdir(image_dir)\n",
    "    ctList.sort()\n",
    "\n",
    "    for image in ctList:\n",
    "        if '.dcm' not in image:\n",
    "            continue\n",
    "        if os.path.getsize(os.path.join(image_dir, image)) < 5*1024:\n",
    "            print('%s size < 5kb skiped!'%os.path.join(image_dir, image) )\n",
    "            continue\n",
    "        data[\"ImageName\"].append(image)\n",
    "\n",
    "        ds = pydicom.dcmread(os.path.join(image_dir, image))\n",
    "        for metadata in ds.dir():\n",
    "            if metadata not in data and metadata not in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                continue\n",
    "            if metadata != \"PixelData\":\n",
    "                metadata_values = getattr(ds, metadata)\n",
    "                if type(metadata_values) == pydicom.multival.MultiValue and metadata not in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                    for i, v in enumerate(metadata_values):\n",
    "                        data[f\"{metadata}_{i}\"].append(v)  \n",
    "                else:\n",
    "                    if type(metadata_values) == pydicom.multival.MultiValue and metadata in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                        data[metadata].append(metadata_values[0])\n",
    "                    else:\n",
    "                        data[metadata].append(metadata_values)\n",
    "\n",
    "    df_image = pd.DataFrame(data).set_index(\"InstanceNumber\")\n",
    "    D_dir2header_df[image_dir] = df_image\n",
    "    return df_image\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "def InstanceNumber2file_name(df_image, num):\n",
    "    return df_image.loc[num,'ImageName']\n",
    "\n",
    "def InstanceNumber2data_element(df_image, num, label):\n",
    "    return df_image.loc[num , label]\n",
    "\n",
    "    \n",
    "def get_SliceThickness(df_image):\n",
    "    flag = False\n",
    "    L = df_image['ImagePositionPatient_2'].tolist()\n",
    "    thick = list( np.diff(L) )\n",
    "    res = float( max(set(thick), key=thick.count) )\n",
    "    res = -res if res < 0 else res\n",
    "    \n",
    "    L.sort()\n",
    "    thick2 = list( np.diff(L) )\n",
    "    res2 = float( max(set(thick2), key=thick2.count) )\n",
    "    if res2 ==0 and res==0:\n",
    "        result = 0\n",
    "        flag = True\n",
    "        print('Warning intv is 0')\n",
    "        print(df_image['ImagePositionPatient_2'])\n",
    "    if res2 == res:\n",
    "        result = res\n",
    "    else:\n",
    "        result = res\n",
    "        flag = True\n",
    "        print('Warning intv may wrong',res,res2)\n",
    "        print(df_image['ImagePositionPatient_2'])\n",
    "    \n",
    "    return result \n",
    "\n",
    "def InstanceNumber2windows_min_max(df_image,num):\n",
    "    try:     \n",
    "        WL = InstanceNumber2data_element(df_image, num, 'WindowCenter')\n",
    "        WW = InstanceNumber2data_element(df_image, num, 'WindowWidth')\n",
    "    except:\n",
    "        print(\"Warning! Window Center or Width is empty! Now use default values\")\n",
    "        WL , WW = 250 , 1500\n",
    "        \n",
    "    minHU = int( WL-WW/2 )\n",
    "    maxHU = minHU + int(WW)\n",
    "    return [minHU , maxHU]\n",
    "\n",
    "\n",
    "class ASerial:\n",
    "    P=-1\n",
    "    D=-1\n",
    "    S=-1\n",
    "    name = ''\n",
    "    def __init__(self, path_str):\n",
    "        self.path = path_str\n",
    "        self.getP()\n",
    "        self.getD()\n",
    "        self.getS()\n",
    "        self.convert_path()\n",
    "        \n",
    "    def getP(self, target = 'DeepLesion_', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.P = int(ss)\n",
    "        \n",
    "    def getD(self, target = '/D', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.D = int(ss)\n",
    "        \n",
    "    def getS(self, target = '/S', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.S = int(ss)\n",
    "        \n",
    "    def convert_path(self):\n",
    "        self.name = '%06d_%02d_%02d'%(self.P, self.D, self.S)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json, yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from collections import OrderedDict\n",
    "from pycocotools import mask as cocomask\n",
    "from pycocotools import coco as cocoapi\n",
    "\n",
    "\n",
    "\n",
    "def replacer(s, newstring, index, nofail=False):\n",
    "    # raise an error if index is outside of the string\n",
    "    if not nofail and index not in range(len(s)):\n",
    "        raise ValueError(\"index outside given string\")\n",
    "\n",
    "    # if not erroring, but the index is still not in the correct range..\n",
    "    if index < 0:  # add it to the beginning\n",
    "        return newstring + s\n",
    "    if index > len(s):  # add it to the end\n",
    "        return s + newstring\n",
    "\n",
    "    # insert the new string between \"slices\" of the original\n",
    "    return s[:index] + newstring + s[index + 1:]\n",
    "\n",
    "def convert_file_name(name,S='/'):\n",
    "    ix = name.rfind('_')\n",
    "    return replacer(name,S,ix)\n",
    "\n",
    "def file_name2id(name):\n",
    "    name.replace('.png','')\n",
    "    name.replace('_','')\n",
    "    return int('1' + name)\n",
    "    \n",
    "def get_image_size( s ):\n",
    "    num = list( map( int , s.split(',')))\n",
    "    return num[0] , num[1]\n",
    "\n",
    "def get_spacing( s ):\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[0] , num[1] , num[2]\n",
    "\n",
    "\n",
    "def get_z_position( df ):\n",
    "    s = df.loc['Normalized_lesion_location']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[2]\n",
    "    \n",
    "def get_slice_no( df ):\n",
    "    s = df.loc['Key_slice_index']\n",
    "    return int(s)\n",
    "\n",
    "def get_windows( df ):\n",
    "    s = df.loc[ 'DICOM_windows']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num\n",
    "\n",
    "\n",
    "def get_segmentation():\n",
    "    return []\n",
    "\n",
    "def get_bbox( df ):\n",
    "    s = df.loc['Bounding_boxes']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    num[2] = num[2]-num[0]\n",
    "    num[3] = num[3]-num[1]\n",
    "    return num \n",
    "\n",
    "def get_noise( df ):\n",
    "    s = df.loc['Possibly_noisy']\n",
    "    num = int(s)\n",
    "    return num\n",
    "\n",
    "def get_area( df ):\n",
    "    s = df.loc['Lesion_diameters_Pixel_']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[0]*num[1]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "newcats = [{'supercategory': 'DeepLesion', 'id': 1, 'name': 'abdomen'},\n",
    "           {'supercategory': 'DeepLN', 'id': 2, 'name': 'abdomen LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 3, 'name': 'adrenal'},\n",
    "           {'supercategory': 'DeepLN', 'id': 4, 'name': 'axillary LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 5, 'name': 'bone'},\n",
    "           {'supercategory': 'DeepLN', 'id': 6, 'name': 'inguinal LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 7, 'name': 'kidney'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 8, 'name': 'liver'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 9, 'name': 'lung'},\n",
    "           {'supercategory': 'DeepLN', 'id': 10, 'name': 'mediastinum LN'},\n",
    "           {'supercategory': 'DeepLN', 'id': 11, 'name': 'neck LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 12, 'name': 'ovary'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 13, 'name': 'pancreas'},\n",
    "           {'supercategory': 'DeepLN', 'id': 14, 'name': 'pelvic LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 15, 'name': 'pelvis'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 16, 'name': 'pleural'},\n",
    "           {'supercategory': 'DeepLN', 'id': 17, 'name': 'retroperitoneal LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 18, 'name': 'soft tissue'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 19, 'name': 'spleen'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 20, 'name': 'stomach'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 21, 'name': 'thyroid'} ]\n",
    "\n",
    "def get_21_lesion_location_cls():\n",
    "    D_cls = {}\n",
    "    for d in newcats:\n",
    "        id_ = d['id']\n",
    "        name = d['name']\n",
    "        D_cls[name] = id_\n",
    "    return D_cls\n",
    "\n",
    "D_cls = get_21_lesion_location_cls()\n",
    "\n",
    "def get_category_id( location , Dict ):\n",
    "    return Dict[location]\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def replace_png_path(s):\n",
    "    cs = s.replace('AutoRecist/Inputs' , 'AutoRecist/Pngs')\n",
    "    return cs\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json, yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from pycocotools import mask as cocomask\n",
    "from pycocotools import coco as cocoapi\n",
    "\n",
    "\n",
    "class DeepLesion():\n",
    "    \"\"\"\n",
    "        DL class to convert annotations to COCO Json format\n",
    "    \"\"\"\n",
    "    def __init__(self, df,image_id_start=0,annotation_id_start=0, savename='a.json'):\n",
    "        self.image_id_start = image_id_start\n",
    "        self.annotation_id_start = annotation_id_start\n",
    "        self.df = df \n",
    "        self.info = {\"year\" : 2021,\n",
    "                     \"version\" : \"2.0\",\n",
    "                     \"description\" : \"Covert Weasis to Json format\",\n",
    "                     \"contributor\" : \"HY,JM,BZ,LS,FSA\",\n",
    "                     \"url\" : \"http:// /\",\n",
    "                     \"date_created\" : \"20211129\"\n",
    "                    }\n",
    "        self.licenses = [{\"id\": 1,\n",
    "                          \"name\": \"Attribution-NonCommercial\",\n",
    "                          \"url\": \"http:// /\"\n",
    "                         }]\n",
    "\n",
    "        self.categories = newcats\n",
    "        \n",
    "        self.images, self.annotations = self.__get_image_annotation_pairs__(self.df)\n",
    "        json_data = {\"info\" : self.info,\n",
    "                     \"images\" : self.images,\n",
    "                     \"licenses\" : self.licenses,\n",
    "                     \"annotations\" : self.annotations,\n",
    "                     \"categories\" : self.categories}\n",
    "\n",
    "        with open(savename, \"w\") as jsonfile:\n",
    "            json.dump(json_data, jsonfile, sort_keys=True, indent=4)\n",
    "            \n",
    "    def change_df(self , df , savename = 'temp.json'):\n",
    "        self.df = df \n",
    "\n",
    "        self.images, self.annotations = self.__get_image_annotation_pairs__(self.df)\n",
    "        json_data = {\"info\" : self.info,\n",
    "                     \"images\" : self.images,\n",
    "                     \"licenses\" : self.licenses,\n",
    "                     \"annotations\" : self.annotations,\n",
    "                     \"categories\" : self.categories}\n",
    "\n",
    "        with open(savename, \"w\") as jsonfile:\n",
    "            json.dump(json_data, jsonfile, sort_keys=True, indent=4)\n",
    "            print( 'Saved %s'%savename )\n",
    "        \n",
    "            \n",
    "    def __get_image_annotation_pairs__(self,df):\n",
    "        images = []\n",
    "        annotations = []\n",
    "        self.file_name_dict = {}\n",
    "        for i , row in df.iterrows():\n",
    "            try:\n",
    "                print(i)\n",
    "                df_image = get_dicom_header_df( row['Image File Path'] )\n",
    "                png_folder = replace_png_path(row['Image File Path'] )\n",
    "                \n",
    "                for one in df_image.index.values.tolist():\n",
    "#                     file_name = InstanceNumber2file_name(df_image, one)\n",
    "#                     file_name = os.path.join( row['Image File Path'] , file_name)\n",
    "                    file_name = os.path.join(png_folder, '%03d.png'%one)\n",
    "                    file_name = file_name.replace('/mnt/fast-disk1/mjc/AutoRecist/','')\n",
    "\n",
    "                    if file_name in self.file_name_dict:\n",
    "                        oneimageid = self.file_name_dict[file_name]\n",
    "                    else:\n",
    "                        oneimage = {}\n",
    "                        oneimage['file_name'] = file_name\n",
    "                        self.image_id_start += 1\n",
    "                        oneimageid = self.image_id_start\n",
    "                        oneimage['id'] = oneimageid\n",
    "\n",
    "                        oneimage['height'] , oneimage['width'] = int(InstanceNumber2data_element(df_image,one,'Rows')), int( InstanceNumber2data_element(df_image,one,'Columns') )\n",
    "\n",
    "                        oneimage['slice_no'] = int(one)\n",
    "                        oneimage['spacing'] = float( InstanceNumber2data_element(df_image,one,'PixelSpacing_0') )\n",
    "                        oneimage['slice_intv'] = float( get_SliceThickness(df_image) )\n",
    "                        oneimage['z_position'] = 0.5\n",
    "                        oneimage['windows'] = InstanceNumber2windows_min_max(df_image,one)\n",
    "\n",
    "                        images.append(oneimage)\n",
    "                        self.file_name_dict[file_name] = oneimageid\n",
    "\n",
    "\n",
    "            except Exception as e: print(e)\n",
    "        \n",
    "        return images, annotations\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Image Process\n",
      "0\n",
      "7\n",
      "21\n",
      "28\n",
      "30\n",
      "47\n",
      "58\n",
      "60\n",
      "64\n",
      "65\n",
      "66\n",
      "68\n",
      "69\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "94\n",
      "95\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "136\n",
      "140\n",
      "144\n",
      "146\n",
      "163\n",
      "164\n",
      "166\n",
      "169\n",
      "170\n",
      "174\n",
      "175\n",
      "176\n",
      "181\n",
      "182\n",
      "184\n",
      "187\n",
      "224\n",
      "226\n",
      "227\n",
      "228\n",
      "232\n",
      "233\n",
      "245\n",
      "246\n",
      "247\n",
      "251\n",
      "253\n",
      "266\n",
      "272\n",
      "273\n",
      "274\n",
      "276\n",
      "281\n",
      "291\n",
      "292\n",
      "301\n",
      "314\n",
      "329\n",
      "330\n",
      "332\n",
      "333\n",
      "335\n",
      "337\n",
      "339\n",
      "346\n",
      "347\n",
      "348\n",
      "359\n",
      "360\n",
      "370\n",
      "371\n",
      "378\n",
      "381\n",
      "384\n",
      "399\n",
      "401\n",
      "403\n",
      "404\n",
      "406\n",
      "409\n",
      "416\n",
      "428\n",
      "431\n",
      "432\n",
      "434\n",
      "436\n",
      "437\n",
      "449\n",
      "451\n",
      "460\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "475\n",
      "478\n",
      "505\n",
      "506\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "515\n",
      "516\n",
      "526\n",
      "527\n",
      "543\n",
      "545\n",
      "548\n",
      "551\n",
      "553\n",
      "555\n",
      "577\n",
      "579\n",
      "590\n",
      "591\n",
      "600\n",
      "601\n",
      "602\n",
      "605\n",
      "608\n",
      "609\n",
      "613\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "649\n",
      "654\n",
      "667\n",
      "679\n",
      "682\n",
      "685\n",
      "686\n",
      "708\n",
      "716\n",
      "718\n",
      "719\n",
      "725\n",
      "727\n",
      "728\n",
      "731\n",
      "733\n",
      "734\n",
      "/mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO_RECIST/METNET0166/D2019_08_02/E5306/CT/S0004_0501/I0056.dcm size < 5kb skiped!\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "746\n",
      "750\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "757\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "768\n",
      "769\n",
      "772\n",
      "778\n",
      "785\n",
      "787\n",
      "788\n",
      "791\n",
      "792\n",
      "795\n",
      "806\n",
      "807\n",
      "816\n",
      "817\n",
      "818\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "826\n",
      "837\n",
      "838\n",
      "840\n",
      "842\n",
      "843\n",
      "846\n",
      "853\n",
      "854\n",
      "857\n",
      "858\n",
      "862\n",
      "865\n",
      "867\n",
      "868\n",
      "869\n",
      "872\n",
      "873\n",
      "875\n",
      "876\n",
      "879\n",
      "889\n",
      "890\n",
      "894\n",
      "895\n",
      "896\n",
      "909\n",
      "942\n",
      "955\n",
      "956\n",
      "957\n",
      "968\n",
      "969\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "979\n",
      "980\n",
      "981\n",
      "984\n",
      "994\n",
      "995\n",
      "998\n",
      "999\n",
      "1008\n",
      "1010\n",
      "1014\n",
      "1018\n",
      "1023\n",
      "1034\n",
      "1042\n",
      "1043\n",
      "1045\n",
      "1052\n",
      "1055\n",
      "1059\n",
      "1060\n",
      "1064\n",
      "1066\n",
      "1068\n",
      "1069\n",
      "1074\n",
      "1075\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1115\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1124\n",
      "1125\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1134\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1143\n",
      "1154\n",
      "1157\n",
      "1158\n",
      "1160\n",
      "1161\n",
      "Image Process is Done\n",
      "Total of 39807 slice images was Processed.\n"
     ]
    }
   ],
   "source": [
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instance should be str or list')\n",
    "\n",
    "pd_str_replace(df, ['Image File Path' ], \"X:\" , \"/mnt/X-drive\")\n",
    "pd_str_replace(df, ['Image File Path' ], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "\n",
    "\n",
    "print('Initial Image Process')\n",
    "dataset = DeepLesion(df,savename='/mnt/fast-data/mjc/AutoRECIST/Annotations/inference.json')\n",
    "print('Image Process is Done')\n",
    "print('Total of {} slice images was Processed.'.format(len(dataset.images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating output/Lesion/superscalenet_seg/Lesion_Q5_scalenet_seg_test/data_patch_valtest\n",
      "=> creating log/Lesion/superscalenet_seg/data_patch_valtest/Lesion_Q5_scalenet_seg_test_2022-03-13-23-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> init weights from normal distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time cost is 7.758070468902588 sec\n",
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache ground truth roidb to /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_Q5/tools/cache/inference_gt_roidb.pkl\n",
      "Loaded dataset: inference\n",
      "Computing image aspect ratios and ordering the ratios...\n",
      "done\n",
      "Computing bounding-box regression targets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 39807\n",
      "2 39807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 39807\n",
      "class_weights are:\n",
      "tensor([0.4000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 0 batches\n",
      "processing: 100 batches\n",
      "processing: 200 batches\n",
      "processing: 300 batches\n",
      "processing: 400 batches\n",
      "processing: 500 batches\n",
      "processing: 600 batches\n",
      "processing: 700 batches\n",
      "processing: 800 batches\n",
      "processing: 900 batches\n",
      "processing: 1000 batches\n",
      "processing: 1100 batches\n",
      "processing: 1200 batches\n",
      "processing: 1300 batches\n",
      "processing: 1400 batches\n",
      "processing: 1500 batches\n",
      "processing: 1600 batches\n",
      "processing: 1700 batches\n",
      "processing: 1800 batches\n",
      "processing: 1900 batches\n",
      "processing: 2000 batches\n",
      "processing: 2100 batches\n",
      "processing: 2200 batches\n",
      "processing: 2300 batches\n",
      "processing: 2400 batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time cost is 6137.491626024246 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "get_ipython().system('rm ./cache/inference_gt_roidb.pkl')\n",
    "\n",
    "get_ipython().magic('reload_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import _init_paths\n",
    "import models\n",
    "import dataset\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.seg_function import validate_seg_wo_loss as validate\n",
    "from core.oneshot_function import calib_bn_seg as calib_bn\n",
    "from utils.utils import get_model_summary\n",
    "from utils.utils import create_logger, FullModel\n",
    "\n",
    "from dataset.roidb import combined_roidb_for_training\n",
    "from roi_data.loader import RoiDataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, name = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.makedirs(sv_path)\n",
    "                save_pred(pred, sv_path, name)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d batches' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "#                 logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc\n",
    "\n",
    "\n",
    "def parse_args(l):\n",
    "    parser = argparse.ArgumentParser(description='Test segmentation network')\n",
    "\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        required=True,\n",
    "                        type=str)\n",
    "    parser.add_argument('opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "    parser.add_argument('--bn_calib',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--mask_path',\n",
    "                        help='the path of a mask.npy',\n",
    "                        default=None,\n",
    "                        type=str)\n",
    "    args = parser.parse_args(l)\n",
    "    update_config(cfg, args)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "# experiment_name = 'Lesion_Q5_9Slices_scalenet_seg_test'\n",
    "# mask_name = 'mask_1988'\n",
    "# arglist = ['--cfg', '../experiments/lesion_Q5/%s.yaml'%experiment_name ,  \n",
    "#            '--mask_path', '../evo_files/masks/%s.npy'%mask_name,  \n",
    "#            'TEST.MODEL_FILE', '../output/Lesion/superscalenet_seg/Lesion_Q5_9Slices_superscalenet/data_patch_train/best.pth',\n",
    "#            'DATASET.ROOT','',\n",
    "#            'TRAIN.USE_FLIPPED',False]\n",
    "\n",
    "experiment_name = 'Lesion_Q5_scalenet_seg_test'\n",
    "mask_name = 'mask_1514'\n",
    "arglist = ['--cfg', '../experiments/lesion_Q5/%s.yaml'%experiment_name ,  \n",
    "           '--mask_path', '../evo_files/masks/%s.npy'%mask_name,  \n",
    "           'TEST.MODEL_FILE', '../output/Lesion/superscalenet_seg/Lesion_Q5_superscalenet_base/data_patch_train/best.pth',\n",
    "           'DATASET.ROOT','../abababab/',\n",
    "           'TRAIN.USE_FLIPPED',False]\n",
    "\n",
    "args = parse_args(arglist)\n",
    "\n",
    "logger, final_output_dir, tb_log_dir = create_logger(\n",
    "    cfg, args.cfg, 'valtest')\n",
    "\n",
    "writer_dict = {\n",
    "    'writer': SummaryWriter(tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "cudnn.enabled = cfg.CUDNN.ENABLED\n",
    "\n",
    "# build model\n",
    "model = eval('models.' + cfg.MODEL.NAME +\n",
    "             '.get_seg_model')(cfg)\n",
    "\n",
    "\n",
    "if cfg.TEST.MODEL_FILE:\n",
    "    model_state_file = cfg.TEST.MODEL_FILE\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    model_state_file = os.path.join(final_output_dir,\n",
    "                                    'final_state.pth')\n",
    "# logger.info('=> loading model from {}'.format(model_state_file))\n",
    "\n",
    "pretrained_dict = torch.load(model_state_file)\n",
    "\n",
    "D2= {}\n",
    "for key in pretrained_dict.keys():\n",
    "    if key[:6] == 'model.':\n",
    "        new_key = key[6:]\n",
    "        D2[new_key] = pretrained_dict[key]\n",
    "    else:\n",
    "        # print(key)\n",
    "        D2[key] = pretrained_dict[key]\n",
    "\n",
    "pretrained_dict = D2      \n",
    "model_dict = model.state_dict()\n",
    "\n",
    "model_keys = set(model_dict.keys())\n",
    "pretrained_keys = set(pretrained_dict.keys())\n",
    "missing_keys = model_keys - pretrained_keys\n",
    "# logger.warn('Missing keys in pretrained_dict: {}'.format(missing_keys))\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )\n",
    "\n",
    "\n",
    "test_size = (cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "\n",
    "# manully select from below.\n",
    "# ('PDS_AMGEN_20020408_22Cat_test',)\n",
    "# ('PDS_Q2_A&C_22Cat_train',)\n",
    "# ('PDS_CUIMC_22Cat_test',)\n",
    "\n",
    "test_roidb, test_ratio_list, test_ratio_index = combined_roidb_for_training(\n",
    "        ('inference',) , cfg.VAL.PROPOSAL_FILES)\n",
    "\n",
    "test_dataset = RoiDataLoader(\n",
    "    test_roidb,\n",
    "    cfg.MODEL.NUM_CLASSES,\n",
    "    training=True)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.TEST.BATCH_SIZE_PER_GPU,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "\n",
    "\n",
    "\n",
    "gpus = list(cfg.GPUS)\n",
    "# logger.info('GPU list is {}'.format(gpus))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "if args.mask_path and os.path.exists(args.mask_path):\n",
    "    masks = np.load(args.mask_path, allow_pickle=True)\n",
    "    model.module.set_active_subnet(masks)\n",
    "    # logger.info('=> setting mask from {}'.format(args.mask_path))\n",
    "    # logger.info(masks)\n",
    "else:\n",
    "    masks=None\n",
    "    logger.info('No model mask')\n",
    "\n",
    "\n",
    "mean_IoU, IoU_array, pixel_acc, mean_acc = testval_lesion(cfg, \n",
    "                                                  test_dataset, \n",
    "                                                  testloader, \n",
    "                                                  model.cuda(),\n",
    "                                                  sv_dir=mask_name, \n",
    "                                                  device=None)\n",
    "\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# This notebook is to load predicted mask for hard-disk and calculate Segmentation evaluation metics.\n",
    "# predicted mask is the output of ScaleNASv2 Test and save predicted mask.ipynb\n",
    "# \n",
    "# cp -v /mnt/fast-data/mjc/AutoRECIST/Codes/ScaleNAS/ScaleNASv1/tools/utils_test.py .\n",
    "# \n",
    "# gt box are loaded from /cache/*gt_roidb.pkl\n",
    "# gt segmentation are loaded from Hao's Raw files\n",
    "# \n",
    "# predictions are all_boxes and all_segms which both are loaded from mask_1988 png files.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # This file is for segmetation metrics evaluation in 3D\n",
    "# Edited by Jingchen around 06/20/2021\n",
    "# This file is after ScaleNAS test which save predition into png images.\n",
    "# This file load png images as predicted contours in 2D\n",
    "# load cache pkl as gold-standard contours in 2D\n",
    "# The stack 2D based on dicom-header to get 3D\n",
    "# Evaluate 3D metics of dice, IoU, over-segmetation, and under-segmetation\n",
    "# \n",
    "get_ipython().magic('reload_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import _init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from utils_test import *\n",
    "from utils_test import __get_annotation__\n",
    "from utils_metrics_3d import *\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/')\n",
    "import weasis_raw_data_api as wr\n",
    "\n",
    "\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "HEIGHT , WIDTH = 512, 512\n",
    "def get_pred_vol(oneCT , site_list , D_z_index, union_mask = True):\n",
    "    slice_no_list =list ( oneCT.keys() )\n",
    "\n",
    "    V = D_z_index.values()\n",
    "    shape_z = np.max(list(V)) + 1\n",
    "    vol_shape = (shape_z , HEIGHT , WIDTH )\n",
    "    height = vol_shape[1]\n",
    "    width = vol_shape[2]\n",
    "\n",
    "    if len(slice_no_list):\n",
    "        slice_no_list.sort()\n",
    "        vol_gt = np.zeros(vol_shape, dtype = bool)\n",
    "        vol_pred = np.zeros(vol_shape, dtype = bool)\n",
    "\n",
    "        for s in slice_no_list:\n",
    "            aroidb , bboxes , segmentations = oneCT[s]\n",
    "\n",
    "            ix = [a for a,b in enumerate(aroidb['gt_classes']) if int(b) in site_list]\n",
    "            contours = [ aroidb['segms'][int(kk)] for kk in ix ]\n",
    "            \n",
    "            for c in contours:\n",
    "                if len(c): #gt\n",
    "                    new = polys_to_mask(c , height , width)\n",
    "                    vol_gt[D_z_index[s]][new>0] = 1 \n",
    "\n",
    "\n",
    "            for j in site_list:\n",
    "                contours = segmentations[j]\n",
    "                if union_mask:\n",
    "                    #contour should be numpy.array here. list cause error of no attribute 'flatten'\n",
    "                    cc = [ contour.flatten().tolist() for contour in contours if len(contour)!=0]\n",
    "                    contours = union_ploys(cc , height, width)\n",
    "\n",
    "                for c in contours:#union pred\n",
    "                    if len(c)>=6:\n",
    "                        new = polys_to_mask([c] , height , width) \n",
    "                        vol_pred[D_z_index[s]][new>0] = 1 \n",
    "                    elif len(c):\n",
    "                        print('len pred contour is %d'%len(c))\n",
    "    return vol_pred\n",
    "\n",
    "def seperate_vol(vol_pred , reduceFP = False):\n",
    "    # vol_dict = seperate_vol(vol_pred)\n",
    "    connectivity = 2\n",
    "    from skimage import measure\n",
    "    labels_pred=measure.label(vol_pred,connectivity=connectivity)\n",
    "    l_pred,c_pred = np.unique(labels_pred , return_counts=True)\n",
    "\n",
    "\n",
    "    ix2 = l_pred>0\n",
    "    l_pred = l_pred[ix2] #background pixels are labeled as 0, so we exclude them\n",
    "    c_pred = c_pred[ix2]\n",
    "\n",
    "    if reduceFP:\n",
    "        ix2 = l_pred>0\n",
    "        for i, p in enumerate(l_pred):\n",
    "            z = np.where(labels_pred == p)[0]\n",
    "            if len( set(z) )<=1:\n",
    "                ix2[i]=False\n",
    "\n",
    "        l_pred = l_pred[ix2] #background pixels are labeled as 0, so we exclude them\n",
    "        c_pred = c_pred[ix2]\n",
    "\n",
    "\n",
    "    vol_dict = {}\n",
    "\n",
    "    for p in l_pred:\n",
    "        vp = labels_pred == p\n",
    "        vol_dict[p] = vp\n",
    "\n",
    "    return vol_dict\n",
    "\n",
    "\n",
    "\n",
    "site_list_liver = [8]\n",
    "site_list_liver_lung_LNs = [2,4,6,8,9,10,11,14,17] \n",
    "site_list_LNs = [2,4,6,10,11,14,17] \n",
    "\n",
    "site_list = site_list_liver\n",
    "user_id = 'jm4669'\n",
    "\n",
    "cache_path = './cache/'\n",
    "name = 'inference'\n",
    "# name = 'lesion_train'\n",
    "\n",
    "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\n",
    "# print('Loading cached gt_roidb from %s', cache_filepath)\n",
    "with open(cache_filepath, 'rb') as fp:\n",
    "    cached_roidb = pickle.load(fp)\n",
    "    \n",
    "roidb = cached_roidb\n",
    "\n",
    "\n",
    "\n",
    "sv_dir = mask_name\n",
    "sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "\n",
    "all_boxes = [ [ np.zeros((0,5),dtype=\"float32\") for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "all_segms = [ [ [] for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "\n",
    "for i in range(len(roidb)):\n",
    "\n",
    "    one = roidb[i]\n",
    "    onename = one['image']\n",
    "    if not os.path.exists( os.path.join( sv_path, convert_name(onename) ) ):\n",
    "        print(os.path.join(sv_path, convert_name(onename) ) , 'not exists!')\n",
    "    pred_im = Image.open(os.path.join( sv_path, convert_name(onename) ))\n",
    "    pred = np.array(pred_im)\n",
    "    for j in range(cfg.DATASET.NUM_CLASSES):\n",
    "        mask = np.asarray( pred==j , dtype=np.uint8)\n",
    "        if np.sum(mask > 0) <= 3 :\n",
    "            continue\n",
    "        segmentation, bbox, area = __get_annotation__(mask , xywh = False , bbox_score=True)\n",
    "        if segmentation and bbox:\n",
    "            all_segms[j][i] = segmentation\n",
    "            all_boxes[j][i] = bbox\n",
    "\n",
    "\n",
    "D_CT = {}\n",
    "for i , aroidb in enumerate(roidb):\n",
    "    dicom_path , png_name = os.path.split(aroidb['image'])\n",
    "    slice_no , _= os.path.splitext(png_name)\n",
    "    slice_no = int(slice_no)\n",
    "    if slice_no != aroidb['slice_no']:\n",
    "        print('following slice numbers are not consistence.')\n",
    "        print(dicom_path,slice_no,aroidb['slice_no'])\n",
    "\n",
    "    segmentations = {}\n",
    "    bboxes = {}\n",
    "    for j in site_list:\n",
    "        segmentations[j] = all_segms[j][i]\n",
    "        bboxes[j] = all_boxes[j][i]\n",
    "\n",
    "    if dicom_path not in D_CT:\n",
    "        D_CT[dicom_path] = {}\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "    else:\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_str_replace(df_all, ['Image File Path' , 'Contour File Path'], \"X:\" , \"/mnt/X-drive\")\n",
    "pd_str_replace(df_all, ['Image File Path' , 'Contour File Path'], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df_all, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df_all, ['Image File Path'], \"/mnt/X-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df_all, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "\n",
    "pd_str_replace(df_all, ['Contour File Path'], \"/mnt/X-drive/ConvWeasisToRaw/PDS_AUTO_RECIST\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw/PDS_AUTO_RECIST_RAW\")\n",
    "pd_str_replace(df_all, ['Contour File Path'], \"/mnt/X-drive/ConvWeasisToRaw\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "pd_str_replace(df_all, ['Contour File Path'], \"/mnt/X-drive/ConvWeasisToMatlab\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0001/D2018_12_03/E2952/CT/S0002_6566\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0002/D2019_01_02/E1326/CT/S0007_3337\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0003/D2019_10_07/E2122/CT/S0002_2131\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0004/D2019_03_04/E9409/CT/S0016_5317\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0005/D2019_01_03/E7914/CT/S0004_6693\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0006/D2018_12_11/E8314/CT/S0002_5268\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0007/D2019_02_26/E8395/CT/S0004_4916\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0008/D2019_12_19/E2450/CT/S0002_7253\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0009/D2020_01_22/E0578/CT/S0018_3927\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0010/D2019_01_04/E0016/CT/S0003_7994\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0011/D2019_01_08/E0715/CT/S0003_9046\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0014/D2019_02_14/E0378/CT/S0004_3854\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0015/D2019_01_29/E9153/CT/S0005_2645\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0016/D2019_01_03/E6476/CT/S0002_6177\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0017/D2019_05_09/E0341/CT/S0005_3505\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0018/D2019_01_15/E3786/CT/S0003_7953\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0019/D2020_01_07/E8279/CT/S0005_2496\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0019/D2020_01_07/E3489/CT/S0006_2039\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0020/D2019_01_09/E2250/CT/S0005_1575\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0020/D2019_01_09/E0051/CT/S0009_0502\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0022/D2019_03_28/E0573/CT/S0005_2496\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0023/D2019_01_03/E3282/CT/S0002_3258\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0024/D2018_11_26/E6107/CT/S0005_1165\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0024/D2018_11_26/E0507/CT/S0006_5482\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0025/D2019_04_09/E6058/CT/S0005_0675\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0026/D2019_04_12/E3925/CT/S0006_9366\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0027/D2020_06_02/E2653/CT/S0003_6603\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0028/D2019_07_12/E6851/CT/S0006_8606\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0029/D2019_06_21/E9823/CT/S0006_8306\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0030/D2020_03_16/E8527/CT/S0002_8534\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0031/D2020_02_19/E2159/CT/S0002_2168\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0032/D2018_11_21/E6418/CT/S0006_4469\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0033/D2018_10_24/E0816/CT/S0002_0822\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0034/D2016_05_27/E1537/CT/S0004_6957\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0035/D2016_12_29/E3137/CT/S0004_0222\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0036/D2018_11_30/E2803/CT/S0003_5983\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0037/D2018_11_21/E5630/CT/S0202_0203\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0038/D2018_11_08/E1856/CT/S0004_9015\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0039/D2018_11_12/E2386/CT/S0003_4970\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0040/D2018_12_25/E0028/CT/S0004_3920\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0041/D2018_12_05/E7781/CT/S0007_9641\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0042/D2019_01_14/E8782/CT/S0002_8396\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0043/D2018_12_20/E0583/CT/S0002_4182\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0044/D2019_01_14/E8072/CT/S0003_0455\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0045/D2018_12_31/E4873/CT/S0004_3712\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0045/D2018_12_31/E4873/CT/S0002_1764\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0046/D2018_08_23/E4649/CT/S0008_9132\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0047/D2019_01_16/E1278/CT/S0004_0423\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0048/D2018_12_14/E3348/CT/S0003_4642\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0049/D2018_11_01/E9980/CT/S0004_2520\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0050/D2019_01_04/E4478/CT/S0002_6859\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0051/D2019_01_25/E4701/CT/S0002_5897\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0052/D2019_01_24/E1463/CT/S0003_1463\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0053/D2018_11_08/E0078/CT/S0007_9789\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0054/D2019_03_13/E9285/CT/S0004_8824\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0055/D2019_02_25/E8293/CT/S0005_8934\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0056/D2019_03_19/E2806/CT/S0002_8158\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0057/D2019_04_04/E3905/CT/S0006_3741\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0058/D2019_04_09/E7107/CT/S0004_0747\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0059/D2019_04_29/E7944/CT/S0008_8791\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0060/D2019_05_28/E4296/CT/S0002_5183\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0061/D2019_09_23/E8963/CT/S0006_9201\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0062/D2019_06_24/E3991/CT/S0704_8364\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0063/D2019_09_06/E5582/CT/S0003_5856\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0063/D2019_09_06/E5582/CT/S0004_5912\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0066/D2019_12_11/E7093/CT/S0002_9653\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0067/D2019_12_12/E3385/CT/S0006_1316\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0068/D2019_12_05/E7533/CT/S0003_7277\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0069/D2020_06_05/E9601/CT/S0002_4343\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0069/D2020_06_05/E9601/CT/S0004_5071\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0070/D2020_03_10/E1191/CT/S0006_1494\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0071/D2020_02_06/E9761/CT/S0003_9189\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0072/D2020_05_06/E8731/CT/S0002_4371\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0074/D2020_03_23/E3151/CT/S0001_8171\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0074/D2020_03_23/E3151/CT/S0004_8557\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0075/D2018_11_09/E1827/CT/S0005_0722\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0076/D2019_01_07/E1023/CT/S0003_0772\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0078/D2019_12_16/E6701/CT/S0005_8165\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0081/D2018_12_26/E6063/CT/S0002_8800\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0082/D2019_01_10/E8327/CT/S0003_0374\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0083/D2020_05_22/E2401/CT/S0002_6856\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0083/D2020_05_22/E2401/CT/S0004_7056\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0086/D2020_07_18/E4710/CT/S0004_8400\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0088/D2019_01_07/E0906/CT/S0002_8721\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0089/D2019_10_22/E2646/CT/S0003_6412\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0089/D2019_10_24/E1690/CT/S0002_1700\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0090/D2019_12_04/E4704/CT/S0002_8241\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0090/D2019_12_04/E0431/CT/S0003_0235\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0091/D2020_07_21/E8492/CT/S0003_1824\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0092/D2019_04_02/E1327/CT/S0007_1538\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0092/D2019_04_02/E8699/CT/S0004_7044\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0093/D2019_01_18/E5743/CT/S0002_5752\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0094/D2019_02_18/E2895/CT/S0602_8602\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0095/D2020_01_05/E7808/CT/S0002_7815\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0096/D2019_03_12/E7312/CT/S0006_3216\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0096/D2019_05_09/E4384/CT/S0003_7683\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0097/D2019_07_05/E2510/CT/S0002_2523\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0099/D2018_10_16/E5079/CT/S0002_5934\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0100/D2018_12_12/E5277/CT/S0003_0190\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0101/D2019_01_03/E9340/CT/S0002_3737\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0102/D2019_01_15/E5054/CT/S0007_8717\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0103/D2019_01_29/E3077/CT/S0002_6008\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0104/D2019_02_12/E3272/CT/S0004_4674\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0105/D2019_05_03/E6428/CT/S0002_0123\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0107/D2019_07_05/E0366/CT/S0004_6314\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0108/D2019_08_19/E5304/CT/S0005_5036\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0109/D2019_12_17/E3845/CT/S0005_1061\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0110/D2020_01_14/E9884/CT/S0011_3164\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0111/D2020_01_06/E7915/CT/S0004_6814\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0113/D2019_08_20/E0724/CT/S0007_7337\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0114/D2017_01_18/E3962/CT/S0002_8516\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0115/D2018_10_19/E5456/CT/S0002_7757\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0116/D2019_01_15/E7393/CT/S0006_5482\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0117/D2019_05_23/E5543/CT/S0004_3920\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0118/D2019_11_13/E0334/CT/S0004_4848\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0120/D2020_01_23/E1606/CT/S0002_9858\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0121/D2019_08_26/E8599/CT/S0003_8756\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0122/D2019_12_12/E5705/CT/S0008_0476\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0123/D2019_12_19/E4748/CT/S0005_0776\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0124/D2019_05_24/E9844/CT/S0004_8534\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0124/D2019_05_24/E4682/CT/S0007_2134\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0125/D2019_07_01/E1437/CT/S0003_4463\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0127/D2019_12_02/E0285/CT/S0005_2965\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0127/D2019_12_02/E5795/CT/S0006_4436\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0128/D2019_09_17/E0773/CT/S0003_9824\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0129/D2019_01_28/E0202/CT/S0002_0209\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0131/D2019_01_04/E1058/CT/S0002_8806\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0132/D2019_01_23/E3700/CT/S0004_1328\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0133/D2019_01_31/E2445/CT/S0005_6241\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0135/D2019_04_26/E7061/CT/S0003_3772\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0136/D2019_06_05/E6581/CT/S0002_0029\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0137/D2019_08_07/E8485/CT/S0002_0959\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0138/D2019_01_20/E7178/CT/S0002_9221\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0139/D2019_02_15/E5480/CT/S0003_3540\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0140/D2019_02_21/E1740/CT/S0003_5046\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0141/D2019_06_03/E1004/CT/S0003_8402\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0142/D2019_06_06/E8264/CT/S0004_2714\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0143/D2019_06_04/E7355/CT/S0004_3920\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0144/D2018_12_05/E9730/CT/S0006_7376\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0145/D2019_03_11/E7344/CT/S0003_3513\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0146/D2019_07_09/E8702/CT/S0007_7117\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0147/D2019_02_08/E7146/CT/S0005_2425\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0148/D2019_07_06/E2583/CT/S0003_5923\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0149/D2019_04_09/E4192/CT/S0602_4602\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0150/D2019_12_13/E6241/CT/S0005_2496\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0151/D2019_02_12/E2881/CT/S0005_2494\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0152/D2019_01_30/E6856/CT/S0003_8653\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0153/D2019_12_10/E3951/CT/S0003_3965\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0154/D2019_03_22/E0387/CT/S0601_7363\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0155/D2019_05_01/E4185/CT/S0601_4232\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0157/D2019_01_04/E8620/CT/S0002_2901\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0157/D2019_01_04/E8684/CT/S0006_9814\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0158/D2019_01_25/E2540/CT/S0002_5284\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0160/D2019_02_19/E0752/CT/S0002_9349\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0162/D2019_04_08/E1360/CT/S0004_6441\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0164/D2019_10_21/E3327/CT/S0003_2013\n",
      "finished  /mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0165/D2019_08_20/E7950/CT/S0002_1410\n"
     ]
    },
    {
     "ename": "InvalidDicomError",
     "evalue": "File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidDicomError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-682c0b0963f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mimage_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdicom_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_series_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_series\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvol_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/weasis_raw_data_api.py\u001b[0m in \u001b[0;36mdicom_header\u001b[0;34m(image_series_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdicom_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_series_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mdicom_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDicomImageReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mimage_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicom_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dicom_image_series_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_series_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/read_dicom_image.py\u001b[0m in \u001b[0;36mread_dicom_image_series_as_list\u001b[0;34m(self, image_series_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_dicom_image_series_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_series_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# image_series_list is a list sorted in ascending order of instance number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mimage_series_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dicom_image_series_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_series_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mimage_series_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/read_dicom_image.py\u001b[0m in \u001b[0;36mread_dicom_image_series_as_dict\u001b[0;34m(self, image_series_path)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mimage_pathes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_series_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dcm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_pathes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mdicom_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dicom_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdicom_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0minstance_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicom_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInstanceNumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/read_dicom_image.py\u001b[0m in \u001b[0;36mread_dicom_image\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_dicom_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mdicom_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dicom_image_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# check essential tags in dicom dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/read_dicom_image.py\u001b[0m in \u001b[0;36mread_dicom_image_inner\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_dicom_image_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdicom_image_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mdicom_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicom_image_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdicom_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdcmread\u001b[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0mdefer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_in_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mspecific_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecific_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         )\n\u001b[1;32m   1034\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Read preamble (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m     \u001b[0mpreamble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_preamble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m     \u001b[0;31m# Read any File Meta Information group (0002,eeee) elements (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0mfile_meta_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_file_meta_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_preamble\u001b[0;34m(fp, force)\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"DICM\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         raise InvalidDicomError(\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0;34m\"File is missing DICOM File Meta Information header or the 'DICM' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;34m\"prefix is missing from the header. Use force=True to force \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;34m\"reading.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidDicomError\u001b[0m: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading."
     ]
    }
   ],
   "source": [
    "def initialize_mask_vol( D_z_index , height , width):\n",
    "    V = D_z_index.values()\n",
    "    shape_z = np.max(list(V)) + 1\n",
    "    mask_vol = np.zeros((shape_z , height , width ) , dtype=np.uint8 )\n",
    "    return mask_vol\n",
    "\n",
    "Metrics_vol = []\n",
    "keys = list(D_CT.keys())\n",
    "for k in keys:\n",
    "#     if 'COU-AA-302' in k:\n",
    "#         site_list = site_list_LNs\n",
    "#     else:\n",
    "#         site_list = site_list_liver_lung_LNs\n",
    "\n",
    "    image_series_path = k.replace('/Pngs/' , '/Inputs/')    \n",
    "\n",
    "    df_image = get_dicom_header_df( image_series_path )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "\n",
    "    oneCT = remove_single_slice_segms(D_CT[k])\n",
    "    vol_pred = get_pred_vol(oneCT , site_list , D_z_index, union_mask = False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    image_series = wr.dicom_header(image_series_path)\n",
    "    if len(image_series):\n",
    "        height = image_series[0].Rows \n",
    "        width = image_series[0].Columns \n",
    "    else:\n",
    "        print('ERROR image_series has no len' , image_series_path)\n",
    "    assert(len(image_series) == vol_pred.shape[0])\n",
    "\n",
    "    mask_vol = initialize_mask_vol( D_z_index, height , width)\n",
    "\n",
    "    df_radiologist = df_all[(df_all['Image File Path'] == image_series_path) & (df_all['Location'].isin(['liver'])) ]\n",
    "    for _ , row in df_radiologist.iterrows():\n",
    "        radiologist_raw = wr.read(row['Contour File Path'])\n",
    "        slice_list = radiologist_raw.get_instance_number_array()\n",
    "        for j, one in enumerate(slice_list):\n",
    "            mask = radiologist_raw.get_mask_image(j)\n",
    "            mask_vol[D_z_index[one]] += mask\n",
    "\n",
    "\n",
    "    vol2 = vol_pred + mask_vol\n",
    "    vol2[vol2>1]=1\n",
    "    vol_dict = seperate_vol(vol2)\n",
    "    \n",
    "    for tumor_index in vol_dict:\n",
    "        mask_volume = vol_dict[tumor_index]\n",
    "        weasis_raw_data = wr.create(image_series, mask_volume)\n",
    "\n",
    "        file_folder = os.path.join(SAVE_PATH , 'RawToWeasis')\n",
    "        if not os.path.exists(file_folder):\n",
    "            os.makedirs(file_folder)\n",
    "        file_name = wr.unique(image_series, tumor_index, user_id)\n",
    "        file_name = os.path.join(file_folder,file_name)\n",
    "        wr.write(weasis_raw_data, file_name)\n",
    "\n",
    "        Metrics_vol.append( [image_series_path , file_name , user_id ])\n",
    "\n",
    "\n",
    "\n",
    "    df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                              columns = ['Image File Path','Contour File Path','Uni']) \n",
    "    df_metrics.to_csv('RawToWeasisUnionAIRadiologist_Amgen20020408.csv' , index=False)\n",
    "    print('finished ', k )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0166/D2019_08_02/E5306/CT/S0004_0501'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

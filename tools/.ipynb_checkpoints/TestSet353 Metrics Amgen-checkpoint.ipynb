{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/')\n",
    "\n",
    "import weasis_raw_data_api as wr\n",
    "sys.path.append('/mnt/fast-disk1/mjc/utils_codes/')\n",
    "from utils_test import *\n",
    "from utils_metrics_3d import *\n",
    "\n",
    "D_dir2header_df = {}\n",
    "def get_dicom_header_df(image_dir , labels = []):\n",
    "    global D_dir2header_df\n",
    "    if image_dir in D_dir2header_df:\n",
    "        return D_dir2header_df[image_dir]\n",
    "\n",
    "    # image_dir = row['Image File Path']\n",
    "\n",
    "\n",
    "    labels = ['ImageName','InstanceNumber',\n",
    "            'BitsAllocated', 'BitsStored', 'Columns', 'HighBit', \n",
    "            'ImageOrientationPatient_0', 'ImageOrientationPatient_1', 'ImageOrientationPatient_2',\n",
    "            'ImageOrientationPatient_3', 'ImageOrientationPatient_4', 'ImageOrientationPatient_5',\n",
    "            'ImagePositionPatient_0', 'ImagePositionPatient_1', 'ImagePositionPatient_2',\n",
    "            'Modality', 'PatientID', 'PhotometricInterpretation', 'PixelRepresentation',\n",
    "            'PixelSpacing_0', 'PixelSpacing_1', 'RescaleIntercept', 'RescaleSlope', 'Rows', 'SOPInstanceUID',\n",
    "            'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID', 'StudyInstanceUID', \n",
    "            'WindowCenter', 'WindowWidth', \n",
    "        ] if not labels else labels\n",
    "\n",
    "    data = {l: [] for l in labels}\n",
    "    \n",
    "    ctList = os.listdir(image_dir)\n",
    "    ctList.sort()\n",
    "\n",
    "    for image in ctList:\n",
    "        if '.dcm' not in image:\n",
    "            continue\n",
    "        if os.path.getsize(os.path.join(image_dir, image)) < 5*1024:\n",
    "            print('%s size < 5kb skiped!'%os.path.join(image_dir, image) )\n",
    "            continue\n",
    "        data[\"ImageName\"].append(image)\n",
    "\n",
    "        ds = pydicom.dcmread(os.path.join(image_dir, image))\n",
    "        for metadata in ds.dir():\n",
    "            if metadata not in data and metadata not in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                continue\n",
    "            if metadata != \"PixelData\":\n",
    "                metadata_values = getattr(ds, metadata)\n",
    "                if type(metadata_values) == pydicom.multival.MultiValue and metadata not in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                    for i, v in enumerate(metadata_values):\n",
    "                        data[f\"{metadata}_{i}\"].append(v)  \n",
    "                else:\n",
    "\n",
    "                    if type(metadata_values) == pydicom.multival.MultiValue and metadata in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                        data[metadata].append(metadata_values[0])\n",
    "                    else:\n",
    "                        \n",
    "                        if metadata in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                            print( 'error of loading key: {}'.format(metadata) )                    \n",
    "                        else:\n",
    "                            data[metadata].append(metadata_values)\n",
    "\n",
    "    df_image = pd.DataFrame(data).set_index(\"InstanceNumber\")\n",
    "    D_dir2header_df[image_dir] = df_image\n",
    "    return df_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        try:\n",
    "            df[col] = df[col].str.replace(ori,new, case = False) \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instance should be str or list')\n",
    "\n",
    "\n",
    "def str_Xdrive2mnt(df_all):\n",
    "    pd_str_replace(df_all, ['Image File Path' , 'Contour File Path'], \"X:\" , \"/mnt/Y-drive\")\n",
    "    pd_str_replace(df_all, ['Image File Path' , 'Contour File Path'], r\"\\\\\" , \"/\")\n",
    "    pd_str_replace(df_all, ['Image File Path'], \"/mnt/Y-drive/ClinicalTrials/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "    pd_str_replace(df_all, ['Image File Path'], \"/mnt/Y-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "    pd_str_replace(df_all, ['Image File Path'], \"/mnt/Y-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "\n",
    "    pd_str_replace(df_all, ['Contour File Path'], \"/mnt/Y-drive/ConvWeasisToRaw/PDS_AUTO_RECIST_Modified_By_Yen\",\n",
    "    \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw/PDS_AUTO_RECIST_Modified_By_Yen\")\n",
    "    pd_str_replace(df_all, ['Contour File Path'], \"/mnt/Y-drive/ConvWeasisToRaw/PDS_AUTO_RECIST\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw/PDS_AUTO_RECIST_RAW\")\n",
    "    pd_str_replace(df_all, ['Contour File Path'], \"/mnt/Y-drive/ConvWeasisToRaw\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "    pd_str_replace(df_all, ['Contour File Path'], \"/mnt/Y-drive/ConvWeasisToMatlab\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "    \n",
    "def get_onect_from_list(df_list , ct):\n",
    "    for i, df in enumerate(df_list):\n",
    "        try:\n",
    "            df_ct = df[ (df[\"Image File Path\"]==ct) & (df['Location'].isin(['liver'])) ]\n",
    "        except KeyError:\n",
    "            df_ct = df[ (df[\"Image File Path\"]==ct)]\n",
    "        if df_ct.shape[0]:\n",
    "            return df_ct , i\n",
    "    print(\"warning! no CT was found\")\n",
    "    return None ,None\n",
    "\n",
    "def raws2mask(raws , D_z_index, mask_vol = None):\n",
    "\n",
    "    for raw in raws:\n",
    "\n",
    "        radiologist_raw = wr.read(raw)\n",
    "        slice_list = radiologist_raw.get_instance_number_array()\n",
    "        if mask_vol is None:\n",
    "            mask_vol = initialize_mask_vol(radiologist_raw , D_z_index)\n",
    "        for j, one in enumerate(slice_list):\n",
    "            mask = radiologist_raw.get_mask_image(j)\n",
    "            mask_vol[D_z_index[one]] += mask\n",
    "    return mask_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Comments  Patient ID  \\\n",
      "225                         minimal or no revision  METNET2910   \n",
      "226                         minimal or no revision  METNET2911   \n",
      "227                                 minor revision  METNET2914   \n",
      "228                                 minor revision  METNET2915   \n",
      "229                                 major revision  METNET2917   \n",
      "..                                             ...         ...   \n",
      "348  minor revision(falsely targeted fat deposits)  METNET6058   \n",
      "349                         minimal or no revision  METNET6067   \n",
      "350                         minimal or no revision  METNET6070   \n",
      "351                         minimal or no revision  METNET6073   \n",
      "352                         minimal or no revision  METNET6082   \n",
      "\n",
      "                                       Image File Path  \\\n",
      "225  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "226  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "227  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "228  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "229  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "..                                                 ...   \n",
      "348  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "349  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "350  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "351  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "352  /mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO...   \n",
      "\n",
      "    The indexes of benign lesions Contrast Diffuse Change in Liver  \\\n",
      "225                           all      YES                      NO   \n",
      "226                           all      YES                      NO   \n",
      "227                           all      YES                      NO   \n",
      "228                           all      YES                      NO   \n",
      "229                           all      YES                     YES   \n",
      "..                            ...      ...                     ...   \n",
      "348                         1,2,3      YES                      NO   \n",
      "349                             1      YES                      NO   \n",
      "350                           all      YES                      NO   \n",
      "351                           NaN      YES                      NO   \n",
      "352                           1,2      YES                      NO   \n",
      "\n",
      "     #AI_Annotated  #Ori_Radiologist_Annotated  #Yen_Annotated  ToDo  \\\n",
      "225              4                           3             4.0   NaN   \n",
      "226              1                           1             1.0   NaN   \n",
      "227              8                           2            14.0   NaN   \n",
      "228              6                           2             7.0   NaN   \n",
      "229             37                           5            55.0   NaN   \n",
      "..             ...                         ...             ...   ...   \n",
      "348              4                           4             NaN  ToDo   \n",
      "349              1                           1             NaN  ToDo   \n",
      "350              2                           1             NaN  ToDo   \n",
      "351              1                           1             NaN  ToDo   \n",
      "352              2                           2             NaN  ToDo   \n",
      "\n",
      "    Revised_Yen  #lesions   min_Uni   max_Uni Priority  max_Uni_Yen  \\\n",
      "225         Yes       3.0   8.25109  17.72740   remove          NaN   \n",
      "226         Yes       1.0  12.93000  12.93000   remove          NaN   \n",
      "227         Yes       2.0  10.27460  15.07550   remove          NaN   \n",
      "228         Yes       2.0  11.58000  30.53950      2nd          NaN   \n",
      "229         Yes       5.0   8.29484  12.36720   remove          NaN   \n",
      "..          ...       ...       ...       ...      ...          ...   \n",
      "348         Yes       4.0   8.01686  23.71940   remove          NaN   \n",
      "349         Yes       1.0   7.04699   7.04699   remove          NaN   \n",
      "350         Yes       1.0  14.74130  14.74130   remove          NaN   \n",
      "351         Yes       1.0   7.24583   7.24583   remove          NaN   \n",
      "352         Yes       2.0  23.28630  43.53880      2nd          NaN   \n",
      "\n",
      "       dataset Column1  \n",
      "225  CUIMClast     NaN  \n",
      "226  CUIMClast     NaN  \n",
      "227  CUIMClast     NaN  \n",
      "228  CUIMClast     NaN  \n",
      "229  CUIMClast     NaN  \n",
      "..         ...     ...  \n",
      "348  CUIMClast     NaN  \n",
      "349  CUIMClast     NaN  \n",
      "350  CUIMClast     NaN  \n",
      "351  CUIMClast     NaN  \n",
      "352  CUIMClast     NaN  \n",
      "\n",
      "[128 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "subsetname = 'CUIMClast'\n",
    "folder = '/mnt/fast-data/mjc/AutoRECIST/Inputs/'\n",
    "\n",
    "df_CTs = pd.read_excel(folder+'AutoRECIST_List_LesionSize_20220602_JM_SingleCTSeries.xlsx')\n",
    "str_Xdrive2mnt(df_CTs)\n",
    "\n",
    "df_CTs = df_CTs[df_CTs['dataset']==subsetname]\n",
    "print(df_CTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fast-disk1/mjc/AutoRecist/Inputs/PDS_AUTO_RECIST/METNET2910/D2015_02_06/E8602/CT/S0005_3151\n"
     ]
    }
   ],
   "source": [
    "df_Yen = pd.read_excel(folder+'PDS_AUTO_RECIST CIA-LAB Testing Dataset Gold Standard_Yen_2022-06-13.xlsx')\n",
    "str_Xdrive2mnt(df_Yen)\n",
    "\n",
    "AI_raw_list = ['ScaleNAS9Slices_ToRaw_Test353.csv',]\n",
    "df_AIs = []\n",
    "for one in AI_raw_list:\n",
    "    df = pd.read_csv(one)\n",
    "    str_Xdrive2mnt(df)\n",
    "    df_AIs.append(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Metrics_vol = []\n",
    "metrics_save_path = 'Metrics_%s_vs_Yen_%s.csv'%('ScaleNAS9Slices' ,subsetname )\n",
    "CTs = df_CTs[\"Image File Path\"].values.tolist()\n",
    "\n",
    "for ct in CTs:\n",
    "    df_image = get_dicom_header_df( ct )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "\n",
    "    df_ct_Yen = df_Yen[df_Yen[\"Image File Path\"]==ct]\n",
    "    df_ct_AI , dataset_id = get_onect_from_list(df_AIs , ct)\n",
    "    # break\n",
    "    if (df_ct_AI is None):\n",
    "        if df_ct_Yen.shape[0]:\n",
    "            fn = df_ct_Yen.shape[0]\n",
    "            print('{} has {} FNs!'.format(ct , fn))   \n",
    "        continue\n",
    "\n",
    "    if not df_ct_Yen.shape[0]:\n",
    "        fp = df_ct_AI.shape[0]\n",
    "        print( '{} has {} FPs'.format(ct , fp)  )\n",
    "        continue\n",
    "    else:\n",
    "        print(ct)\n",
    "\n",
    "    raws = df_ct_AI[\"Contour File Path\"].values.tolist()\n",
    "    vol_pred = raws2mask(raws , D_z_index, mask_vol = None)\n",
    "    connectivity = 2\n",
    "    from skimage import measure\n",
    "    labels_pred=measure.label(vol_pred,connectivity=connectivity)\n",
    "    l_pred,c_pred = np.unique(labels_pred , return_counts=True)\n",
    "    ix2 = l_pred>0\n",
    "    l_pred = l_pred[ix2] #background pixels are labeled as 0, so we exclude them\n",
    "    c_pred = c_pred[ix2]\n",
    "    if len(l_pred)!= len(raws):\n",
    "        print(\"warning! raws overlaped on {}\".format(ct))\n",
    "\n",
    "\n",
    "    for _ , row in df_ct_Yen.iterrows():\n",
    "\n",
    "        Yen_raw = wr.read(row['Contour File Path'])\n",
    "        gt_vol = initialize_mask_vol(Yen_raw , D_z_index)\n",
    "\n",
    "        slice_list = Yen_raw.get_instance_number_array()\n",
    "        for j, one in enumerate(slice_list):\n",
    "            mask = Yen_raw.get_mask_image(j)\n",
    "            gt_vol[D_z_index[one]] = mask\n",
    "        \n",
    "        hit = vols_seg_results(gt_vol , vol_pred, CTname=row['Contour File Path'], gt_keep_largest=1)\n",
    "        Metrics_vol.extend(hit)\n",
    "\n",
    "        _n = len(Metrics_vol)\n",
    "        if _n%100==0 or _n in [1,2,5,10,30,50]:\n",
    "            df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                                    columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                                'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                                'area_gt','area_pred','intersection','union']) \n",
    "            df_metrics.to_csv(metrics_save_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                        columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                    'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                    'area_gt','area_pred','intersection','union']) \n",
    "df_metrics.to_csv(metrics_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>igt</th>\n",
       "      <th>merge</th>\n",
       "      <th>#gt</th>\n",
       "      <th>#pred</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>over_seg</th>\n",
       "      <th>under_seg</th>\n",
       "      <th>area_gt</th>\n",
       "      <th>area_pred</th>\n",
       "      <th>intersection</th>\n",
       "      <th>union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "      <td>405.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.136</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.432</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0.470</td>\n",
       "      <td>7985.679</td>\n",
       "      <td>13033.126</td>\n",
       "      <td>6235.800</td>\n",
       "      <td>14783.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.797</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.338</td>\n",
       "      <td>27.741</td>\n",
       "      <td>0.389</td>\n",
       "      <td>35262.667</td>\n",
       "      <td>50323.962</td>\n",
       "      <td>29954.115</td>\n",
       "      <td>54546.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>43.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>46.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>219.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>317.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.362</td>\n",
       "      <td>753.000</td>\n",
       "      <td>537.000</td>\n",
       "      <td>262.000</td>\n",
       "      <td>1070.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.552</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2525.000</td>\n",
       "      <td>2860.000</td>\n",
       "      <td>1118.000</td>\n",
       "      <td>3962.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.876</td>\n",
       "      <td>10.250</td>\n",
       "      <td>1.000</td>\n",
       "      <td>27016.400</td>\n",
       "      <td>58918.200</td>\n",
       "      <td>16139.000</td>\n",
       "      <td>60843.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.965</td>\n",
       "      <td>462.278</td>\n",
       "      <td>1.000</td>\n",
       "      <td>446885.000</td>\n",
       "      <td>423728.000</td>\n",
       "      <td>367722.000</td>\n",
       "      <td>502891.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          igt   merge     #gt   #pred  iou_score  dice_score  over_seg  \\\n",
       "count 405.000 405.000 405.000 405.000    405.000     405.000   405.000   \n",
       "mean    1.032   0.000   1.000  10.136      0.336       0.432     4.100   \n",
       "std     0.214   0.000   0.000   7.797      0.285       0.338    27.741   \n",
       "min     1.000   0.000   1.000   1.000      0.000       0.000     0.000   \n",
       "5%      1.000   0.000   1.000   2.000      0.000       0.000     0.000   \n",
       "25%     1.000   0.000   1.000   5.000      0.000       0.000     0.000   \n",
       "50%     1.000   0.000   1.000   8.000      0.355       0.524     0.160   \n",
       "75%     1.000   0.000   1.000  17.000      0.590       0.742     0.552   \n",
       "95%     1.000   0.000   1.000  29.000      0.779       0.876    10.250   \n",
       "max     4.000   0.000   1.000  29.000      0.932       0.965   462.278   \n",
       "\n",
       "       under_seg    area_gt  area_pred  intersection      union  \n",
       "count    405.000    405.000    405.000       405.000    405.000  \n",
       "mean       0.470   7985.679  13033.126      6235.800  14783.005  \n",
       "std        0.389  35262.667  50323.962     29954.115  54546.834  \n",
       "min        0.000      8.000      0.000         0.000      8.000  \n",
       "5%         0.009     43.200      0.000         0.000     46.600  \n",
       "25%        0.106    219.000      0.000         0.000    317.000  \n",
       "50%        0.362    753.000    537.000       262.000   1070.000  \n",
       "75%        1.000   2525.000   2860.000      1118.000   3962.000  \n",
       "95%        1.000  27016.400  58918.200     16139.000  60843.400  \n",
       "max        1.000 446885.000 423728.000    367722.000 502891.000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                          columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                     'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                     'area_gt','area_pred','intersection','union']) \n",
    "df_metrics.describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>igt</th>\n",
       "      <th>merge</th>\n",
       "      <th>#gt</th>\n",
       "      <th>#pred</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>over_seg</th>\n",
       "      <th>under_seg</th>\n",
       "      <th>area_gt</th>\n",
       "      <th>area_pred</th>\n",
       "      <th>intersection</th>\n",
       "      <th>union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "      <td>258.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.031</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.674</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.255</td>\n",
       "      <td>11583.857</td>\n",
       "      <td>13335.736</td>\n",
       "      <td>9601.248</td>\n",
       "      <td>15318.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.052</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.224</td>\n",
       "      <td>43719.614</td>\n",
       "      <td>49496.962</td>\n",
       "      <td>37120.742</td>\n",
       "      <td>55719.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>79.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.010</td>\n",
       "      <td>113.550</td>\n",
       "      <td>124.100</td>\n",
       "      <td>64.100</td>\n",
       "      <td>190.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.067</td>\n",
       "      <td>329.000</td>\n",
       "      <td>333.000</td>\n",
       "      <td>202.250</td>\n",
       "      <td>510.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.181</td>\n",
       "      <td>959.000</td>\n",
       "      <td>970.000</td>\n",
       "      <td>684.500</td>\n",
       "      <td>1230.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.395</td>\n",
       "      <td>3313.750</td>\n",
       "      <td>3451.750</td>\n",
       "      <td>2479.750</td>\n",
       "      <td>4733.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.888</td>\n",
       "      <td>2.483</td>\n",
       "      <td>0.699</td>\n",
       "      <td>52986.150</td>\n",
       "      <td>48483.800</td>\n",
       "      <td>38371.950</td>\n",
       "      <td>57283.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.965</td>\n",
       "      <td>5.781</td>\n",
       "      <td>0.855</td>\n",
       "      <td>446885.000</td>\n",
       "      <td>423728.000</td>\n",
       "      <td>367722.000</td>\n",
       "      <td>502891.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          igt   merge     #gt   #pred  iou_score  dice_score  over_seg  \\\n",
       "count 258.000 258.000 258.000 258.000    258.000     258.000   258.000   \n",
       "mean    1.031   0.000   1.000  10.674      0.519       0.664     0.594   \n",
       "std     0.174   0.000   0.000   8.052      0.182       0.168     0.900   \n",
       "min     1.000   0.000   1.000   1.000      0.145       0.254     0.000   \n",
       "5%      1.000   0.000   1.000   2.000      0.206       0.342     0.018   \n",
       "25%     1.000   0.000   1.000   5.000      0.379       0.550     0.112   \n",
       "50%     1.000   0.000   1.000   8.000      0.533       0.696     0.303   \n",
       "75%     1.000   0.000   1.000  17.000      0.652       0.790     0.607   \n",
       "95%     1.000   0.000   1.000  29.000      0.798       0.888     2.483   \n",
       "max     2.000   0.000   1.000  29.000      0.932       0.965     5.781   \n",
       "\n",
       "       under_seg    area_gt  area_pred  intersection      union  \n",
       "count    258.000    258.000    258.000       258.000    258.000  \n",
       "mean       0.255  11583.857  13335.736      9601.248  15318.345  \n",
       "std        0.224  43719.614  49496.962     37120.742  55719.856  \n",
       "min        0.000     29.000     32.000        29.000     79.000  \n",
       "5%         0.010    113.550    124.100        64.100    190.400  \n",
       "25%        0.067    329.000    333.000       202.250    510.500  \n",
       "50%        0.181    959.000    970.000       684.500   1230.000  \n",
       "75%        0.395   3313.750   3451.750      2479.750   4733.500  \n",
       "95%        0.699  52986.150  48483.800     38371.950  57283.600  \n",
       "max        0.855 446885.000 423728.000    367722.000 502891.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics[df_metrics.dice_score>0.25].describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name 405\n",
      "igt 3\n",
      "merge 1\n",
      "#gt 1\n",
      "#pred 17\n",
      "iou_score 296\n",
      "dice_score 296\n",
      "over_seg 287\n",
      "under_seg 282\n",
      "area_gt 369\n",
      "area_pred 263\n",
      "intersection 279\n",
      "union 380\n",
      "Image File Path 72\n",
      "Contour File Path 405\n",
      "Raw File Name 405\n",
      "Uni 396\n",
      "Perp 396\n",
      "Bi 405\n",
      "Volume 405\n",
      "================================================================================\n",
      "In total, 72 CT series; 415 AI detections \n",
      "sensitivity is 0.728(295/405) FP-rate is 1.7 per CT-serie at threshold 0\n",
      "sensitivity is 0.679(275/405) FP-rate is 1.9 per CT-serie at threshold 0.1\n",
      "sensitivity is 0.644(261/405) FP-rate is 2.1 per CT-serie at threshold 0.2\n",
      "sensitivity is 0.637(258/405) FP-rate is 2.2 per CT-serie at threshold 0.25\n",
      "sensitivity is 0.516(209/405) FP-rate is 2.9 per CT-serie at threshold 0.5\n"
     ]
    }
   ],
   "source": [
    "dfinnermerge = pd.merge(df_metrics,df_Yen,how='inner',left_on='file_name' , right_on='Contour File Path')\n",
    "for col in dfinnermerge.columns.tolist():\n",
    "    print(col , len(set(dfinnermerge[col].tolist() )) )\n",
    "\n",
    "\n",
    "\n",
    "pts = dfinnermerge[\"Image File Path\"].values.tolist()\n",
    "FPs = []\n",
    "for onept in list(set(pts)):\n",
    "    df_onept = dfinnermerge[dfinnermerge[\"Image File Path\"]==onept]\n",
    "    assert( min(df_onept[\"#pred\"]) == max(df_onept[\"#pred\"]))\n",
    "    fp = max(df_onept[\"#pred\"])\n",
    "    FPs.append(fp)\n",
    "print(\"=\"*80)\n",
    "print( \"In total, {} CT series; {} AI detections \".format( len(FPs) , sum(FPs) ) )\n",
    "\n",
    "dices = dfinnermerge.dice_score.tolist()\n",
    "\n",
    "for th in [0, 0.1, 0.2, 0.25, 0.5]:\n",
    "    TP = [p>th for p in dices ]\n",
    "    assert( len(TP) == len(dices))\n",
    "    fprate = ( sum(FPs) - sum(TP) ) / len(FPs)\n",
    "    print(f\"sensitivity is {sum(TP)/len(dices):.3f}({sum(TP)}/{len(dices)}) FP-rate is {fprate:.1f} per CT-serie at threshold {th}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to load predicted mask for hard-disk and calculate Segmentation evaluation metics.\n",
    "predicted mask is the output of ScaleNASv2 Test and save predicted mask.ipynb\n",
    "\n",
    "cp -v /mnt/fast-data/mjc/AutoRECIST/Codes/ScaleNAS/ScaleNASv1/tools/utils_test.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "site_list = [2,4,6,10,11,14,17] # LN list\n",
    "cache_path = './cache/'\n",
    "name = 'Cougar302_80pts_test'\n",
    "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\n",
    "\n",
    "\n",
    "sv_dir = mask_name = 'mask_1988'\n",
    "sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "\n",
    "DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/COU_baseline.csv'\n",
    "metrics_save_path = 'temp_%s_.csv'%'ScaleNAS_Q5_9Slices_Cougar_LNs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # This file is for segmetation metrics evaluation in 3D\n",
    "# Edited by Jingchen around 06/20/2021\n",
    "# This file is after ScaleNAS test which save predition into png images.\n",
    "# This file load png images as predicted contours in 2D\n",
    "# load cache pkl as gold-standard contours in 2D\n",
    "# The stack 2D based on dicom-header to get 3D\n",
    "# Evaluate 3D metics of dice, IoU, over-segmetation, and under-segmetation\n",
    "# \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import _init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from utils_test import *\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, batchname = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                save_pred(pred, sv_path, batchname)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d images' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached gt_roidb from %s ./cache/Cougar302_80pts_test_gt_roidb.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/fast-data/mjc/envs/Lesions/lib/python3.6/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== 0\n",
      "======================================== 500\n",
      "======================================== 1000\n",
      "======================================== 1500\n",
      "======================================== 2000\n",
      "======================================== 2500\n",
      "======================================== 3000\n",
      "======================================== 3500\n",
      "======================================== 4000\n",
      "======================================== 4500\n",
      "======================================== 5000\n",
      "======================================== 5500\n",
      "======================================== 6000\n",
      "======================================== 6500\n",
      "======================================== 7000\n",
      "======================================== 7500\n",
      "======================================== 8000\n",
      "======================================== 8500\n",
      "======================================== 9000\n",
      "======================================== 9500\n",
      "======================================== 10000\n",
      "======================================== 10500\n",
      "======================================== 11000\n",
      "======================================== 11500\n",
      "======================================== 12000\n",
      "======================================== 12500\n",
      "======================================== 13000\n",
      "======================================== 13500\n",
      "======================================== 14000\n",
      "======================================== 14500\n",
      "======================================== 15000\n",
      "======================================== 15500\n",
      "======================================== 16000\n",
      "======================================== 16500\n",
      "======================================== 17000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Loading cached gt_roidb from %s', cache_filepath)\n",
    "with open(cache_filepath, 'rb') as fp:\n",
    "    cached_roidb = pickle.load(fp)\n",
    "    \n",
    "roidb = cached_roidb\n",
    "\n",
    "from utils_test import __get_annotation__\n",
    "\n",
    "all_boxes = [ [ np.zeros((0,5),dtype=\"float32\") for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "all_segms = [ [ [] for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "\n",
    "for i in range(len(roidb)):\n",
    "    if i%500==0:\n",
    "        print('='*40,i)\n",
    "\n",
    "    one = roidb[i]\n",
    "    onename = one['image']\n",
    "    pred_im = Image.open(os.path.join(sv_path, convert_name(onename) ))\n",
    "    pred = np.array(pred_im)\n",
    "    for j in range(cfg.DATASET.NUM_CLASSES):\n",
    "        mask = np.asarray( pred==j , dtype=np.uint8)\n",
    "        if np.sum(mask > 0) <= 3 :\n",
    "            continue\n",
    "        segmentation, bbox, area = __get_annotation__(mask , xywh = False , bbox_score=True)\n",
    "        if segmentation and bbox:\n",
    "            all_segms[j][i] = segmentation\n",
    "            all_boxes[j][i] = bbox\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_CT = {}\n",
    "for i , aroidb in enumerate(roidb):\n",
    "    dicom_path , png_name = os.path.split(aroidb['image'])\n",
    "    slice_no , _= os.path.splitext(png_name)\n",
    "    slice_no = int(slice_no)\n",
    "    if slice_no != aroidb['slice_no']:\n",
    "        print(dicom_path,slice_no,aroidb['slice_no'])\n",
    "\n",
    "    segmentations = {}\n",
    "    bboxes = {}\n",
    "    for j in site_list:\n",
    "        segmentations[j] = all_segms[j][i]\n",
    "        bboxes[j] = all_boxes[j][i]\n",
    "\n",
    "    if dicom_path not in D_CT:\n",
    "        D_CT[dicom_path] = {}\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "    else:\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "if DL_info[-4:]=='.csv':\n",
    "    df = pd.read_csv(DL_info)\n",
    "else:\n",
    "    df = pd.read_excel(DL_info)\n",
    "\n",
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instence should be str or list')\n",
    "\n",
    "pd_str_replace(df, ['Image File Path' , 'Contour File Path'], \"X:\" , \"/mnt/W-drive\")\n",
    "pd_str_replace(df, ['Image File Path' , 'Contour File Path'], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/W-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/W-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Contour File Path'], \"/mnt/W-drive/ConvWeasisToRaw\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "\n",
    "\n",
    "sys.path.append('/mnt/fast-data/mjc/DeepLesion/Codes/CollectData/')\n",
    "from print_weasis_raw_data import WeasisRawDataPrinter\n",
    "from read_weasis_raw_data import WeasisRawFileReader\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "D_dir2header_df = {}\n",
    "\n",
    "sys.path.append('/mnt/fast-disk1/mjc/utils_codes/')\n",
    "from utils_ct import get_dicom_header_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_site(location , site_list):\n",
    "    for i in site_list:\n",
    "        if location == ix2labelname(i):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "2 3\n",
      "4 5\n",
      "9 10\n",
      "32 30\n",
      "55 50\n",
      "108 100\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ImageOrientationPatient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0c3f5721fee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dicom_header_df\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image File Path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0minstanceNumber_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mD_z_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstanceNumber2Matrix_z_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstanceNumber_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f05f38896fd6>\u001b[0m in \u001b[0;36mget_dicom_header_df\u001b[0;34m(image_dir, labels)\u001b[0m\n\u001b[1;32m     88\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mdf_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"InstanceNumber\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ImageOrientationPatient'"
     ]
    }
   ],
   "source": [
    "from utils_metrics_3d import *\n",
    "Metrics_vol = []\n",
    "Missed_vol = []\n",
    "previous_CT_ss = ''\n",
    "for _,row in df.iterrows():\n",
    "    if not compare_site(row.Location , site_list):\n",
    "#         only calculate one lesion site\n",
    "        continue\n",
    "\n",
    "\n",
    "    df_image = get_dicom_header_df( row['Image File Path'] )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "    reader = WeasisRawFileReader()\n",
    "    weasis_raw_data = reader.read_weasis_raw_file(row['Contour File Path'])\n",
    "\n",
    "    ss = row['Image File Path']\n",
    "    ss = ss.replace('/Inputs/' , '/Pngs/')\n",
    "    if ss not in D_CT:\n",
    "        print(ss , 'not in D_CT and skip it')\n",
    "        continue\n",
    "\n",
    "    mask_vol = initialize_mask_vol(weasis_raw_data , D_z_index)\n",
    "\n",
    "    slice_list = weasis_raw_data.get_instance_number_array()\n",
    "    for j, one in enumerate(slice_list):\n",
    "        file_name = InstanceNumber2file_name(df_image, one)\n",
    "        file_name = os.path.join( row['Image File Path'] , file_name)   \n",
    "        mask = weasis_raw_data.get_mask_image_2d(j)\n",
    "        mask_vol[D_z_index[one]] = mask\n",
    "\n",
    "    if ss != previous_CT_ss:\n",
    "        oneCT = D_CT[ss]\n",
    "        vol_gt , vol_pred = get_gt_and_pred_vols( oneCT, site_list, mask_vol.shape, D_z_index, union_mask=False )\n",
    "        previous_CT_ss = ss\n",
    "    hit = vols_seg_results(mask_vol , vol_pred, CTname=row['Contour File Path'], gt_keep_largest=1)\n",
    "    Metrics_vol.extend(hit)\n",
    "    \n",
    "    _n = len(Metrics_vol)\n",
    "    if _n%100==0 or _n in [1,3,5,10,30,50]:\n",
    "        print(_, _n)\n",
    "        df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                                  columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                             'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                             'area_gt','area_pred','intersection','union']) \n",
    "        df_metrics.to_csv(metrics_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metrics.to_csv(metrics_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Select                                                                5\n",
       "PatientID                                           COU-AA-302_88982524\n",
       "PatientName                                         COU-AA-302_88982524\n",
       "StudyDate                                                    2012-07-27\n",
       "User ID                                                          pg2725\n",
       "Tumor QA State                                                        3\n",
       "Tumor Label                                                           1\n",
       "Location                                                      pelvic LN\n",
       "Uni                                                             27.8853\n",
       "Perp                                                            18.2406\n",
       "Bi                                                              508.645\n",
       "Volume                                                          6007.15\n",
       "Update Date Time                                    2021-12-08 16:16:11\n",
       "Raw File Name         pg2725_COU-AA-302_88982524_2012-07-27_S0002_T0...\n",
       "Tumor Instance UID                 2c417c79-59d3-4eae-b6c8-593742e8099b\n",
       "Image File Path       /mnt/fast-disk1/mjc/AutoRecist/Inputs/COU-AA-3...\n",
       "Contour File Path     /mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeas...\n",
       "Name: 166, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cougar302_80pts_test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>igt</th>\n",
       "      <th>merge</th>\n",
       "      <th>#gt</th>\n",
       "      <th>#pred</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>over_seg</th>\n",
       "      <th>under_seg</th>\n",
       "      <th>area_gt</th>\n",
       "      <th>area_pred</th>\n",
       "      <th>intersection</th>\n",
       "      <th>union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.353333</td>\n",
       "      <td>0.273646</td>\n",
       "      <td>0.383968</td>\n",
       "      <td>1.944692</td>\n",
       "      <td>0.437850</td>\n",
       "      <td>4315.913333</td>\n",
       "      <td>8217.260000</td>\n",
       "      <td>2556.700000</td>\n",
       "      <td>9976.473333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.180107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.145785</td>\n",
       "      <td>0.219632</td>\n",
       "      <td>0.270168</td>\n",
       "      <td>5.663466</td>\n",
       "      <td>0.374270</td>\n",
       "      <td>5918.768126</td>\n",
       "      <td>13744.120806</td>\n",
       "      <td>4214.592322</td>\n",
       "      <td>14419.842711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>437.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>528.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.079393</td>\n",
       "      <td>0.147058</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.102258</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>765.750000</td>\n",
       "      <td>379.500000</td>\n",
       "      <td>1782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.245801</td>\n",
       "      <td>0.394601</td>\n",
       "      <td>0.525443</td>\n",
       "      <td>0.296913</td>\n",
       "      <td>2601.000000</td>\n",
       "      <td>3187.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>5602.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.448861</td>\n",
       "      <td>0.619604</td>\n",
       "      <td>1.718671</td>\n",
       "      <td>0.818277</td>\n",
       "      <td>4869.000000</td>\n",
       "      <td>9611.000000</td>\n",
       "      <td>3183.750000</td>\n",
       "      <td>12346.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.639719</td>\n",
       "      <td>0.780273</td>\n",
       "      <td>7.403893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14230.800000</td>\n",
       "      <td>31120.750000</td>\n",
       "      <td>8542.300000</td>\n",
       "      <td>36810.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.803707</td>\n",
       "      <td>0.891172</td>\n",
       "      <td>63.490818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45092.000000</td>\n",
       "      <td>87738.000000</td>\n",
       "      <td>29804.000000</td>\n",
       "      <td>92584.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              igt  merge    #gt       #pred   iou_score  dice_score  \\\n",
       "count  150.000000  150.0  150.0  150.000000  150.000000  150.000000   \n",
       "mean     1.033333    0.0    1.0   16.353333    0.273646    0.383968   \n",
       "std      0.180107    0.0    0.0    7.145785    0.219632    0.270168   \n",
       "min      1.000000    0.0    1.0    5.000000    0.000000    0.000000   \n",
       "5%       1.000000    0.0    1.0    5.450000    0.000000    0.000000   \n",
       "25%      1.000000    0.0    1.0   11.000000    0.079393    0.147058   \n",
       "50%      1.000000    0.0    1.0   15.000000    0.245801    0.394601   \n",
       "75%      1.000000    0.0    1.0   23.000000    0.448861    0.619604   \n",
       "95%      1.000000    0.0    1.0   29.000000    0.639719    0.780273   \n",
       "max      2.000000    0.0    1.0   33.000000    0.803707    0.891172   \n",
       "\n",
       "         over_seg   under_seg       area_gt     area_pred  intersection  \\\n",
       "count  150.000000  150.000000    150.000000    150.000000    150.000000   \n",
       "mean     1.944692    0.437850   4315.913333   8217.260000   2556.700000   \n",
       "std      5.663466    0.374270   5918.768126  13744.120806   4214.592322   \n",
       "min      0.000000    0.000000    179.000000      0.000000      0.000000   \n",
       "5%       0.000000    0.017847    437.550000      0.000000      0.000000   \n",
       "25%      0.061077    0.102258   1192.000000    765.750000    379.500000   \n",
       "50%      0.525443    0.296913   2601.000000   3187.000000   1192.000000   \n",
       "75%      1.718671    0.818277   4869.000000   9611.000000   3183.750000   \n",
       "95%      7.403893    1.000000  14230.800000  31120.750000   8542.300000   \n",
       "max     63.490818    1.000000  45092.000000  87738.000000  29804.000000   \n",
       "\n",
       "              union  \n",
       "count    150.000000  \n",
       "mean    9976.473333  \n",
       "std    14419.842711  \n",
       "min      195.000000  \n",
       "5%       528.150000  \n",
       "25%     1782.000000  \n",
       "50%     5602.500000  \n",
       "75%    12346.500000  \n",
       "95%    36810.650000  \n",
       "max    92584.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(name)\n",
    "df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                          columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                     'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                     'area_gt','area_pred','intersection','union']) \n",
    "df_metrics.describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics.to_csv('%s_metrics_vol.csv'%name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_lesions)",
   "language": "python",
   "name": "conda_lesions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

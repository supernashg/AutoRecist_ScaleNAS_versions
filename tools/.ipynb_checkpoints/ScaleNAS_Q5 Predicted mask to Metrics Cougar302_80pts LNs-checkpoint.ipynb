{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to load predicted mask for hard-disk and calculate Segmentation evaluation metics.\n",
    "predicted mask is the output of ScaleNASv2 Test and save predicted mask.ipynb\n",
    "\n",
    "cp -v /mnt/fast-data/mjc/AutoRECIST/Codes/ScaleNAS/ScaleNASv1/tools/utils_test.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # This file is for segmetation metrics evaluation in 3D\n",
    "# Edited by Jingchen around 06/20/2021\n",
    "# This file is after ScaleNAS test which save predition into png images.\n",
    "# This file load png images as predicted contours in 2D\n",
    "# load cache pkl as gold-standard contours in 2D\n",
    "# The stack 2D based on dicom-header to get 3D\n",
    "# Evaluate 3D metics of dice, IoU, over-segmetation, and under-segmetation\n",
    "# \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import _init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from utils_test import *\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, batchname = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                save_pred(pred, sv_path, batchname)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d images' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached gt_roidb from %s ./cache/Cougar302_80pts_test_gt_roidb.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/fast-data/mjc/envs/Lesions/lib/python3.6/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== 0\n",
      "======================================== 500\n",
      "======================================== 1000\n",
      "======================================== 1500\n",
      "FROC:FP in no-lesion-images:  44\n",
      "========================================\n",
      "Recall@0.2=24.92%\n",
      "Mean FROC is 24.92\n",
      "========================================\n",
      "FROC:FP in no-lesion-images:  44\n"
     ]
    }
   ],
   "source": [
    "site_ix =14\n",
    "site_list = [2,4,6,10,11,14,17] # LN list\n",
    "\n",
    "cache_path = './cache/'\n",
    "name = 'Cougar302_80pts_test'\n",
    "# name = 'lesion_train'\n",
    "\n",
    "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\n",
    "print('Loading cached gt_roidb from %s', cache_filepath)\n",
    "with open(cache_filepath, 'rb') as fp:\n",
    "    cached_roidb = pickle.load(fp)\n",
    "    \n",
    "roidb = cached_roidb\n",
    "\n",
    "\n",
    "from utils_test import __get_annotation__\n",
    "\n",
    "sv_dir = mask_name = 'mask_1514'\n",
    "sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "\n",
    "all_boxes = [ [ np.zeros((0,5),dtype=\"float32\") for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "all_segms = [ [ [] for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "\n",
    "for i in range(len(roidb)):\n",
    "    if i%500==0:\n",
    "        print('='*40,i)\n",
    "\n",
    "    one = roidb[i]\n",
    "    onename = one['image']\n",
    "    pred_im = Image.open(os.path.join(sv_path, convert_name(onename) ))\n",
    "    pred = np.array(pred_im)\n",
    "    for j in range(cfg.DATASET.NUM_CLASSES):\n",
    "        mask = np.asarray( pred==j , dtype=np.uint8)\n",
    "        if np.sum(mask > 0) <= 3 :\n",
    "            continue\n",
    "        segmentation, bbox, area = __get_annotation__(mask , xywh = False , bbox_score=True)\n",
    "        if segmentation and bbox:\n",
    "            all_segms[j][i] = segmentation\n",
    "            all_boxes[j][i] = bbox\n",
    "\n",
    "\n",
    "gt_boxes = get_gt_boxes(cached_roidb,site_ix)\n",
    "avgFP=[0.5,1,2,3,4,8,16,32,64]\n",
    "iou_th=0.5\n",
    "\n",
    "stack_box = all_boxes[site_ix]\n",
    "result, valid_avgFP = sens_at_FP(stack_box, gt_boxes, avgFP, iou_th)\n",
    "print('='*40)\n",
    "for recall,fp in zip(result,valid_avgFP):\n",
    "    print('Recall@%.1f=%.2f%%' % (fp, recall*100))\n",
    "#TODO: when num of valid_avgFP < 6,is FROC correct?\n",
    "print('Mean FROC is %.2f'% np.mean(np.array(result[:6])*100))\n",
    "print('='*40)\n",
    "\n",
    "\n",
    "sens, fp_per_img, scores_th = FROC(stack_box, gt_boxes, iou_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([6, 7, 8, 9]),)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "D_CT = {}\n",
    "for i , aroidb in enumerate(roidb):\n",
    "    dicom_path , png_name = os.path.split(aroidb['image'])\n",
    "    slice_no , _= os.path.splitext(png_name)\n",
    "    slice_no = int(slice_no)\n",
    "    if slice_no != aroidb['slice_no']:\n",
    "        print(dicom_path,slice_no,aroidb['slice_no'])\n",
    "\n",
    "    segmentations = {}\n",
    "    bboxes = {}\n",
    "    for j in site_list:\n",
    "        segmentations[j] = all_segms[j][i]\n",
    "        bboxes[j] = all_boxes[j][i]\n",
    "\n",
    "    if dicom_path not in D_CT:\n",
    "        D_CT[dicom_path] = {}\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "    else:\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AUTO_RECIST CIA-LAB Image and Contour 2020-10-01.xlsx'\n",
    "# json_name = 'CUIMC20201027.json'\n",
    "\n",
    "# DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AMGEN_20020408_CIA-LAB_Image_And_Contour_2020-10-21.xlsx'\n",
    "# json_name = 'AMGEN_20020408_20201027.json'\n",
    "\n",
    "# DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AMGEN_PRIME_CIA-LAB_Image_And_Contour_2020-10-21.xlsx'\n",
    "# json_name = 'AMGEN_PRIME_20201027.json'\n",
    "\n",
    "DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/Prepare 100 Cougar 302 annotated cases for Jingchen.xlsx'\n",
    "df = pd.read_excel(DL_info)\n",
    "\n",
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instence should be str or list')\n",
    "\n",
    "pd_str_replace(df, ['Image File Path' , 'Contour File Path'], \"X:\" , \"/mnt/W-drive\")\n",
    "pd_str_replace(df, ['Image File Path' , 'Contour File Path'], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/W-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/W-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Contour File Path'], \"/mnt/W-drive/ConvWeasisToRaw\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "sys.path.append('/mnt/fast-data/mjc/DeepLesion/Codes/CollectData/')\n",
    "\n",
    "from print_weasis_raw_data import WeasisRawDataPrinter\n",
    "from read_weasis_raw_data import WeasisRawFileReader\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "data_path = \"\"\n",
    "metadata_path = \"/mnt/fast-data/mjc/AutoRECIST/Outputs/Dicom_header\"\n",
    "if not os.path.exists(metadata_path):\n",
    "    os.mkdir(metadata_path)\n",
    "\n",
    "\n",
    "D_dir2header_df = {}\n",
    "\n",
    "\n",
    "def get_dicom_header_df(image_dir , labels = []):\n",
    "    global D_dir2header_df\n",
    "    if image_dir in D_dir2header_df:\n",
    "        return D_dir2header_df[image_dir]\n",
    "\n",
    "    # image_dir = row['Image File Path']\n",
    "\n",
    "\n",
    "    labels = ['ImageName','InstanceNumber',\n",
    "            'BitsAllocated', 'BitsStored', 'Columns', 'HighBit', \n",
    "            'ImageOrientationPatient_0', 'ImageOrientationPatient_1', 'ImageOrientationPatient_2',\n",
    "            'ImageOrientationPatient_3', 'ImageOrientationPatient_4', 'ImageOrientationPatient_5',\n",
    "            'ImagePositionPatient_0', 'ImagePositionPatient_1', 'ImagePositionPatient_2',\n",
    "            'Modality', 'PatientID', 'PhotometricInterpretation', 'PixelRepresentation',\n",
    "            'PixelSpacing_0', 'PixelSpacing_1', 'RescaleIntercept', 'RescaleSlope', 'Rows', 'SOPInstanceUID',\n",
    "            'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID', 'StudyInstanceUID', \n",
    "            'WindowCenter', 'WindowWidth', \n",
    "        ] if not labels else labels\n",
    "\n",
    "    data = {l: [] for l in labels}\n",
    "    \n",
    "    ctList = os.listdir(image_dir)\n",
    "    ctList.sort()\n",
    "\n",
    "    for image in ctList:\n",
    "        if '.dcm' not in image:\n",
    "            continue\n",
    "        if os.path.getsize(os.path.join(image_dir, image)) < 5*1024:\n",
    "            print('%s size < 5kb skiped!'%os.path.join(image_dir, image) )\n",
    "            continue\n",
    "        data[\"ImageName\"].append(image)\n",
    "\n",
    "        ds = pydicom.dcmread(os.path.join(image_dir, image))\n",
    "        for metadata in ds.dir():\n",
    "            if metadata not in data and metadata not in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                continue\n",
    "            if metadata != \"PixelData\":\n",
    "                metadata_values = getattr(ds, metadata)\n",
    "                if type(metadata_values) == pydicom.multival.MultiValue and metadata not in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                    for i, v in enumerate(metadata_values):\n",
    "                        data[f\"{metadata}_{i}\"].append(v)  \n",
    "                else:\n",
    "                    if type(metadata_values) == pydicom.multival.MultiValue and metadata in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                        data[metadata].append(metadata_values[0])\n",
    "                    else:\n",
    "                        data[metadata].append(metadata_values)\n",
    "\n",
    "    df_image = pd.DataFrame(data).set_index(\"InstanceNumber\")\n",
    "    D_dir2header_df[image_dir] = df_image\n",
    "    return df_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Delete df row 76\n",
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "def compare_site(location , site_list):\n",
    "    for i in site_list:\n",
    "        if location == ix2labelname(i):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "from utils_metrics_3d import *\n",
    "Metrics_vol = []\n",
    "Missed_vol = []\n",
    "previous_CT_ss = ''\n",
    "for _,row in df.iterrows():\n",
    "    if _ in [76]:\n",
    "        print('Delete df row {}'.format(_))\n",
    "        continue\n",
    "\n",
    "    if _%100==0 or _<10:\n",
    "        print(_)\n",
    "    if not compare_site(row.Location , site_list):\n",
    "#         only calculate one lesion site\n",
    "        continue\n",
    "    \n",
    "    ## convert png numbers to dicom slice numbers.\n",
    "    df_image = get_dicom_header_df( row['Image File Path'] )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "    reader = WeasisRawFileReader()\n",
    "    weasis_raw_data = reader.read_weasis_raw_file(row['Contour File Path'])\n",
    "\n",
    "    ss = row['Image File Path']\n",
    "    ss = ss.replace('/Inputs/' , '/Pngs/')\n",
    "    if ss not in D_CT:\n",
    "        print(ss , 'not in D_CT')\n",
    "\n",
    "    mask_vol = initialize_mask_vol(weasis_raw_data , D_z_index)\n",
    "\n",
    "    slice_list = weasis_raw_data.get_instance_number_array()\n",
    "    for j, one in enumerate(slice_list):\n",
    "        file_name = InstanceNumber2file_name(df_image, one)\n",
    "        file_name = os.path.join( row['Image File Path'] , file_name)   \n",
    "        mask = weasis_raw_data.get_mask_image_2d(j)\n",
    "        mask_vol[D_z_index[one]] = mask\n",
    "\n",
    "    if ss != previous_CT_ss:\n",
    "        oneCT = D_CT[ss]\n",
    "        vol_gt , vol_pred = get_gt_and_pred_vols( oneCT, site_list, mask_vol.shape, D_z_index, union_mask=False )\n",
    "        previous_CT_ss = ss\n",
    "    hit = vols_seg_results(mask_vol , vol_pred, CTname=ss, gt_keep_largest=1)\n",
    "    Metrics_vol.extend(hit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cougar302_80pts_test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>igt</th>\n",
       "      <th>merge</th>\n",
       "      <th>#gt</th>\n",
       "      <th>#pred</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>over_seg</th>\n",
       "      <th>under_seg</th>\n",
       "      <th>area_gt</th>\n",
       "      <th>area_pred</th>\n",
       "      <th>intersection</th>\n",
       "      <th>union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.981132</td>\n",
       "      <td>0.303373</td>\n",
       "      <td>0.422396</td>\n",
       "      <td>0.875082</td>\n",
       "      <td>0.535703</td>\n",
       "      <td>4922.452830</td>\n",
       "      <td>5628.268868</td>\n",
       "      <td>2259.575472</td>\n",
       "      <td>8291.146226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.499362</td>\n",
       "      <td>0.219492</td>\n",
       "      <td>0.260194</td>\n",
       "      <td>2.097429</td>\n",
       "      <td>0.320332</td>\n",
       "      <td>6661.119752</td>\n",
       "      <td>10310.721373</td>\n",
       "      <td>3805.788303</td>\n",
       "      <td>12184.536522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046741</td>\n",
       "      <td>605.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>693.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.119748</td>\n",
       "      <td>0.213883</td>\n",
       "      <td>0.030254</td>\n",
       "      <td>0.238917</td>\n",
       "      <td>1211.250000</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>354.500000</td>\n",
       "      <td>1636.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.271039</td>\n",
       "      <td>0.426484</td>\n",
       "      <td>0.141060</td>\n",
       "      <td>0.545092</td>\n",
       "      <td>3004.500000</td>\n",
       "      <td>1595.500000</td>\n",
       "      <td>989.500000</td>\n",
       "      <td>3951.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.456464</td>\n",
       "      <td>0.626801</td>\n",
       "      <td>0.604223</td>\n",
       "      <td>0.817844</td>\n",
       "      <td>5583.750000</td>\n",
       "      <td>5774.250000</td>\n",
       "      <td>2713.250000</td>\n",
       "      <td>8363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.681912</td>\n",
       "      <td>0.810877</td>\n",
       "      <td>4.874221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17051.400000</td>\n",
       "      <td>24076.850000</td>\n",
       "      <td>8094.050000</td>\n",
       "      <td>29511.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.791008</td>\n",
       "      <td>0.883311</td>\n",
       "      <td>15.988153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44658.000000</td>\n",
       "      <td>70282.000000</td>\n",
       "      <td>31006.000000</td>\n",
       "      <td>78041.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         igt  merge    #gt       #pred   iou_score  dice_score    over_seg  \\\n",
       "count  212.0  212.0  212.0  212.000000  212.000000  212.000000  212.000000   \n",
       "mean     1.0    0.0    1.0   12.981132    0.303373    0.422396    0.875082   \n",
       "std      0.0    0.0    0.0   10.499362    0.219492    0.260194    2.097429   \n",
       "min      1.0    0.0    1.0    1.000000    0.000000    0.000000    0.000000   \n",
       "5%       1.0    0.0    1.0    2.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.0    0.0    1.0    6.000000    0.119748    0.213883    0.030254   \n",
       "50%      1.0    0.0    1.0   10.000000    0.271039    0.426484    0.141060   \n",
       "75%      1.0    0.0    1.0   17.000000    0.456464    0.626801    0.604223   \n",
       "95%      1.0    0.0    1.0   34.000000    0.681912    0.810877    4.874221   \n",
       "max      1.0    0.0    1.0   47.000000    0.791008    0.883311   15.988153   \n",
       "\n",
       "        under_seg       area_gt     area_pred  intersection         union  \n",
       "count  212.000000    212.000000    212.000000    212.000000    212.000000  \n",
       "mean     0.535703   4922.452830   5628.268868   2259.575472   8291.146226  \n",
       "std      0.320332   6661.119752  10310.721373   3805.788303  12184.536522  \n",
       "min      0.003826    396.000000      0.000000      0.000000    396.000000  \n",
       "5%       0.046741    605.200000      0.000000      0.000000    693.850000  \n",
       "25%      0.238917   1211.250000    558.000000    354.500000   1636.000000  \n",
       "50%      0.545092   3004.500000   1595.500000    989.500000   3951.000000  \n",
       "75%      0.817844   5583.750000   5774.250000   2713.250000   8363.000000  \n",
       "95%      1.000000  17051.400000  24076.850000   8094.050000  29511.950000  \n",
       "max      1.000000  44658.000000  70282.000000  31006.000000  78041.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[54]:\n",
    "\n",
    "print(name)\n",
    "df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                          columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                     'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                     'area_gt','area_pred','intersection','union']) \n",
    "df_metrics.describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics.to_csv('%s_lung_seg_metrics_vol_2021116.csv'%name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SHOW_LABEL = True\n",
    "SHOW_BOX = False\n",
    "SHOW_MASK = True\n",
    "SHOW_UNION_MASK= False\n",
    "SHOW_MASK_LABEL = True\n",
    "SHOW_GT_MASK = True\n",
    "\n",
    "# site_list = range(1,len(all_boxes))\n",
    "site_list = range(1,22) #8 is liver\n",
    "savepath = '/mnt/fast-disk1/mjc/AutoRecist/Outputs/ScaleNAS_Q5/%s/Images_%s_allsites'%(mask_name,name)\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "for i , aroidb in enumerate(roidb):\n",
    "\n",
    "    image_path = os.path.join(aroidb['image'])\n",
    "    [HU1, HU2 ] = aroidb['windows']\n",
    "\n",
    "    image = load_image(image_path, HU1, HU2)\n",
    "    height,width = image.shape\n",
    "#     plt.imshow(image)\n",
    "    image = np.dstack((image,image,image))\n",
    "    if SHOW_GT_MASK:\n",
    "        ix = [a for a,b in enumerate(aroidb['gt_classes']) if int(b) in site_list]\n",
    "        contours = [ aroidb['segms'][int(kk)] for kk in ix ]\n",
    "        if not contours:\n",
    "            continue\n",
    "        colors = [0,0,255]\n",
    "        for c in contours:\n",
    "            c = [ np.int64( np.reshape(c,(-1,2)) ) for c in c]\n",
    "            if len(c):\n",
    "                image = cv2.drawContours(image, c, -1, colors, 1)\n",
    "#             c = np.reshape(c,(-1,2))\n",
    "#             if c.shape[0]:\n",
    "#                 image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "    \n",
    "    if SHOW_MASK:\n",
    "        for j in site_list:\n",
    "            contours = all_segms[j][i]\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            label = ix2labelname(j)\n",
    "            for c in contours:\n",
    "                c = np.reshape(c,(-1,2))\n",
    "                if c.shape[0]:\n",
    "                    image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "                    if SHOW_MASK_LABEL:\n",
    "                        x,y,_,_ =ploy2boxes(c)\n",
    "                        template = \"{}\"\n",
    "                        if len(label)>=9:\n",
    "                            label=label[:3]+label[-3:]\n",
    "            \n",
    "                        s = template.format(label)\n",
    "                        cv2.putText(\n",
    "                            image, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, .5, colors, 1\n",
    "                        )  \n",
    "    \n",
    "\n",
    "    if SHOW_UNION_MASK:\n",
    "        for j in site_list:\n",
    "            contours = all_segms[j][i]\n",
    "            cc = [ contour.flatten().tolist() for contour in contours if len(contour)!=0]\n",
    "            contours = union_ploys(cc , height, width)\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            label = ix2labelname(j)\n",
    "\n",
    "            for c in contours:\n",
    "                c = np.reshape(c,(-1,2))\n",
    "                if c.shape[0]:\n",
    "                    image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "                    if SHOW_MASK_LABEL:\n",
    "                        x,y,_,_ =ploy2boxes(c)\n",
    "                        template = \"{}\"\n",
    "                        if len(label)>=9:\n",
    "                            label=label[:3]+label[-3:]\n",
    "            \n",
    "                        s = template.format(label)\n",
    "                        cv2.putText(\n",
    "                            image, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, .5, colors, 1\n",
    "                        )        \n",
    "\n",
    "    if SHOW_BOX:\n",
    "        for j in site_list:\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            for box in all_boxes[j][i]:\n",
    "                \n",
    "                if box.shape[0]:\n",
    "                    top_left, bottom_right = box[:2].tolist(), box[2:4].tolist()\n",
    "                    image = cv2.rectangle(image, tuple(np.int64(top_left).tolist()), tuple(np.int64(bottom_right).tolist()), colors, 1)\n",
    "                \n",
    "            \n",
    "    \n",
    "    cv2.imwrite( os.path.join(savepath, '%06d.png'%aroidb['id'] ), image )\n",
    "print('saved {} images to {}'.format(i+1,savepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd  /Users/jingchen/OneDrive/OneDrive - cumc.columbia.edu/AutoRECIST/ImageResults/ScaleNAS_Q5/mask_1514/\n",
    "rsync -avzh --progress jm4669@radio-gpu.cpmc.columbia.edu:/mnt/fast-disk1/mjc/AutoRecist/Outputs/ScaleNAS_Q5/mask_1514/Images_Cougar302_80pts_test_allsites . \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "case = 1668\n",
    "pname = 'BAILN'\n",
    "for aroidb in roidb:\n",
    "    if pname in aroidb['image']:\n",
    "        print(aroidb['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.iloc[76]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_lesions)",
   "language": "python",
   "name": "conda_lesions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

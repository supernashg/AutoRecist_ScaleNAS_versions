{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/')\n",
    "\n",
    "import weasis_raw_data_api as wr\n",
    "sys.path.append('/mnt/fast-disk1/mjc/utils_codes/')\n",
    "from utils_test import *\n",
    "from utils_metrics_3d import *\n",
    "\n",
    "D_dir2header_df = {}\n",
    "def get_dicom_header_df(image_dir , labels = []):\n",
    "    global D_dir2header_df\n",
    "    if image_dir in D_dir2header_df:\n",
    "        return D_dir2header_df[image_dir]\n",
    "\n",
    "    # image_dir = row['Image File Path']\n",
    "\n",
    "\n",
    "    labels = ['ImageName','InstanceNumber',\n",
    "            'BitsAllocated', 'BitsStored', 'Columns', 'HighBit', \n",
    "            'ImageOrientationPatient_0', 'ImageOrientationPatient_1', 'ImageOrientationPatient_2',\n",
    "            'ImageOrientationPatient_3', 'ImageOrientationPatient_4', 'ImageOrientationPatient_5',\n",
    "            'ImagePositionPatient_0', 'ImagePositionPatient_1', 'ImagePositionPatient_2',\n",
    "            'Modality', 'PatientID', 'PhotometricInterpretation', 'PixelRepresentation',\n",
    "            'PixelSpacing_0', 'PixelSpacing_1', 'RescaleIntercept', 'RescaleSlope', 'Rows', 'SOPInstanceUID',\n",
    "            'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID', 'StudyInstanceUID', \n",
    "            'WindowCenter', 'WindowWidth', \n",
    "        ] if not labels else labels\n",
    "\n",
    "    data = {l: [] for l in labels}\n",
    "    \n",
    "    ctList = os.listdir(image_dir)\n",
    "    ctList.sort()\n",
    "\n",
    "    for image in ctList:\n",
    "        if '.dcm' not in image:\n",
    "            continue\n",
    "        if os.path.getsize(os.path.join(image_dir, image)) < 5*1024:\n",
    "            print('%s size < 5kb skiped!'%os.path.join(image_dir, image) )\n",
    "            continue\n",
    "        data[\"ImageName\"].append(image)\n",
    "\n",
    "        ds = pydicom.dcmread(os.path.join(image_dir, image))\n",
    "        for metadata in ds.dir():\n",
    "            if metadata not in data and metadata not in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                continue\n",
    "            if metadata != \"PixelData\":\n",
    "                metadata_values = getattr(ds, metadata)\n",
    "                if type(metadata_values) == pydicom.multival.MultiValue and metadata not in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                    for i, v in enumerate(metadata_values):\n",
    "                        data[f\"{metadata}_{i}\"].append(v)  \n",
    "                else:\n",
    "\n",
    "                    if type(metadata_values) == pydicom.multival.MultiValue and metadata in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                        data[metadata].append(metadata_values[0])\n",
    "                    else:\n",
    "                        \n",
    "                        if metadata in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                            print( 'error of loading key: {}'.format(metadata) )                    \n",
    "                        else:\n",
    "                            data[metadata].append(metadata_values)\n",
    "\n",
    "    df_image = pd.DataFrame(data).set_index(\"InstanceNumber\")\n",
    "    D_dir2header_df[image_dir] = df_image\n",
    "    return df_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        try:\n",
    "            df[col] = df[col].str.replace(ori,new, case = False) \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instance should be str or list')\n",
    "\n",
    "\n",
    "def str_Xdrive2mnt(df_all):\n",
    "    pd_str_replace(df_all, ['Image File Path' , 'Contour File Path'], \"X:\" , \"/mnt/Y-drive\")\n",
    "    pd_str_replace(df_all, ['Image File Path' , 'Contour File Path'], r\"\\\\\" , \"/\")\n",
    "    pd_str_replace(df_all, ['Image File Path'], \"/mnt/Y-drive/ClinicalTrials/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "    pd_str_replace(df_all, ['Image File Path'], \"/mnt/Y-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "    pd_str_replace(df_all, ['Image File Path'], \"/mnt/Y-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "\n",
    "    pd_str_replace(df_all, ['Contour File Path'], \"/mnt/Y-drive/ConvWeasisToRaw/PDS_AUTO_RECIST_Modified_By_Yen\",\n",
    "    \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw/PDS_AUTO_RECIST_Modified_By_Yen\")\n",
    "    pd_str_replace(df_all, ['Contour File Path'], \"/mnt/Y-drive/ConvWeasisToRaw/PDS_AUTO_RECIST\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw/PDS_AUTO_RECIST_RAW\")\n",
    "    pd_str_replace(df_all, ['Contour File Path'], \"/mnt/Y-drive/ConvWeasisToRaw\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "    pd_str_replace(df_all, ['Contour File Path'], \"/mnt/Y-drive/ConvWeasisToMatlab\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "    \n",
    "def get_onect_from_list(df_list , ct):\n",
    "    for i, df in enumerate(df_list):\n",
    "        try:\n",
    "            df_ct = df[ (df[\"Image File Path\"]==ct) & (df['Location'].isin(['liver'])) ]\n",
    "        except KeyError:\n",
    "            df_ct = df[ (df[\"Image File Path\"]==ct)]\n",
    "        if df_ct.shape[0]:\n",
    "            return df_ct , i\n",
    "    print(\"warning! no CT was found\")\n",
    "    return None ,None\n",
    "\n",
    "def raws2mask(raws , D_z_index, mask_vol = None):\n",
    "\n",
    "    for raw in raws:\n",
    "\n",
    "        radiologist_raw = wr.read(raw)\n",
    "        slice_list = radiologist_raw.get_instance_number_array()\n",
    "        if mask_vol is None:\n",
    "            mask_vol = initialize_mask_vol(radiologist_raw , D_z_index)\n",
    "        for j, one in enumerate(slice_list):\n",
    "            mask = radiologist_raw.get_mask_image(j)\n",
    "            mask_vol[D_z_index[one]] += mask\n",
    "    return mask_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Comments Patient ID  \\\n",
      "0                         minor revision      BAIJC   \n",
      "1                         minor revision      BAIJD   \n",
      "2    minor revision(lesion not in liver)      BAIJG   \n",
      "3                         minor revision      BAIJL   \n",
      "4                         major revision      BAIJM   \n",
      "..                                   ...        ...   \n",
      "148                       minor revision      BAITS   \n",
      "149                       minor revision      BAITU   \n",
      "150                       minor revision      BAITV   \n",
      "151                       minor revision      BAITW   \n",
      "152                       major revision      BAITX   \n",
      "\n",
      "                                       Image File Path  \\\n",
      "0    /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "1    /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "2    /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "3    /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "4    /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "..                                                 ...   \n",
      "148  /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "149  /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "150  /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "151  /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "152  /mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20...   \n",
      "\n",
      "    The indexes of benign lesions              Contrast  \\\n",
      "0                             NaN                   YES   \n",
      "1                             NaN                   YES   \n",
      "2                             NaN                   YES   \n",
      "3                             NaN                   YES   \n",
      "4                             NaN                   YES   \n",
      "..                            ...                   ...   \n",
      "148                           NaN  YES - early arterial   \n",
      "149                           NaN                   YES   \n",
      "150                           NaN                   YES   \n",
      "151                           NaN                   YES   \n",
      "152                           NaN                   YES   \n",
      "\n",
      "    Diffuse Change in Liver  #AI_Annotated  #Ori_Radiologist_Annotated  \\\n",
      "0                        NO             10                           6   \n",
      "1                        NO              5                           5   \n",
      "2                        NO              4                           6   \n",
      "3                        NO              3                           5   \n",
      "4                       YES              5                           1   \n",
      "..                      ...            ...                         ...   \n",
      "148                      NO              6                           3   \n",
      "149                      NO              8                           7   \n",
      "150                      NO              3                           3   \n",
      "151                      NO             14                          13   \n",
      "152                     YES             11                           8   \n",
      "\n",
      "     #Yen_Annotated  ToDo Revised_Yen  #lesions  min_Uni  max_Uni Priority  \\\n",
      "0              10.0   NaN         Yes       NaN      NaN      NaN      NaN   \n",
      "1               5.0   NaN         Yes       NaN      NaN      NaN      NaN   \n",
      "2               4.0   NaN         Yes       NaN      NaN      NaN      NaN   \n",
      "3               3.0   NaN         Yes       NaN      NaN      NaN      NaN   \n",
      "4               2.0   NaN         Yes       NaN      NaN      NaN      NaN   \n",
      "..              ...   ...         ...       ...      ...      ...      ...   \n",
      "148             NaN  ToDo         Yes       NaN      NaN      NaN      NaN   \n",
      "149             NaN  ToDo         Yes       NaN      NaN      NaN      NaN   \n",
      "150             NaN  ToDo         Yes       NaN      NaN      NaN      NaN   \n",
      "151             NaN  ToDo         Yes       NaN      NaN      NaN      NaN   \n",
      "152             NaN  ToDo         Yes       NaN      NaN      NaN      NaN   \n",
      "\n",
      "     max_Uni_Yen dataset Column1  \n",
      "0            NaN   Amgen     NaN  \n",
      "1            NaN   Amgen     NaN  \n",
      "2            NaN   Amgen     NaN  \n",
      "3            NaN   Amgen     NaN  \n",
      "4            NaN   Amgen     NaN  \n",
      "..           ...     ...     ...  \n",
      "148          NaN   Amgen     NaN  \n",
      "149          NaN   Amgen     NaN  \n",
      "150          NaN   Amgen     NaN  \n",
      "151          NaN   Amgen     NaN  \n",
      "152          NaN   Amgen     NaN  \n",
      "\n",
      "[153 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "subsetname = 'Amgen'\n",
    "folder = '/mnt/fast-data/mjc/AutoRECIST/Inputs/'\n",
    "\n",
    "df_CTs = pd.read_excel(folder+'AutoRECIST_List_LesionSize_20220602_JM_SingleCTSeries.xlsx')\n",
    "str_Xdrive2mnt(df_CTs)\n",
    "\n",
    "df_CTs = df_CTs[df_CTs['dataset']==subsetname]\n",
    "print(df_CTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fast-disk1/mjc/AutoRecist/Inputs/AMGEN/20020408/BAIJC/D2004_02_27/E20040227/CT/S0002\n"
     ]
    }
   ],
   "source": [
    "df_Yen = pd.read_excel(folder+'PDS_AUTO_RECIST CIA-LAB Testing Dataset Gold Standard_Yen_2022-06-13.xlsx')\n",
    "str_Xdrive2mnt(df_Yen)\n",
    "\n",
    "AI_raw_list = ['ScaleNAS9SlicesAccLiverToRaw_Test353.csv',]\n",
    "df_AIs = []\n",
    "for one in AI_raw_list:\n",
    "    df = pd.read_csv(one)\n",
    "    str_Xdrive2mnt(df)\n",
    "    df_AIs.append(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Metrics_vol = []\n",
    "metrics_save_path = 'Metrics_%s_vs_Yen_%s.csv'%('ScaleNAS9SlicesAccLiver' ,subsetname )\n",
    "CTs = df_CTs[\"Image File Path\"].values.tolist()\n",
    "\n",
    "for ct in CTs:\n",
    "    df_image = get_dicom_header_df( ct )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "\n",
    "    df_ct_Yen = df_Yen[df_Yen[\"Image File Path\"]==ct]\n",
    "    df_ct_AI , dataset_id = get_onect_from_list(df_AIs , ct)\n",
    "    # break\n",
    "    if (df_ct_AI is None):\n",
    "        if df_ct_Yen.shape[0]:\n",
    "            fn = df_ct_Yen.shape[0]\n",
    "            print('{} has {} FNs!'.format(ct , fn))   \n",
    "        continue\n",
    "\n",
    "    if not df_ct_Yen.shape[0]:\n",
    "        fp = df_ct_AI.shape[0]\n",
    "        print( '{} has {} FPs'.format(ct , fp)  )\n",
    "        continue\n",
    "    else:\n",
    "        print(ct)\n",
    "\n",
    "    raws = df_ct_AI[\"Contour File Path\"].values.tolist()\n",
    "    vol_pred = raws2mask(raws , D_z_index, mask_vol = None)\n",
    "    connectivity = 2\n",
    "    from skimage import measure\n",
    "    labels_pred=measure.label(vol_pred,connectivity=connectivity)\n",
    "    l_pred,c_pred = np.unique(labels_pred , return_counts=True)\n",
    "    ix2 = l_pred>0\n",
    "    l_pred = l_pred[ix2] #background pixels are labeled as 0, so we exclude them\n",
    "    c_pred = c_pred[ix2]\n",
    "    if len(l_pred)!= len(raws):\n",
    "        print(\"warning! raws overlaped on {}\".format(ct))\n",
    "\n",
    "\n",
    "    for _ , row in df_ct_Yen.iterrows():\n",
    "\n",
    "        Yen_raw = wr.read(row['Contour File Path'])\n",
    "        gt_vol = initialize_mask_vol(Yen_raw , D_z_index)\n",
    "\n",
    "        slice_list = Yen_raw.get_instance_number_array()\n",
    "        for j, one in enumerate(slice_list):\n",
    "            mask = Yen_raw.get_mask_image(j)\n",
    "            gt_vol[D_z_index[one]] = mask\n",
    "        \n",
    "        hit = vols_seg_results(gt_vol , vol_pred, CTname=row['Contour File Path'], gt_keep_largest=1)\n",
    "        Metrics_vol.extend(hit)\n",
    "\n",
    "        _n = len(Metrics_vol)\n",
    "        if _n%100==0 or _n in [1,2,5,10,30,50]:\n",
    "            df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                                    columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                                'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                                'area_gt','area_pred','intersection','union']) \n",
    "            df_metrics.to_csv(metrics_save_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                        columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                    'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                    'area_gt','area_pred','intersection','union']) \n",
    "df_metrics.to_csv(metrics_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                          columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                     'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                     'area_gt','area_pred','intersection','union']) \n",
    "df_metrics.describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_metrics[df_metrics.dice_score>0.25].describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfinnermerge = pd.merge(df_metrics,df_Yen,how='inner',left_on='file_name' , right_on='Contour File Path')\n",
    "for col in dfinnermerge.columns.tolist():\n",
    "    print(col , len(set(dfinnermerge[col].tolist() )) )\n",
    "\n",
    "\n",
    "\n",
    "pts = dfinnermerge[\"Image File Path\"].values.tolist()\n",
    "FPs = []\n",
    "for onept in list(set(pts)):\n",
    "    df_onept = dfinnermerge[dfinnermerge[\"Image File Path\"]==onept]\n",
    "    assert( min(df_onept[\"#pred\"]) == max(df_onept[\"#pred\"]))\n",
    "    fp = max(df_onept[\"#pred\"])\n",
    "    FPs.append(fp)\n",
    "print(\"=\"*80)\n",
    "print( \"In total, {} CT series; {} AI detections \".format( len(FPs) , sum(FPs) ) )\n",
    "\n",
    "dices = dfinnermerge.dice_score.tolist()\n",
    "\n",
    "for th in [0, 0.1, 0.2, 0.25, 0.5]:\n",
    "    TP = [p>th for p in dices ]\n",
    "    assert( len(TP) == len(dices))\n",
    "    fprate = ( sum(FPs) - sum(TP) ) / len(FPs)\n",
    "    print(f\"sensitivity is {sum(TP)/len(dices):.3f}({sum(TP)}/{len(dices)}) FP-rate is {fprate:.1f} per CT-serie at threshold {th}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subgroup analysis for gt_lesion >=10mm\n",
    "\n",
    "Uni_thresh = 10\n",
    "df_subgroup = dfinnermerge[dfinnermerge['Uni']>=Uni_thresh]\n",
    "df_subgroup.describe([.05, .25, .5, .75, .95])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_subgroup[df_subgroup.dice_score>0.25].describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detection_performance(dfinnermerge):\n",
    "    pts = dfinnermerge[\"Image File Path\"].values.tolist()\n",
    "    FPs = []\n",
    "    for onept in list(set(pts)):\n",
    "        df_onept = dfinnermerge[dfinnermerge[\"Image File Path\"]==onept]\n",
    "        assert( min(df_onept[\"#pred\"]) == max(df_onept[\"#pred\"]))\n",
    "        fp = max(df_onept[\"#pred\"])\n",
    "        FPs.append(fp)\n",
    "    print(\"=\"*80)\n",
    "    print( \"In total, {} CT series; {} AI detections \".format( len(FPs) , sum(FPs) ) )\n",
    "\n",
    "    dices = dfinnermerge.dice_score.tolist()\n",
    "\n",
    "    for th in [0, 0.1, 0.2, 0.25, 0.5]:\n",
    "        TP = [p>th for p in dices ]\n",
    "        assert( len(TP) == len(dices))\n",
    "        fprate = ( sum(FPs) - sum(TP) ) / len(FPs)\n",
    "        print(f\"sensitivity is {sum(TP)/len(dices):.3f}({sum(TP)}/{len(dices)}) FP-rate is {fprate:.1f} per CT-serie at threshold {th}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "detection_performance(df_subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

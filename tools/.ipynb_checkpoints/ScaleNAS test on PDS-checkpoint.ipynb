{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Licensed under the MIT License.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import _init_paths\n",
    "import models\n",
    "import dataset\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.seg_function import validate_seg_wo_loss as validate\n",
    "from core.oneshot_function import calib_bn_seg as calib_bn\n",
    "from utils.utils import get_model_summary\n",
    "from utils.utils import create_logger, FullModel\n",
    "\n",
    "\n",
    "def parse_args(l):\n",
    "    parser = argparse.ArgumentParser(description='Test segmentation network')\n",
    "\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        required=True,\n",
    "                        type=str)\n",
    "    parser.add_argument('opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "    parser.add_argument('--bn_calib',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--mask_path',\n",
    "                        help='the path of a mask.npy',\n",
    "                        default=None,\n",
    "                        type=str)\n",
    "    args = parser.parse_args(l)\n",
    "    update_config(cfg, args)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arglist = ['--cfg', '../experiments/cityscapes/scalenet_seg_w32_test.yaml' ,  \n",
    "           '--bn_calib',\n",
    "           '--mask_path', '../experiments/searched_masks/cityscapes/seg_w32_S1.npy' ,  \n",
    "           'TEST.MODEL_FILE', '../models/pytorch/seg_cityscapes/superscalenet_seg_w32.pth',\n",
    "          'DATASET.ROOT','../data/']\n",
    "\n",
    "\n",
    "args = parse_args(arglist)\n",
    "\n",
    "\n",
    "# cfg.defrost()\n",
    "# cfg.LESION.NUM_IMAGES_3DCE = 1\n",
    "# cfg.TRAIN.DATASETS = ('PDS_AMGEN_PRIME_22Cat_train',)\n",
    "# cfg.MODEL.NUM_CLASSES = 22\n",
    "# cfg.TRAIN.PROPOSAL_FILES = ()\n",
    "# cfg.TRAIN.CROWD_FILTER_THRESH = 0.7\n",
    "# cfg.TRAIN.GT_MIN_AREA = -1\n",
    "# cfg.TRAIN.USE_ADJACENT_LAYER = False\n",
    "# cfg.TRAIN.USE_FLIPPED = True\n",
    "# cfg.TRAIN.USE_Z_FLIPPED = False\n",
    "\n",
    "# # Fraction of minibatch that is labeled foreground (i.e. class > 0)\n",
    "# cfg.TRAIN.FG_FRACTION = 0.25\n",
    "\n",
    "# # Overlap threshold for a ROI to be considered foreground (if >= FG_THRESH)\n",
    "# cfg.TRAIN.FG_THRESH = 0.5\n",
    "\n",
    "# # Overlap threshold for a ROI to be considered background (class = 0 if\n",
    "# # overlap in [LO, HI))\n",
    "# cfg.TRAIN.BG_THRESH_HI = 0.5\n",
    "# cfg.TRAIN.BG_THRESH_LO = 0.0\n",
    "# cfg.MODEL.KEYPOINTS_ON = False\n",
    "# cfg.TRAIN.BBOX_THRESH = 0.5\n",
    "# cfg.MODEL.CLS_AGNOSTIC_BBOX_REG = False\n",
    "# cfg.MODEL.BBOX_REG_WEIGHTS = (10.0, 10.0, 5.0, 5.0)\n",
    "\n",
    "# cfg.TEST.IMAGE_SIZE = [800,800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from dataset.roidb import combined_roidb_for_training\n",
    "from roi_data.loader import RoiDataLoader, MinibatchSampler, BatchSampler, collate_minibatch\n",
    "roidb, ratio_list, ratio_index = combined_roidb_for_training(\n",
    "        cfg.TRAIN.DATASETS, cfg.TRAIN.PROPOSAL_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating output/cityscapes/superscalenet_seg/scalenet_seg_w32_test/data_patch_test\n",
      "=> creating log/cityscapes/superscalenet_seg/data_patch_test/scalenet_seg_w32_test_2021-05-27-21-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> init weights from normal distribution\n",
      "=> loading model from ../models/pytorch/seg_cityscapes/superscalenet_seg_w32.pth\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/ipykernel/__main__.py:36: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "Missing keys in pretrained_dict: set()\n"
     ]
    }
   ],
   "source": [
    "logger, final_output_dir, tb_log_dir = create_logger(\n",
    "    cfg, args.cfg, 'test')\n",
    "\n",
    "writer_dict = {\n",
    "    'writer': SummaryWriter(tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "cudnn.enabled = cfg.CUDNN.ENABLED\n",
    "\n",
    "# build model\n",
    "model = eval('models.' + cfg.MODEL.NAME +\n",
    "             '.get_seg_model')(cfg)\n",
    "\n",
    "input_shape = (1, 3, cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "dump_input = torch.rand(\n",
    "    input_shape\n",
    ")\n",
    "\n",
    "if cfg.TEST.MODEL_FILE:\n",
    "    model_state_file = cfg.TEST.MODEL_FILE\n",
    "else:\n",
    "    model_state_file = os.path.join(final_output_dir,\n",
    "                                    'final_state.pth')\n",
    "logger.info('=> loading model from {}'.format(model_state_file))\n",
    "\n",
    "pretrained_dict = torch.load(model_state_file)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "model_keys = set(model_dict.keys())\n",
    "pretrained_keys = set(pretrained_dict.keys())\n",
    "missing_keys = model_keys - pretrained_keys\n",
    "logger.warn('Missing keys in pretrained_dict: {}'.format(missing_keys))\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "\n",
    "# prepare data\n",
    "test_size = (cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 1024, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTO_RESUME: False\n",
      "A_HIST_EQ: False\n",
      "CUDNN:\n",
      "  BENCHMARK: True\n",
      "  DETERMINISTIC: False\n",
      "  ENABLED: True\n",
      "DATASET:\n",
      "  COLOR_RGB: False\n",
      "  DATASET: cityscapes\n",
      "  DATA_FORMAT: jpg\n",
      "  EXTRA_TRAIN_SET: \n",
      "  FLIP: True\n",
      "  HYBRID_JOINTS_TYPE: \n",
      "  INPUT_SIZE: 256\n",
      "  NUM_CLASSES: 19\n",
      "  NUM_JOINTS_HALF_BODY: 8\n",
      "  PROB_HALF_BODY: 0.0\n",
      "  ROOT: ../data/\n",
      "  ROT_FACTOR: 30\n",
      "  SCALE_FACTOR: 0.25\n",
      "  SELECT_DATA: False\n",
      "  TEST_SET: list/cityscapes/val.lst\n",
      "  TRAIN_SET: list/cityscapes/train.lst\n",
      "DATA_DIR: \n",
      "DATA_SOURCE: coco\n",
      "DEBUG:\n",
      "  DEBUG: False\n",
      "  SAVE_BATCH_IMAGES_GT: False\n",
      "  SAVE_BATCH_IMAGES_PRED: False\n",
      "  SAVE_HEATMAPS_GT: False\n",
      "  SAVE_HEATMAPS_PRED: False\n",
      "FPN:\n",
      "  COARSEST_STRIDE: 32\n",
      "  DIM: 256\n",
      "  EXTRA_CONV_LEVELS: False\n",
      "  FPN_ON: True\n",
      "  MULTILEVEL_ROIS: True\n",
      "  MULTILEVEL_RPN: True\n",
      "  ROI_CANONICAL_LEVEL: 4\n",
      "  ROI_CANONICAL_SCALE: 224\n",
      "  ROI_MAX_LEVEL: 5\n",
      "  ROI_MIN_LEVEL: 2\n",
      "  RPN_ANCHOR_START_SIZE: 16\n",
      "  RPN_ASPECT_RATIOS: (0.5, 1, 2)\n",
      "  RPN_COLLECT_SCALE: 1\n",
      "  RPN_MAX_LEVEL: 6\n",
      "  RPN_MIN_LEVEL: 2\n",
      "  USE_GN: False\n",
      "  ZERO_INIT_LATERAL: False\n",
      "GPUS: (0,)\n",
      "HIST_EQ: False\n",
      "HIST_EQ_SYM: False\n",
      "LESION:\n",
      "  CONCAT_BEFORE_RPN: True\n",
      "  DEBUG: False\n",
      "  FUSION_BEFORE_RPN: False\n",
      "  GIF_BEFORE_RPN: False\n",
      "  LESION_ENABLED: True\n",
      "  MM_POS: False\n",
      "  MM_POS_CHANNEL: False\n",
      "  MM_TEST: False\n",
      "  MULTI_MODALITY: True\n",
      "  NO_DEPTH_PAD: True\n",
      "  NUM_IMAGES_3DCE: 1\n",
      "  POSITION_RCNN: False\n",
      "  POS_CONCAT_RCNN: False\n",
      "  SHALLOW_POSITION: False\n",
      "  SLICE_INTERVAL: 2.0\n",
      "  SLICE_NUM: 3\n",
      "  SUM_BEFORE_RPN: False\n",
      "  USE_3DCE: False\n",
      "  USE_3DCE_FROC: True\n",
      "  USE_3D_INPUT: False\n",
      "  USE_MULTI_WINDOWS: False\n",
      "  USE_ONE_WINDOW: False\n",
      "  USE_POSITION: True\n",
      "  USE_SPECIFIC_WINDOWS: False\n",
      "  WITHOUT_SHARE: False\n",
      "LOG_DIR: log\n",
      "LOSS:\n",
      "  BALANCE_WEIGHTS: [1]\n",
      "  OHEMKEEP: 131072\n",
      "  OHEMTHRES: 0.9\n",
      "  TOPK: 8\n",
      "  USE_DIFFERENT_JOINTS_WEIGHT: False\n",
      "  USE_OHEM: True\n",
      "  USE_OHKM: False\n",
      "  USE_TARGET_WEIGHT: True\n",
      "MODEL:\n",
      "  ALIGN_CORNERS: True\n",
      "  BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "  CLS_AGNOSTIC_BBOX_REG: False\n",
      "  EXTRA:\n",
      "    FINAL_CONV_KERNEL: 1\n",
      "    STAGE1:\n",
      "      BLOCK: BOTTLENECK\n",
      "      FUSE_METHOD: SUM\n",
      "      NUM_BLOCKS: [4]\n",
      "      NUM_CHANNELS: [64]\n",
      "      NUM_MODULES: 1\n",
      "      NUM_RANCHES: 1\n",
      "    STAGE2:\n",
      "      BLOCK: BASIC\n",
      "      DEPTH_LIST: [2, 3, 4, 5]\n",
      "      FUSE_METHOD: SUM\n",
      "      FUSION_PERCENTAGE: 0.5\n",
      "      NUM_BLOCKS: [5, 5]\n",
      "      NUM_BRANCHES: 2\n",
      "      NUM_CHANNELS: [32, 64]\n",
      "      NUM_MODULES: 1\n",
      "    STAGE3:\n",
      "      BLOCK: BASIC\n",
      "      DEPTH_LIST: [2, 3, 4, 5]\n",
      "      FUSE_METHOD: SUM\n",
      "      FUSION_PERCENTAGE: 0.5\n",
      "      NUM_BLOCKS: [5, 5, 5]\n",
      "      NUM_BRANCHES: 3\n",
      "      NUM_CHANNELS: [32, 64, 128]\n",
      "      NUM_MODULES: 4\n",
      "    STAGE4:\n",
      "      BLOCK: BASIC\n",
      "      DEPTH_LIST: [2, 3, 4, 5]\n",
      "      FUSE_METHOD: SUM\n",
      "      FUSION_PERCENTAGE: 0.5\n",
      "      NUM_BLOCKS: [5, 5, 5, 5]\n",
      "      NUM_BRANCHES: 4\n",
      "      NUM_CHANNELS: [32, 64, 128, 256]\n",
      "      NUM_MODULES: 3\n",
      "  GIF_ON: False\n",
      "  HEATMAP_SIZE: [64, 64]\n",
      "  IMAGE_SIZE: [256, 256]\n",
      "  INIT_WEIGHTS: True\n",
      "  KEYPOINTS_ON: False\n",
      "  LRASY_MAHA_ON: False\n",
      "  LR_VIEW_ON: False\n",
      "  MASK_PATH: \n",
      "  MULTI_HEATMAP_SIZE: []\n",
      "  MULTI_IMAGE_SIZE: []\n",
      "  NAME: superscalenet_seg\n",
      "  NUM_CLASSES: 22\n",
      "  NUM_JOINTS: 17\n",
      "  NUM_OUTPUTS: 1\n",
      "  OCR:\n",
      "    DROPOUT: 0.05\n",
      "    KEY_CHANNELS: 256\n",
      "    MID_CHANNELS: 512\n",
      "    SCALE: 1\n",
      "  PRETRAINED: \n",
      "  SIGMA: 2\n",
      "  TAG_PER_JOINT: True\n",
      "  TARGET_TYPE: gaussian\n",
      "OUTPUT_DIR: output\n",
      "PIN_MEMORY: True\n",
      "PIXEL_MEANS: [[[102.9801, 115.9465, 122.7717]]]\n",
      "PRINT_FREQ: 100\n",
      "RANK: 0\n",
      "RETINANET:\n",
      "  RETINANET_ON: False\n",
      "RPN:\n",
      "  RPN_ON: True\n",
      "TEST:\n",
      "  BASE_SIZE: 2048\n",
      "  BATCH_SIZE_PER_GPU: 4\n",
      "  BBOX_THRE: 1.0\n",
      "  CENTER_CROP_TEST: False\n",
      "  COCO_BBOX_FILE: \n",
      "  FLIP_TEST: False\n",
      "  IMAGE_SIZE: [2048, 1024]\n",
      "  IMAGE_THRE: 0.1\n",
      "  IN_VIS_THRE: 0.0\n",
      "  MODEL_FILE: ../models/pytorch/seg_cityscapes/superscalenet_seg_w32.pth\n",
      "  MULTI_SCALE: False\n",
      "  NMS_THRE: 0.6\n",
      "  NUM_SAMPLES: 0\n",
      "  OKS_THRE: 0.5\n",
      "  POST_PROCESS: False\n",
      "  SHIFT_HEATMAP: False\n",
      "  SOFT_NMS: False\n",
      "  USE_GT_BBOX: False\n",
      "TRAIN:\n",
      "  ASPECT_CROPPING: False\n",
      "  ASPECT_GROUPING: True\n",
      "  ASPECT_HI: 2\n",
      "  ASPECT_LO: 0.5\n",
      "  AUGMENTATION: False\n",
      "  AUG_LRV_BBOX: False\n",
      "  BASE_SIZE: 2048\n",
      "  BATCH_SIZE_PER_GPU: 3\n",
      "  BBOX_THRESH: 0.5\n",
      "  BEGIN_EPOCH: 0\n",
      "  BG_THRESH_HI: 0.5\n",
      "  BG_THRESH_LO: 0.0\n",
      "  CHECKPOINT: \n",
      "  CROWD_FILTER_THRESH: 0.7\n",
      "  DATASETS: ('PDS_AMGEN_PRIME_22Cat_train',)\n",
      "  DEPTH_OPTIONS: [[2, 3], [3, 4], [4, 5]]\n",
      "  DOWNSAMPLERATE: 1\n",
      "  END_EPOCH: 484\n",
      "  EXTRA_EPOCH: 0\n",
      "  FG_FRACTION: 0.25\n",
      "  FG_THRESH: 0.5\n",
      "  FLIP: True\n",
      "  FREEZE_EPOCHS: -1\n",
      "  FREEZE_LAYERS: \n",
      "  FUSION_OPTIONS: [0.2, 0.5, 0.8]\n",
      "  GAMMA1: 0.99\n",
      "  GAMMA2: 0.0\n",
      "  GROUP_SAMPLING: True\n",
      "  GT_MIN_AREA: -1\n",
      "  IGNORE_LABEL: 255\n",
      "  IGNORE_ON: False\n",
      "  IMAGE_SIZE: [1024, 512]\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR: 0.002\n",
      "  LR_FACTOR: 0.1\n",
      "  LR_SCHEDULER_TYPE: Step\n",
      "  LR_STEP: [90, 110]\n",
      "  MAX_SIZE: 800\n",
      "  MINMAL_LR: 1e-05\n",
      "  MOMENTUM: 0.9\n",
      "  MULTI_SCALE: True\n",
      "  NESTEROV: False\n",
      "  NONBACKBONE_KEYWORDS: []\n",
      "  NONBACKBONE_MULT: 10\n",
      "  NUM_SAMPLES: 0\n",
      "  ONLINE_RANDOM_CROPPING: False\n",
      "  ONLINE_RANDOM_CROPPING_HEIGHT_MAX: 2000\n",
      "  ONLINE_RANDOM_CROPPING_HEIGHT_MIN: 500\n",
      "  ONLINE_RANDOM_CROPPING_IOP_THRESHOLD: 0.9\n",
      "  ONLINE_RANDOM_CROPPING_PROBABILITY: 1.0\n",
      "  ONLINE_RANDOM_CROPPING_WIDTH_MAX: 1000\n",
      "  ONLINE_RANDOM_CROPPING_WIDTH_MIN: 500\n",
      "  OPTIMIZER: sgd\n",
      "  PADDING: 128\n",
      "  PROPOSAL_FILES: ()\n",
      "  RESUME: True\n",
      "  RPN_BATCH_SIZE_PER_IM: 256\n",
      "  RPN_FG_FRACTION: 0.5\n",
      "  RPN_MIN_SIZE: 0\n",
      "  RPN_NEGATIVE_OVERLAP: 0.3\n",
      "  RPN_NMS_THRESH: 0.7\n",
      "  RPN_POSITIVE_OVERLAP: 0.7\n",
      "  RPN_POST_NMS_TOP_N: 2000\n",
      "  RPN_PRE_NMS_TOP_N: 12000\n",
      "  RPN_STRADDLE_THRESH: 0\n",
      "  SANDWICH_RULE: True\n",
      "  SCALES: (512,)\n",
      "  SCALE_FACTOR: 16\n",
      "  SHUFFLE: True\n",
      "  SUBNET_NUM: 1\n",
      "  USE_ADJACENT_LAYER: False\n",
      "  USE_FLIPPED: True\n",
      "  USE_Z_FLIPPED: False\n",
      "  VIS_ANCHOR: False\n",
      "  VIS_ANCHOR_DIR: ./anchor_vis/\n",
      "  WD: 0.0005\n",
      "WINDOWING: [-1024, 3071]\n",
      "WORKERS: 4\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = RoiDataLoader(\n",
    "    roidb,\n",
    "    cfg.MODEL.NUM_CLASSES,\n",
    "    training=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=cfg.WORKERS)\n",
    "dataiterator = iter(dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batchSampler = BatchSampler(\n",
    "#     sampler=MinibatchSampler(ratio_list, ratio_index),\n",
    "#     batch_size=1,\n",
    "#     drop_last=True\n",
    "# )\n",
    "# dataset = RoiDataLoader(\n",
    "#     roidb,\n",
    "#     cfg.MODEL.NUM_CLASSES,\n",
    "#     training=True)\n",
    "# dataloader = torch.utils.data.DataLoader(\n",
    "#     dataset,\n",
    "#     batch_sampler=batchSampler,\n",
    "#     num_workers=cfg.WORKERS)\n",
    "# dataiterator = iter(dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> setting mask from ../experiments/searched_masks/cityscapes/seg_w32_S1.npy\n",
      "[{'d': array([[3],\n",
      "       [4]]), 'f': array([[list([1, 1]), list([1, 0]), list([1, 1]), list([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1]), list([0, 1]), list([1, 1]), list([0, 1]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[3],\n",
      "       [2],\n",
      "       [3]]), 'f': array([[list([1, 1, 0]), list([1, 0, 1]), list([1, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1, 0]), list([1, 1, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 1, 1]), list([0, 0, 1]), list([1, 1, 1]), array([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[2],\n",
      "       [2],\n",
      "       [2]]), 'f': array([[list([1, 0, 1]), list([1, 1, 0]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1, 1]), list([0, 1, 0]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 0, 1]), list([0, 0, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[2],\n",
      "       [2],\n",
      "       [2]]), 'f': array([[list([1, 1, 1]), list([1, 0, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1, 0]), list([1, 1, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1, 1]), list([1, 0, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[2],\n",
      "       [3],\n",
      "       [2]]), 'f': array([[list([1, 1, 1]), list([1, 1, 0]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 1, 1]), list([1, 1, 1]), list([1, 1, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 1, 1]), list([0, 1, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [3]]), 'f': array([[list([1, 1, 0, 1]), list([1, 1, 1, 1]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 1, 0, 0]), list([0, 1, 1, 0]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 1, 1, 0]), list([0, 0, 1, 0]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([0, 1, 0, 1]), list([1, 1, 1, 1]), list([1, 0, 1, 1]),\n",
      "        array([0, 0]), array([0, 0])]], dtype=object)}\n",
      " {'d': array([[2],\n",
      "       [3],\n",
      "       [3],\n",
      "       [3]]), 'f': array([[list([1, 0, 0, 1]), list([1, 0, 1, 0]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([0, 1, 1, 1]), list([1, 1, 1, 1]), list([1, 1, 1, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 0, 1, 1]), list([0, 1, 1, 0]), list([1, 1, 1, 1]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 0, 0, 1]), list([0, 1, 1, 1]), list([1, 0, 0, 1]),\n",
      "        array([0, 0]), array([0, 0])]], dtype=object)}\n",
      " {'d': array([[3],\n",
      "       [4],\n",
      "       [3],\n",
      "       [4]]), 'f': array([[list([1, 1, 1, 1]), list([1, 1, 1, 1]), list([1, 0, 0, 1]),\n",
      "        list([0, 0, 0, 0]), array([0, 0])],\n",
      "       [list([0, 1, 1, 1]), list([1, 1, 1, 0]), list([0, 1, 1, 1]),\n",
      "        list([0, 1, 1, 0]), array([0, 0])],\n",
      "       [list([1, 1, 1, 1]), list([0, 1, 1, 1]), list([0, 1, 1, 0]),\n",
      "        list([0, 0, 0, 0]), array([0, 0])],\n",
      "       [list([0, 0, 1, 1]), list([0, 1, 1, 1]), list([1, 1, 1, 1]),\n",
      "        list([1, 0, 1, 1]), array([0, 0])]], dtype=object)}]\n",
      "prepare to set running statistics\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "calculate bn done\n",
      "INFO: profile from hrnet: Model superscalenet_seg: params 25.3 M, flops 265.5 G (with input size (1, 3, 1024, 2048))\n",
      "mean_IoU:  0.0006, IoU_array: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01126371 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "testloader = dataloader\n",
    "gpus = list(cfg.GPUS)\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "if os.path.exists(args.mask_path):\n",
    "    masks = np.load(args.mask_path, allow_pickle=True)\n",
    "    model.module.set_active_subnet(masks)\n",
    "    logger.info('=> setting mask from {}'.format(args.mask_path))\n",
    "    logger.info(masks)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.bn_calib:\n",
    "    calib_bn(cfg, model, 0, masks)\n",
    "params, flops, details = get_model_summary(model.module, dump_input.cuda())\n",
    "logger.info('INFO: profile from hrnet: Model {}: params {:.1f} M, flops {:.1f} G (with input size {})'.\n",
    "            format(cfg.MODEL.NAME, params / 1e6, flops, input_shape))\n",
    "\n",
    "\n",
    "mean_IoU, IoU_array = validate(cfg, testloader, model, writer_dict, device=None)\n",
    "\n",
    "msg = 'mean_IoU: {: 4.4f}, IoU_array: {}'.format(mean_IoU, IoU_array)\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.histogram(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.random.randint(0,10,(2,2,2,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(batch[0][1][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(batch[0][1][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def compute_image_resize_params(data):\n",
    "    \"\"\"Compute median dimension of all images in data.\n",
    "\n",
    "    It used to resize the images later. Number of channels do not change from the original data.\n",
    "\n",
    "    Args:\n",
    "        data: a list of images.\n",
    "\n",
    "    Returns:\n",
    "        median shape.\n",
    "    \"\"\"\n",
    "    if data is None or len(data) == 0:\n",
    "        print('data is empty')\n",
    "        return []\n",
    "\n",
    "    data_shapes = []\n",
    "    for x in data:\n",
    "        data_shapes.append(x.shape)\n",
    "\n",
    "    median_shape = np.median(np.array(data_shapes), axis=0)\n",
    "    return tuple( median_shape.astype(int) )\n",
    "\n",
    "def smart_stack(in_list, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Use the first element to determine the size for all the results and resize the ones that dont match\n",
    "    \"\"\"\n",
    "    base_shape = compute_image_resize_params(in_list)\n",
    "    return np.stack([x if x.shape==base_shape else resize(x, base_shape, preserve_range=True) for x in in_list], *args, **kwargs)\n",
    "\n",
    "\n",
    "from skimage.util import montage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contourList = [batch[1][i] for i in range(3)]\n",
    "all_contours = smart_stack(contourList)\n",
    "\n",
    "imageList = [batch[0][i][j] for i in range(3) for j in range(27)]\n",
    "all_lesions = smart_stack(imageList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (28, 23))\n",
    "ax1.imshow(montage(all_lesions), cmap = 'gray')\n",
    "fig.savefig('montage.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imsave('1.png',montage(all_lesions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (28, 23))\n",
    "ax1.imshow(montage(all_contours), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils.blob as blob_utils\n",
    "roidb = blob_utils.deserialize(batch['roidb'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roidb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycocotools.mask as mask_util\n",
    "def polys_to_mask(polygons, height, width):\n",
    "    \"\"\"\n",
    "    Convert from the COCO polygon segmentation format to a binary mask\n",
    "    encoded as a 2D array of data type numpy.float32. The polygon segmentation\n",
    "    is understood to be enclosed inside a height x width image. The resulting\n",
    "    mask is therefore of shape (height, width).\n",
    "    \"\"\"\n",
    "    rle = mask_util.frPyObjects(polygons, height, width)\n",
    "    mask = np.array(mask_util.decode(rle), dtype=np.float32)\n",
    "    # Flatten in case polygons was a list\n",
    "    mask = np.sum(mask, axis=2)\n",
    "    mask = np.array(mask > 0, dtype=np.float32)\n",
    "    return mask\n",
    "\n",
    "\n",
    "ix = [a for a,b in enumerate(aroidb['gt_classes']) if int(b) in site_list]\n",
    "contours = [ aroidb['segms'][int(kk)] for kk in ix ]\n",
    "if not contours:\n",
    "    continue\n",
    "\n",
    "for c in contours:\n",
    "    if len(c): #gt\n",
    "        vol_gt[D_z_index[s]] = polys_to_mask(c , height , width) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roidb[0]['gt_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch['data'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "mask = polys_to_mask(roidb[0]['segms'][0],300,300)\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch = next(iter(testloader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataset = eval('dataset.' + cfg.DATASET.DATASET)(\n",
    "    root=cfg.DATASET.ROOT,\n",
    "    list_path=cfg.DATASET.TEST_SET,\n",
    "    num_samples=None,\n",
    "    num_classes=cfg.DATASET.NUM_CLASSES,\n",
    "    multi_scale=False,\n",
    "    flip=False,\n",
    "    ignore_label=cfg.TRAIN.IGNORE_LABEL,\n",
    "    base_size=cfg.TEST.BASE_SIZE,\n",
    "    crop_size=test_size,\n",
    "    downsample_rate=1)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=True)\n",
    "\n",
    "gpus = list(cfg.GPUS)\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "if os.path.exists(args.mask_path):\n",
    "    masks = np.load(args.mask_path, allow_pickle=True)\n",
    "    model.module.set_active_subnet(masks)\n",
    "    logger.info('=> setting mask from {}'.format(args.mask_path))\n",
    "    logger.info(masks)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.bn_calib:\n",
    "    calib_bn(cfg, model, 0, masks)\n",
    "params, flops, details = get_model_summary(model.module, dump_input.cuda())\n",
    "logger.info('INFO: profile from hrnet: Model {}: params {:.1f} M, flops {:.1f} G (with input size {})'.\n",
    "            format(cfg.MODEL.NAME, params / 1e6, flops, input_shape))\n",
    "\n",
    "\n",
    "mean_IoU, IoU_array = validate(cfg, testloader, model, writer_dict, device=None)\n",
    "\n",
    "msg = 'mean_IoU: {: 4.4f}, IoU_array: {}'.format(mean_IoU, IoU_array)\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to load predicted mask for hard-disk and calculate Segmentation evaluation metics.\n",
    "predicted mask is the output of ScaleNASv2 Test and save predicted mask.ipynb\n",
    "\n",
    "cp -v /mnt/fast-data/mjc/AutoRECIST/Codes/ScaleNAS/ScaleNASv1/tools/utils_test.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # This file is for segmetation metrics evaluation in 3D\n",
    "# Edited by Jingchen around 06/20/2021\n",
    "# This file is after ScaleNAS test which save predition into png images.\n",
    "# This file load png images as predicted contours in 2D\n",
    "# load cache pkl as gold-standard contours in 2D\n",
    "# The stack 2D based on dicom-header to get 3D\n",
    "# Evaluate 3D metics of dice, IoU, over-segmetation, and under-segmetation\n",
    "# \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import _init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from utils_test import *\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, batchname = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                save_pred(pred, sv_path, batchname)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d images' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached gt_roidb from %s ./cache/PDS_AMGEN_20020408_22Cat_test_gt_roidb.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/fast-data/mjc/envs/Lesions/lib/python3.6/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== 0\n"
     ]
    }
   ],
   "source": [
    "cache_path = './cache/'\n",
    "name = 'PDS_AMGEN_20020408_22Cat_test'\n",
    "# name = 'lesion_train'\n",
    "\n",
    "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\n",
    "print('Loading cached gt_roidb from %s', cache_filepath)\n",
    "with open(cache_filepath, 'rb') as fp:\n",
    "    cached_roidb = pickle.load(fp)\n",
    "    \n",
    "roidb = cached_roidb\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "from utils_test import __get_annotation__\n",
    "\n",
    "sv_dir = mask_name = 'mask_1661'\n",
    "sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "\n",
    "all_boxes = [ [ np.zeros((0,5),dtype=\"float32\") for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "all_segms = [ [ [] for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "\n",
    "for i in range(len(roidb)):\n",
    "    if i%500==0:\n",
    "        print('='*40,i)\n",
    "\n",
    "    one = roidb[i]\n",
    "    onename = one['image']\n",
    "    pred_im = Image.open(os.path.join(sv_path, convert_name(onename) ))\n",
    "    pred = np.array(pred_im)\n",
    "    for j in range(cfg.DATASET.NUM_CLASSES):\n",
    "        mask = np.asarray( pred==j , dtype=np.uint8)\n",
    "        if np.sum(mask > 0) <= 3 :\n",
    "            continue\n",
    "        segmentation, bbox, area = __get_annotation__(mask , xywh = False , bbox_score=True)\n",
    "        if segmentation and bbox:\n",
    "            all_segms[j][i] = segmentation\n",
    "            all_boxes[j][i] = bbox\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "site_ix = 8\n",
    "gt_boxes = get_gt_boxes(cached_roidb,site_ix)\n",
    "avgFP=[0.5,1,2,3,4,8,16,32,64]\n",
    "iou_th=0.5\n",
    "\n",
    "stack_box = all_boxes[site_ix]\n",
    "result, valid_avgFP = sens_at_FP(stack_box, gt_boxes, avgFP, iou_th)\n",
    "print('='*40)\n",
    "for recall,fp in zip(result,valid_avgFP):\n",
    "    print('Recall@%.1f=%.2f%%' % (fp, recall*100))\n",
    "#TODO: when num of valid_avgFP < 6,is FROC correct?\n",
    "print('Mean FROC is %.2f'% np.mean(np.array(result[:6])*100))\n",
    "print('='*40)\n",
    "\n",
    "\n",
    "sens, fp_per_img, scores_th = FROC(stack_box, gt_boxes, iou_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "site_list = [site_ix] #8 is liver\n",
    "D_CT = {}\n",
    "for i , aroidb in enumerate(roidb):\n",
    "    dicom_path , png_name = os.path.split(aroidb['image'])\n",
    "    slice_no , _= os.path.splitext(png_name)\n",
    "    slice_no = int(slice_no)\n",
    "    if slice_no != aroidb['slice_no']:\n",
    "        print(dicom_path,slice_no,aroidb['slice_no'])\n",
    "\n",
    "    segmentations = {}\n",
    "    bboxes = {}\n",
    "    for j in site_list:\n",
    "        segmentations[j] = all_segms[j][i]\n",
    "        bboxes[j] = all_boxes[j][i]\n",
    "\n",
    "    if dicom_path not in D_CT:\n",
    "        D_CT[dicom_path] = {}\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "    else:\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# DL_info = '../Inputs/PDS_AUTO_RECIST CIA-LAB Image and Contour 2020-10-01.xlsx'\n",
    "# json_name = 'CUIMC20201027.json'\n",
    "\n",
    "DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AMGEN_20020408_CIA-LAB_Image_And_Contour_2020-10-21.xlsx'\n",
    "# json_name = 'AMGEN_20020408_20201027.json'\n",
    "\n",
    "# DL_info = '../Inputs/PDS_AMGEN_PRIME_CIA-LAB_Image_And_Contour_2020-10-21.xlsx'\n",
    "# json_name = 'AMGEN_PRIME_20201027.json'\n",
    "\n",
    "df = pd.read_excel(DL_info)\n",
    "\n",
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instence should be str or list')\n",
    "\n",
    "pd_str_replace(df, ['Image File Path' , 'Contour File Path'], \"X:\" , \"/mnt/W-drive\")\n",
    "pd_str_replace(df, ['Image File Path' , 'Contour File Path'], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/W-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/W-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Contour File Path'], \"/mnt/W-drive/ConvWeasisToRaw\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "sys.path.append('/mnt/fast-data/mjc/DeepLesion/Codes/CollectData/')\n",
    "\n",
    "from print_weasis_raw_data import WeasisRawDataPrinter\n",
    "from read_weasis_raw_data import WeasisRawFileReader\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "data_path = \"\"\n",
    "metadata_path = \"/mnt/fast-data/mjc/AutoRECIST/Outputs/Dicom_header\"\n",
    "if not os.path.exists(metadata_path):\n",
    "    os.mkdir(metadata_path)\n",
    "\n",
    "\n",
    "D_dir2header_df = {}\n",
    "\n",
    "\n",
    "def get_dicom_header_df(image_dir , labels = []):\n",
    "    global D_dir2header_df\n",
    "    if image_dir in D_dir2header_df:\n",
    "        return D_dir2header_df[image_dir]\n",
    "\n",
    "    # image_dir = row['Image File Path']\n",
    "\n",
    "\n",
    "    labels = ['ImageName','InstanceNumber',\n",
    "            'BitsAllocated', 'BitsStored', 'Columns', 'HighBit', \n",
    "            'ImageOrientationPatient_0', 'ImageOrientationPatient_1', 'ImageOrientationPatient_2',\n",
    "            'ImageOrientationPatient_3', 'ImageOrientationPatient_4', 'ImageOrientationPatient_5',\n",
    "            'ImagePositionPatient_0', 'ImagePositionPatient_1', 'ImagePositionPatient_2',\n",
    "            'Modality', 'PatientID', 'PhotometricInterpretation', 'PixelRepresentation',\n",
    "            'PixelSpacing_0', 'PixelSpacing_1', 'RescaleIntercept', 'RescaleSlope', 'Rows', 'SOPInstanceUID',\n",
    "            'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID', 'StudyInstanceUID', \n",
    "            'WindowCenter', 'WindowWidth', \n",
    "        ] if not labels else labels\n",
    "\n",
    "    data = {l: [] for l in labels}\n",
    "    \n",
    "    ctList = os.listdir(image_dir)\n",
    "    ctList.sort()\n",
    "\n",
    "    for image in ctList:\n",
    "        if '.dcm' not in image:\n",
    "            continue\n",
    "        if os.path.getsize(os.path.join(image_dir, image)) < 5*1024:\n",
    "            print('%s size < 5kb skiped!'%os.path.join(image_dir, image) )\n",
    "            continue\n",
    "        data[\"ImageName\"].append(image)\n",
    "\n",
    "        ds = pydicom.dcmread(os.path.join(image_dir, image))\n",
    "        for metadata in ds.dir():\n",
    "            if metadata not in data and metadata not in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                continue\n",
    "            if metadata != \"PixelData\":\n",
    "                metadata_values = getattr(ds, metadata)\n",
    "                if type(metadata_values) == pydicom.multival.MultiValue and metadata not in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                    for i, v in enumerate(metadata_values):\n",
    "                        data[f\"{metadata}_{i}\"].append(v)  \n",
    "                else:\n",
    "                    if type(metadata_values) == pydicom.multival.MultiValue and metadata in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                        data[metadata].append(metadata_values[0])\n",
    "                    else:\n",
    "                        data[metadata].append(metadata_values)\n",
    "\n",
    "    df_image = pd.DataFrame(data).set_index(\"InstanceNumber\")\n",
    "    D_dir2header_df[image_dir] = df_image\n",
    "    return df_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cp -v /mnt/fast-data/mjc/AutoRECIST/Codes/ScaleNAS/ScaleNASv1/tools/utils_metrics_3d.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In[53]:\n",
    "\n",
    "from utils_metrics_3d import *\n",
    "Metrics_vol = []\n",
    "Missed_vol = []\n",
    "previous_CT_ss = ''\n",
    "for _,row in df.iterrows():\n",
    "\n",
    "    if _%100==0 or _<10:\n",
    "        print(_)\n",
    "    if row.Location != ix2labelname(site_ix):\n",
    "#         only calculate liver\n",
    "        continue\n",
    "    df_image = get_dicom_header_df( row['Image File Path'] )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "    reader = WeasisRawFileReader()\n",
    "    weasis_raw_data = reader.read_weasis_raw_file(row['Contour File Path'])\n",
    "\n",
    "    ss = row['Image File Path']\n",
    "    ss = ss.replace('/Inputs/' , '/Pngs/')\n",
    "    if ss not in D_CT:\n",
    "        print(ss , 'not in D_CT')\n",
    "\n",
    "    mask_vol = initialize_mask_vol(weasis_raw_data , D_z_index)\n",
    "\n",
    "    slice_list = weasis_raw_data.get_instance_number_array()\n",
    "    for j, one in enumerate(slice_list):\n",
    "        file_name = InstanceNumber2file_name(df_image, one)\n",
    "        file_name = os.path.join( row['Image File Path'] , file_name)   \n",
    "        mask = weasis_raw_data.get_mask_image_2d(j)\n",
    "        mask_vol[D_z_index[one]] = mask\n",
    "\n",
    "    if ss != previous_CT_ss:\n",
    "        oneCT = D_CT[ss]\n",
    "        vol_gt , vol_pred = get_gt_and_pred_vols( oneCT, site_list, mask_vol.shape, D_z_index, union_mask=False )\n",
    "        previous_CT_ss = ss\n",
    "    hit = vols_seg_results(mask_vol , vol_pred, CTname=ss, gt_keep_largest=1)\n",
    "    Metrics_vol.extend(hit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In[54]:\n",
    "\n",
    "print(name)\n",
    "df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                          columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                     'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                     'area_gt','area_pred','intersection','union']) \n",
    "df_metrics.describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In[55]:\n",
    "\n",
    "print(name)\n",
    "df_miss = pd.DataFrame(Missed_vol, \n",
    "                          columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                     'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                     'area_gt','area_pred','intersection','union']) \n",
    "df_miss.describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "SHOW_LABEL = True\n",
    "SHOW_BOX = False\n",
    "SHOW_MASK = True\n",
    "SHOW_UNION_MASK= False\n",
    "SHOW_MASK_LABEL = True\n",
    "SHOW_GT_MASK = True\n",
    "\n",
    "# site_list = range(1,len(all_boxes))\n",
    "site_list = [site_ix] #8 is liver\n",
    "savepath = '/mnt/fast-disk1/mjc/AutoRecist/Outputs/ScaleNAS/%s/Images_%s_UnionMask_liver'%(mask_name,name)\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "for i , aroidb in enumerate(roidb):\n",
    "\n",
    "    image_path = os.path.join(aroidb['image'])\n",
    "    [HU1, HU2 ] = aroidb['windows']\n",
    "\n",
    "    image = load_image(image_path, HU1, HU2)\n",
    "    height,width = image.shape\n",
    "#     plt.imshow(image)\n",
    "    image = np.dstack((image,image,image))\n",
    "    if SHOW_GT_MASK:\n",
    "        ix = [a for a,b in enumerate(aroidb['gt_classes']) if int(b) in site_list]\n",
    "        contours = [ aroidb['segms'][int(kk)] for kk in ix ]\n",
    "        if not contours:\n",
    "            continue\n",
    "        colors = [0,0,255]\n",
    "        for c in contours:\n",
    "            c = [ np.int64( np.reshape(c,(-1,2)) ) for c in c]\n",
    "            if len(c):\n",
    "                image = cv2.drawContours(image, c, -1, colors, 1)\n",
    "#             c = np.reshape(c,(-1,2))\n",
    "#             if c.shape[0]:\n",
    "#                 image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "    \n",
    "    if SHOW_MASK:\n",
    "        for j in site_list:\n",
    "            contours = all_segms[j][i]\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            for c in contours:\n",
    "                c = np.reshape(c,(-1,2))\n",
    "                if c.shape[0]:\n",
    "                    image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "    \n",
    "\n",
    "    if SHOW_UNION_MASK:\n",
    "        for j in site_list:\n",
    "            contours = all_segms[j][i]\n",
    "            cc = [ contour.flatten().tolist() for contour in contours if len(contour)!=0]\n",
    "            contours = union_ploys(cc , height, width)\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            label = ix2labelname(j)\n",
    "\n",
    "            for c in contours:\n",
    "                c = np.reshape(c,(-1,2))\n",
    "                if c.shape[0]:\n",
    "                    image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "                    if SHOW_MASK_LABEL:\n",
    "                        x,y,_,_ =ploy2boxes(c)\n",
    "                        template = \"{}\"\n",
    "                        if len(label)>=9:\n",
    "                            label=label[:3]+label[-3:]\n",
    "            \n",
    "                        s = template.format(label)\n",
    "                        cv2.putText(\n",
    "                            image, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, .5, colors, 1\n",
    "                        )        \n",
    "\n",
    "    if SHOW_BOX:\n",
    "        for j in site_list:\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            for box in all_boxes[j][i]:\n",
    "                \n",
    "                if box.shape[0]:\n",
    "                    top_left, bottom_right = box[:2].tolist(), box[2:4].tolist()\n",
    "                    image = cv2.rectangle(image, tuple(np.int64(top_left).tolist()), tuple(np.int64(bottom_right).tolist()), colors, 1)\n",
    "                \n",
    "            \n",
    "    \n",
    "    cv2.imwrite( os.path.join(savepath, '%06d.png'%aroidb['id'] ), image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "all_segms[8][5]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "all_boxes[8][5]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_lesions)",
   "language": "python",
   "name": "conda_lesions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

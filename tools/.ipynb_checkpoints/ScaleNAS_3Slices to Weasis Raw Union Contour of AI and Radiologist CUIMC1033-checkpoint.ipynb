{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PatientID PatientName  StudyDate User ID  Tumor QA State  Tumor Label  \\\n",
      "0        BAIJC       BAIJC 2004-02-27  js5680               3            1   \n",
      "1        BAIJC       BAIJC 2004-02-27  js5680               3            2   \n",
      "2        BAIJC       BAIJC 2004-02-27  js5680               3            3   \n",
      "3        BAIJC       BAIJC 2004-02-27  js5680               3            4   \n",
      "4        BAIJC       BAIJC 2004-02-27  js5680               3            5   \n",
      "...        ...         ...        ...     ...             ...          ...   \n",
      "3243     BAIXA       BAIXA 2004-02-09  yh2588               3            2   \n",
      "3244     BAIXA       BAIXA 2004-02-09  yh2588               3            3   \n",
      "3245     BAIXA       BAIXA 2004-02-09  yh2588               3            4   \n",
      "3246     BAIXA       BAIXA 2004-02-09  yh2588               3            5   \n",
      "3247     BAIXA       BAIXA 2004-02-09  yh2588               3            6   \n",
      "\n",
      "     Location      Uni      Perp           Bi    Volume    Update Date Time  \\\n",
      "0       liver  45.5731  36.56930  1666.576500  24536.30 2020-06-16 10:39:58   \n",
      "1        lung  15.5643  11.11740   173.034550   2039.34 2020-06-16 10:40:00   \n",
      "2        lung  12.8308  10.06720   129.170230   1344.73 2020-06-22 16:51:16   \n",
      "3        lung  15.1458  12.27960   185.984360   1586.98 2020-06-22 16:51:26   \n",
      "4        lung  10.7557   3.58525    38.561874    538.88 2020-06-22 16:51:38   \n",
      "...       ...      ...       ...          ...       ...                 ...   \n",
      "3243    liver  23.2746  13.19280   307.057130   7250.49 2020-07-01 12:33:51   \n",
      "3244    liver  16.8104   9.88845   166.228790   1557.17 2020-07-01 12:33:51   \n",
      "3245    liver  27.1977  17.68900   481.100100   5395.09 2020-07-09 15:44:15   \n",
      "3246    liver  17.4805  16.14270   282.182460   2574.10 2020-07-09 15:44:25   \n",
      "3247    liver  16.9263   8.95437   151.564350   1178.27 2020-07-09 15:44:43   \n",
      "\n",
      "                                          Raw File Name  \\\n",
      "0     js5680_BAIJC_2004-02-27_S0002_T0000_1.3.6.1.4....   \n",
      "1     js5680_BAIJC_2004-02-27_S0003_T0000_1.3.6.1.4....   \n",
      "2     js5680_BAIJC_2004-02-27_S0002_T0001_1.3.6.1.4....   \n",
      "3     js5680_BAIJC_2004-02-27_S0002_T0002_1.3.6.1.4....   \n",
      "4     js5680_BAIJC_2004-02-27_S0002_T0003_1.3.6.1.4....   \n",
      "...                                                 ...   \n",
      "3243  yh2588_BAIXA_2004-02-09_S0002_T0001_1.3.12.2.1...   \n",
      "3244  yh2588_BAIXA_2004-02-09_S0002_T0002_1.3.12.2.1...   \n",
      "3245  yh2588_BAIXA_2004-02-09_S0002_T0003_1.3.12.2.1...   \n",
      "3246  yh2588_BAIXA_2004-02-09_S0002_T0004_1.3.12.2.1...   \n",
      "3247  yh2588_BAIXA_2004-02-09_S0002_T0005_1.3.12.2.1...   \n",
      "\n",
      "                        Tumor Instance UID  \\\n",
      "0     c77ee057-1b44-46e4-a860-64a0ea2659a2   \n",
      "1     8a3aa808-3588-4a3e-a46f-258867dd9ff3   \n",
      "2     37e51f5c-8ea1-4cda-9451-9a7f39357971   \n",
      "3     a4c79b5b-020d-423e-8541-48e80e398fb5   \n",
      "4     31dd6b13-1323-4097-88df-ecba9f76abb5   \n",
      "...                                    ...   \n",
      "3243  cbc0f051-9943-47ec-a1be-c92c942e5770   \n",
      "3244  1d38835a-7651-4b76-98e4-23a5a9b31de1   \n",
      "3245  2c707ced-3805-4746-a79c-bd6bb98944bf   \n",
      "3246  bf41ffe0-7a73-43af-9070-f41a3bc8f162   \n",
      "3247  bc2881d4-2e49-4313-b5a5-9cf5dffbc4bb   \n",
      "\n",
      "                                        Image File Path  \\\n",
      "0     X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "1     X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "2     X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "3     X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "4     X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "...                                                 ...   \n",
      "3243  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "3244  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "3245  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "3246  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "3247  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "\n",
      "                                      Contour File Path  \n",
      "0     X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "1     X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "2     X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "3     X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "4     X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "...                                                 ...  \n",
      "3243  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\yh2588_B...  \n",
      "3244  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\yh2588_B...  \n",
      "3245  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\yh2588_B...  \n",
      "3246  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\yh2588_B...  \n",
      "3247  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\yh2588_B...  \n",
      "\n",
      "[3248 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "CT_EXCEL_FILE = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AMGEN_20020408_CIA-LAB_Image_And_Contour_2022-01-10.xlsx'\n",
    "SAVE_PATH = '/mnt/fast-disk1/refine_gt/'\n",
    "\n",
    "import pandas as pd\n",
    "df_all = pd.read_excel(CT_EXCEL_FILE)\n",
    "\n",
    "print(df_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PatientID PatientName  StudyDate User ID  Tumor QA State  Tumor Label  \\\n",
      "0     BAIJC       BAIJC 2004-02-27  js5680               3            1   \n",
      "1     BAIJC       BAIJC 2004-02-27  js5680               3            2   \n",
      "2     BAIJC       BAIJC 2004-02-27  js5680               3            3   \n",
      "3     BAIJC       BAIJC 2004-02-27  js5680               3            4   \n",
      "4     BAIJC       BAIJC 2004-02-27  js5680               3            5   \n",
      "\n",
      "  Location      Uni      Perp           Bi    Volume    Update Date Time  \\\n",
      "0    liver  45.5731  36.56930  1666.576500  24536.30 2020-06-16 10:39:58   \n",
      "1     lung  15.5643  11.11740   173.034550   2039.34 2020-06-16 10:40:00   \n",
      "2     lung  12.8308  10.06720   129.170230   1344.73 2020-06-22 16:51:16   \n",
      "3     lung  15.1458  12.27960   185.984360   1586.98 2020-06-22 16:51:26   \n",
      "4     lung  10.7557   3.58525    38.561874    538.88 2020-06-22 16:51:38   \n",
      "\n",
      "                                       Raw File Name  \\\n",
      "0  js5680_BAIJC_2004-02-27_S0002_T0000_1.3.6.1.4....   \n",
      "1  js5680_BAIJC_2004-02-27_S0003_T0000_1.3.6.1.4....   \n",
      "2  js5680_BAIJC_2004-02-27_S0002_T0001_1.3.6.1.4....   \n",
      "3  js5680_BAIJC_2004-02-27_S0002_T0002_1.3.6.1.4....   \n",
      "4  js5680_BAIJC_2004-02-27_S0002_T0003_1.3.6.1.4....   \n",
      "\n",
      "                     Tumor Instance UID  \\\n",
      "0  c77ee057-1b44-46e4-a860-64a0ea2659a2   \n",
      "1  8a3aa808-3588-4a3e-a46f-258867dd9ff3   \n",
      "2  37e51f5c-8ea1-4cda-9451-9a7f39357971   \n",
      "3  a4c79b5b-020d-423e-8541-48e80e398fb5   \n",
      "4  31dd6b13-1323-4097-88df-ecba9f76abb5   \n",
      "\n",
      "                                     Image File Path  \\\n",
      "0  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "1  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "2  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "3  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "4  X:\\ClinicalTrials\\FNIH_VOLPACK\\AMGEN\\20020408\\...   \n",
      "\n",
      "                                   Contour File Path  \n",
      "0  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "1  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "2  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "3  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n",
      "4  X:\\ConvWeasisToRaw\\PDS_AMGEN_20020408\\js5680_B...  \n"
     ]
    }
   ],
   "source": [
    "df = df_all.iloc[0:5] # a liver lesions case\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from math import ceil, floor\n",
    "import cv2\n",
    "import sys\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def window_image(img, window_center,window_width, intercept, slope):\n",
    "    \n",
    "#     window_center,window_width = 50 ,100\n",
    "    img = (img*slope +intercept)\n",
    "    img_min = window_center - window_width//2\n",
    "    img_max = window_center + window_width//2\n",
    "    img[img<img_min] = img_min\n",
    "    img[img>img_max] = img_max\n",
    "    return img \n",
    "\n",
    "\n",
    "def get_first_of_dicom_field_as_int(x):\n",
    "    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n",
    "    if type(x) == pydicom.multival.MultiValue:\n",
    "        return int(x[0])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def get_windowing(data):\n",
    "    dicom_fields = [data[('0028','1050')].value, #window center\n",
    "                    data[('0028','1051')].value, #window width\n",
    "                    data[('0028','1052')].value, #intercept\n",
    "                    data[('0028','1053')].value] #slope\n",
    "    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]\n",
    "\n",
    "def _normalize(img):\n",
    "    if img.max() == img.min():\n",
    "        return np.zeros(img.shape)-1\n",
    "    return 2 * (img - img.min())/(img.max() - img.min()) - 1\n",
    "\n",
    "def normalize_minmax(img):\n",
    "    mi, ma = img.min(), img.max()\n",
    "    if mi == ma:\n",
    "        return np.zeros(img.shape)-1\n",
    "    return 2*(img - mi) / (ma - mi) - 1\n",
    "\n",
    "def getName(s):\n",
    "    ix1 = s.rfind('/')\n",
    "    ix2 = s.rfind('.')\n",
    "    return s[ix1:ix2]\n",
    "\n",
    "\n",
    "def _read(path, desired_size = (512,512)):\n",
    "    \"\"\"Will be used in DataGenerator\"\"\"\n",
    "\n",
    "    try:\n",
    "        data = pydicom.read_file(path)\n",
    "        image = data.pixel_array\n",
    "        window_center , window_width, intercept, slope = get_windowing(data)\n",
    "        \n",
    "        image_windowed = window_image(image, window_center, window_width, intercept, slope)\n",
    "        img = normalize_minmax(image_windowed)\n",
    "\n",
    "    except:\n",
    "        img = np.zeros(desired_size[:2])-1\n",
    "    \n",
    "    if img.shape[:2] != desired_size[:2]:\n",
    "        print(\"image shape is not desired size. Interpolation is done.\")\n",
    "        img = cv2.resize(img, desired_size[:2], interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "\n",
    "D_dir2header_df = {}\n",
    "\n",
    "\n",
    "def get_dicom_header_df(image_dir , labels = []):\n",
    "    global D_dir2header_df\n",
    "    if image_dir in D_dir2header_df:\n",
    "        return D_dir2header_df[image_dir]\n",
    "\n",
    "    # image_dir = row['Image File Path']\n",
    "\n",
    "\n",
    "    labels = ['ImageName','InstanceNumber',\n",
    "            'BitsAllocated', 'BitsStored', 'Columns', 'HighBit', \n",
    "            'ImageOrientationPatient_0', 'ImageOrientationPatient_1', 'ImageOrientationPatient_2',\n",
    "            'ImageOrientationPatient_3', 'ImageOrientationPatient_4', 'ImageOrientationPatient_5',\n",
    "            'ImagePositionPatient_0', 'ImagePositionPatient_1', 'ImagePositionPatient_2',\n",
    "            'Modality', 'PatientID', 'PhotometricInterpretation', 'PixelRepresentation',\n",
    "            'PixelSpacing_0', 'PixelSpacing_1', 'RescaleIntercept', 'RescaleSlope', 'Rows', 'SOPInstanceUID',\n",
    "            'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID', 'StudyInstanceUID', \n",
    "            'WindowCenter', 'WindowWidth', \n",
    "        ] if not labels else labels\n",
    "\n",
    "    data = {l: [] for l in labels}\n",
    "    \n",
    "    ctList = os.listdir(image_dir)\n",
    "    ctList.sort()\n",
    "\n",
    "    for image in ctList:\n",
    "        if '.dcm' not in image:\n",
    "            continue\n",
    "        if os.path.getsize(os.path.join(image_dir, image)) < 5*1024:\n",
    "            print('%s size < 5kb skiped!'%os.path.join(image_dir, image) )\n",
    "            continue\n",
    "        data[\"ImageName\"].append(image)\n",
    "\n",
    "        ds = pydicom.dcmread(os.path.join(image_dir, image))\n",
    "        for metadata in ds.dir():\n",
    "            if metadata not in data and metadata not in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                continue\n",
    "            if metadata != \"PixelData\":\n",
    "                metadata_values = getattr(ds, metadata)\n",
    "                if type(metadata_values) == pydicom.multival.MultiValue and metadata not in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                    for i, v in enumerate(metadata_values):\n",
    "                        data[f\"{metadata}_{i}\"].append(v)  \n",
    "                else:\n",
    "                    if type(metadata_values) == pydicom.multival.MultiValue and metadata in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                        data[metadata].append(metadata_values[0])\n",
    "                    else:\n",
    "                        data[metadata].append(metadata_values)\n",
    "\n",
    "    df_image = pd.DataFrame(data).set_index(\"InstanceNumber\")\n",
    "    D_dir2header_df[image_dir] = df_image\n",
    "    return df_image\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "def InstanceNumber2file_name(df_image, num):\n",
    "    return df_image.loc[num,'ImageName']\n",
    "\n",
    "def InstanceNumber2data_element(df_image, num, label):\n",
    "    return df_image.loc[num , label]\n",
    "\n",
    "    \n",
    "def get_SliceThickness(df_image):\n",
    "    flag = False\n",
    "    L = df_image['ImagePositionPatient_2'].tolist()\n",
    "    thick = list( np.diff(L) )\n",
    "    res = float( max(set(thick), key=thick.count) )\n",
    "    res = -res if res < 0 else res\n",
    "    \n",
    "    L.sort()\n",
    "    thick2 = list( np.diff(L) )\n",
    "    res2 = float( max(set(thick2), key=thick2.count) )\n",
    "    if res2 ==0 and res==0:\n",
    "        result = 0\n",
    "        flag = True\n",
    "        print('Warning intv is 0')\n",
    "        print(df_image['ImagePositionPatient_2'])\n",
    "    if res2 == res:\n",
    "        result = res\n",
    "    else:\n",
    "        result = res\n",
    "        flag = True\n",
    "        print('Warning intv may wrong',res,res2)\n",
    "        print(df_image['ImagePositionPatient_2'])\n",
    "    \n",
    "    return result \n",
    "\n",
    "def InstanceNumber2windows_min_max(df_image,num):\n",
    "    try:     \n",
    "        WL = InstanceNumber2data_element(df_image, num, 'WindowCenter')\n",
    "        WW = InstanceNumber2data_element(df_image, num, 'WindowWidth')\n",
    "    except:\n",
    "        print(\"Warning! Window Center or Width is empty! Now use default values\")\n",
    "        WL , WW = 250 , 1500\n",
    "        \n",
    "    minHU = int( WL-WW/2 )\n",
    "    maxHU = minHU + int(WW)\n",
    "    return [minHU , maxHU]\n",
    "\n",
    "\n",
    "class ASerial:\n",
    "    P=-1\n",
    "    D=-1\n",
    "    S=-1\n",
    "    name = ''\n",
    "    def __init__(self, path_str):\n",
    "        self.path = path_str\n",
    "        self.getP()\n",
    "        self.getD()\n",
    "        self.getS()\n",
    "        self.convert_path()\n",
    "        \n",
    "    def getP(self, target = 'DeepLesion_', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.P = int(ss)\n",
    "        \n",
    "    def getD(self, target = '/D', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.D = int(ss)\n",
    "        \n",
    "    def getS(self, target = '/S', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.S = int(ss)\n",
    "        \n",
    "    def convert_path(self):\n",
    "        self.name = '%06d_%02d_%02d'%(self.P, self.D, self.S)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json, yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from collections import OrderedDict\n",
    "from pycocotools import mask as cocomask\n",
    "from pycocotools import coco as cocoapi\n",
    "\n",
    "\n",
    "\n",
    "def replacer(s, newstring, index, nofail=False):\n",
    "    # raise an error if index is outside of the string\n",
    "    if not nofail and index not in range(len(s)):\n",
    "        raise ValueError(\"index outside given string\")\n",
    "\n",
    "    # if not erroring, but the index is still not in the correct range..\n",
    "    if index < 0:  # add it to the beginning\n",
    "        return newstring + s\n",
    "    if index > len(s):  # add it to the end\n",
    "        return s + newstring\n",
    "\n",
    "    # insert the new string between \"slices\" of the original\n",
    "    return s[:index] + newstring + s[index + 1:]\n",
    "\n",
    "def convert_file_name(name,S='/'):\n",
    "    ix = name.rfind('_')\n",
    "    return replacer(name,S,ix)\n",
    "\n",
    "def file_name2id(name):\n",
    "    name.replace('.png','')\n",
    "    name.replace('_','')\n",
    "    return int('1' + name)\n",
    "    \n",
    "def get_image_size( s ):\n",
    "    num = list( map( int , s.split(',')))\n",
    "    return num[0] , num[1]\n",
    "\n",
    "def get_spacing( s ):\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[0] , num[1] , num[2]\n",
    "\n",
    "\n",
    "def get_z_position( df ):\n",
    "    s = df.loc['Normalized_lesion_location']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[2]\n",
    "    \n",
    "def get_slice_no( df ):\n",
    "    s = df.loc['Key_slice_index']\n",
    "    return int(s)\n",
    "\n",
    "def get_windows( df ):\n",
    "    s = df.loc[ 'DICOM_windows']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num\n",
    "\n",
    "\n",
    "def get_segmentation():\n",
    "    return []\n",
    "\n",
    "def get_bbox( df ):\n",
    "    s = df.loc['Bounding_boxes']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    num[2] = num[2]-num[0]\n",
    "    num[3] = num[3]-num[1]\n",
    "    return num \n",
    "\n",
    "def get_noise( df ):\n",
    "    s = df.loc['Possibly_noisy']\n",
    "    num = int(s)\n",
    "    return num\n",
    "\n",
    "def get_area( df ):\n",
    "    s = df.loc['Lesion_diameters_Pixel_']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[0]*num[1]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "newcats = [{'supercategory': 'DeepLesion', 'id': 1, 'name': 'abdomen'},\n",
    "           {'supercategory': 'DeepLN', 'id': 2, 'name': 'abdomen LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 3, 'name': 'adrenal'},\n",
    "           {'supercategory': 'DeepLN', 'id': 4, 'name': 'axillary LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 5, 'name': 'bone'},\n",
    "           {'supercategory': 'DeepLN', 'id': 6, 'name': 'inguinal LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 7, 'name': 'kidney'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 8, 'name': 'liver'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 9, 'name': 'lung'},\n",
    "           {'supercategory': 'DeepLN', 'id': 10, 'name': 'mediastinum LN'},\n",
    "           {'supercategory': 'DeepLN', 'id': 11, 'name': 'neck LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 12, 'name': 'ovary'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 13, 'name': 'pancreas'},\n",
    "           {'supercategory': 'DeepLN', 'id': 14, 'name': 'pelvic LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 15, 'name': 'pelvis'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 16, 'name': 'pleural'},\n",
    "           {'supercategory': 'DeepLN', 'id': 17, 'name': 'retroperitoneal LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 18, 'name': 'soft tissue'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 19, 'name': 'spleen'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 20, 'name': 'stomach'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 21, 'name': 'thyroid'} ]\n",
    "\n",
    "def get_21_lesion_location_cls():\n",
    "    D_cls = {}\n",
    "    for d in newcats:\n",
    "        id_ = d['id']\n",
    "        name = d['name']\n",
    "        D_cls[name] = id_\n",
    "    return D_cls\n",
    "\n",
    "D_cls = get_21_lesion_location_cls()\n",
    "\n",
    "def get_category_id( location , Dict ):\n",
    "    return Dict[location]\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def replace_png_path(s):\n",
    "    cs = s.replace('AutoRecist/Inputs' , 'AutoRecist/Pngs')\n",
    "    return cs\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json, yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from pycocotools import mask as cocomask\n",
    "from pycocotools import coco as cocoapi\n",
    "\n",
    "\n",
    "class DeepLesion():\n",
    "    \"\"\"\n",
    "        DL class to convert annotations to COCO Json format\n",
    "    \"\"\"\n",
    "    def __init__(self, df,image_id_start=0,annotation_id_start=0, savename='a.json'):\n",
    "        self.image_id_start = image_id_start\n",
    "        self.annotation_id_start = annotation_id_start\n",
    "        self.df = df \n",
    "        self.info = {\"year\" : 2021,\n",
    "                     \"version\" : \"2.0\",\n",
    "                     \"description\" : \"Covert Weasis to Json format\",\n",
    "                     \"contributor\" : \"HY,JM,BZ,LS,FSA\",\n",
    "                     \"url\" : \"http:// /\",\n",
    "                     \"date_created\" : \"20211129\"\n",
    "                    }\n",
    "        self.licenses = [{\"id\": 1,\n",
    "                          \"name\": \"Attribution-NonCommercial\",\n",
    "                          \"url\": \"http:// /\"\n",
    "                         }]\n",
    "\n",
    "        self.categories = newcats\n",
    "        \n",
    "        self.images, self.annotations = self.__get_image_annotation_pairs__(self.df)\n",
    "        json_data = {\"info\" : self.info,\n",
    "                     \"images\" : self.images,\n",
    "                     \"licenses\" : self.licenses,\n",
    "                     \"annotations\" : self.annotations,\n",
    "                     \"categories\" : self.categories}\n",
    "\n",
    "        with open(savename, \"w\") as jsonfile:\n",
    "            json.dump(json_data, jsonfile, sort_keys=True, indent=4)\n",
    "            \n",
    "    def change_df(self , df , savename = 'temp.json'):\n",
    "        self.df = df \n",
    "\n",
    "        self.images, self.annotations = self.__get_image_annotation_pairs__(self.df)\n",
    "        json_data = {\"info\" : self.info,\n",
    "                     \"images\" : self.images,\n",
    "                     \"licenses\" : self.licenses,\n",
    "                     \"annotations\" : self.annotations,\n",
    "                     \"categories\" : self.categories}\n",
    "\n",
    "        with open(savename, \"w\") as jsonfile:\n",
    "            json.dump(json_data, jsonfile, sort_keys=True, indent=4)\n",
    "            print( 'Saved %s'%savename )\n",
    "        \n",
    "            \n",
    "    def __get_image_annotation_pairs__(self,df):\n",
    "        images = []\n",
    "        annotations = []\n",
    "        self.file_name_dict = {}\n",
    "        for i , row in df.iterrows():\n",
    "            try:\n",
    "                print(i)\n",
    "                df_image = get_dicom_header_df( row['Image File Path'] )\n",
    "                png_folder = replace_png_path(row['Image File Path'] )\n",
    "                \n",
    "                for one in df_image.index.values.tolist():\n",
    "#                     file_name = InstanceNumber2file_name(df_image, one)\n",
    "#                     file_name = os.path.join( row['Image File Path'] , file_name)\n",
    "                    file_name = os.path.join(png_folder, '%03d.png'%one)\n",
    "                    file_name = file_name.replace('/mnt/fast-disk1/mjc/AutoRecist/','')\n",
    "\n",
    "                    if file_name in self.file_name_dict:\n",
    "                        oneimageid = self.file_name_dict[file_name]\n",
    "                    else:\n",
    "                        oneimage = {}\n",
    "                        oneimage['file_name'] = file_name\n",
    "                        self.image_id_start += 1\n",
    "                        oneimageid = self.image_id_start\n",
    "                        oneimage['id'] = oneimageid\n",
    "\n",
    "                        oneimage['height'] , oneimage['width'] = int(InstanceNumber2data_element(df_image,one,'Rows')), int( InstanceNumber2data_element(df_image,one,'Columns') )\n",
    "\n",
    "                        oneimage['slice_no'] = int(one)\n",
    "                        oneimage['spacing'] = float( InstanceNumber2data_element(df_image,one,'PixelSpacing_0') )\n",
    "                        oneimage['slice_intv'] = float( get_SliceThickness(df_image) )\n",
    "                        oneimage['z_position'] = 0.5\n",
    "                        oneimage['windows'] = InstanceNumber2windows_min_max(df_image,one)\n",
    "\n",
    "                        images.append(oneimage)\n",
    "                        self.file_name_dict[file_name] = oneimageid\n",
    "\n",
    "\n",
    "            except Exception as e: print(e)\n",
    "        \n",
    "        return images, annotations\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Image Process\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Image Process is Done\n",
      "Total of 230 slice images was Processed.\n"
     ]
    }
   ],
   "source": [
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instance should be str or list')\n",
    "\n",
    "pd_str_replace(df, ['Image File Path' ], \"X:\" , \"/mnt/X-drive\")\n",
    "pd_str_replace(df, ['Image File Path' ], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "\n",
    "\n",
    "print('Initial Image Process')\n",
    "dataset = DeepLesion(df,savename='/mnt/fast-data/mjc/AutoRECIST/Annotations/inference.json')\n",
    "print('Image Process is Done')\n",
    "print('Total of {} slice images was Processed.'.format(len(dataset.images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘/mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_9Slices/tools/cache/inference_gt_roidb.pkl’: No such file or directory\n",
      "=> creating output/Lesion/superscalenet_seg/Lesion_Q5_scalenet_seg_test/data_patch_valtest\n",
      "=> creating log/Lesion/superscalenet_seg/data_patch_valtest/Lesion_Q5_scalenet_seg_test_2022-03-13-16-37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> init weights from normal distribution\n",
      "Cache ground truth roidb to /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_Q5/tools/cache/inference_gt_roidb.pkl\n",
      "Loaded dataset: inference\n",
      "Computing image aspect ratios and ordering the ratios...\n",
      "done\n",
      "Computing bounding-box regression targets...\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time cost is 7.133440732955933 sec\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "1 230\n",
      "2 230\n",
      "4 230\n",
      "class_weights are:\n",
      "tensor([0.4000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000])\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!no segms!!\n",
      "\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!no segms!!\n",
      "\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "no segms!!\n",
      "Current time cost is 49.83324384689331 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "get_ipython().system('rm /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_9Slices/tools/cache/inference_gt_roidb.pkl')\n",
    "\n",
    "get_ipython().magic('reload_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import _init_paths\n",
    "import models\n",
    "import dataset\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.seg_function import validate_seg_wo_loss as validate\n",
    "from core.oneshot_function import calib_bn_seg as calib_bn\n",
    "from utils.utils import get_model_summary\n",
    "from utils.utils import create_logger, FullModel\n",
    "\n",
    "from dataset.roidb import combined_roidb_for_training\n",
    "from roi_data.loader import RoiDataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, name = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.makedirs(sv_path)\n",
    "                save_pred(pred, sv_path, name)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                # logging.info('processing: %d batches' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                # logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc\n",
    "\n",
    "\n",
    "def parse_args(l):\n",
    "    parser = argparse.ArgumentParser(description='Test segmentation network')\n",
    "\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        required=True,\n",
    "                        type=str)\n",
    "    parser.add_argument('opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "    parser.add_argument('--bn_calib',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--mask_path',\n",
    "                        help='the path of a mask.npy',\n",
    "                        default=None,\n",
    "                        type=str)\n",
    "    args = parser.parse_args(l)\n",
    "    update_config(cfg, args)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "# experiment_name = 'Lesion_Q5_9Slices_scalenet_seg_test'\n",
    "# mask_name = 'mask_1988'\n",
    "# arglist = ['--cfg', '../experiments/lesion_Q5/%s.yaml'%experiment_name ,  \n",
    "#            '--mask_path', '../evo_files/masks/%s.npy'%mask_name,  \n",
    "#            'TEST.MODEL_FILE', '../output/Lesion/superscalenet_seg/Lesion_Q5_9Slices_superscalenet/data_patch_train/best.pth',\n",
    "#            'DATASET.ROOT','',\n",
    "#            'TRAIN.USE_FLIPPED',False]\n",
    "\n",
    "experiment_name = 'Lesion_Q5_scalenet_seg_test'\n",
    "mask_name = 'mask_1514'\n",
    "arglist = ['--cfg', '../experiments/lesion_Q5/%s.yaml'%experiment_name ,  \n",
    "           '--mask_path', '../evo_files/masks/%s.npy'%mask_name,  \n",
    "           'TEST.MODEL_FILE', '../output/Lesion/superscalenet_seg/Lesion_Q5_superscalenet_base/data_patch_train/best.pth',\n",
    "           'DATASET.ROOT','../abababab/',\n",
    "           'TRAIN.USE_FLIPPED',False]\n",
    "\n",
    "args = parse_args(arglist)\n",
    "\n",
    "logger, final_output_dir, tb_log_dir = create_logger(\n",
    "    cfg, args.cfg, 'valtest')\n",
    "\n",
    "writer_dict = {\n",
    "    'writer': SummaryWriter(tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "cudnn.enabled = cfg.CUDNN.ENABLED\n",
    "\n",
    "# build model\n",
    "model = eval('models.' + cfg.MODEL.NAME +\n",
    "             '.get_seg_model')(cfg)\n",
    "\n",
    "\n",
    "if cfg.TEST.MODEL_FILE:\n",
    "    model_state_file = cfg.TEST.MODEL_FILE\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    model_state_file = os.path.join(final_output_dir,\n",
    "                                    'final_state.pth')\n",
    "# logger.info('=> loading model from {}'.format(model_state_file))\n",
    "\n",
    "pretrained_dict = torch.load(model_state_file)\n",
    "\n",
    "D2= {}\n",
    "for key in pretrained_dict.keys():\n",
    "    if key[:6] == 'model.':\n",
    "        new_key = key[6:]\n",
    "        D2[new_key] = pretrained_dict[key]\n",
    "    else:\n",
    "        # print(key)\n",
    "        D2[key] = pretrained_dict[key]\n",
    "\n",
    "pretrained_dict = D2      \n",
    "model_dict = model.state_dict()\n",
    "\n",
    "model_keys = set(model_dict.keys())\n",
    "pretrained_keys = set(pretrained_dict.keys())\n",
    "missing_keys = model_keys - pretrained_keys\n",
    "# logger.warn('Missing keys in pretrained_dict: {}'.format(missing_keys))\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )\n",
    "\n",
    "\n",
    "test_size = (cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "\n",
    "# manully select from below.\n",
    "# ('PDS_AMGEN_20020408_22Cat_test',)\n",
    "# ('PDS_Q2_A&C_22Cat_train',)\n",
    "# ('PDS_CUIMC_22Cat_test',)\n",
    "\n",
    "test_roidb, test_ratio_list, test_ratio_index = combined_roidb_for_training(\n",
    "        ('inference',) , cfg.VAL.PROPOSAL_FILES)\n",
    "\n",
    "test_dataset = RoiDataLoader(\n",
    "    test_roidb,\n",
    "    cfg.MODEL.NUM_CLASSES,\n",
    "    training=True)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.TEST.BATCH_SIZE_PER_GPU,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "\n",
    "\n",
    "\n",
    "gpus = list(cfg.GPUS)\n",
    "# logger.info('GPU list is {}'.format(gpus))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "if args.mask_path and os.path.exists(args.mask_path):\n",
    "    masks = np.load(args.mask_path, allow_pickle=True)\n",
    "    model.module.set_active_subnet(masks)\n",
    "    # logger.info('=> setting mask from {}'.format(args.mask_path))\n",
    "    # logger.info(masks)\n",
    "else:\n",
    "    masks=None\n",
    "    logger.info('No model mask')\n",
    "\n",
    "\n",
    "mean_IoU, IoU_array, pixel_acc, mean_acc = testval_lesion(cfg, \n",
    "                                                  test_dataset, \n",
    "                                                  testloader, \n",
    "                                                  model.cuda(),\n",
    "                                                  sv_dir=mask_name, \n",
    "                                                  device=None)\n",
    "\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# This notebook is to load predicted mask for hard-disk and calculate Segmentation evaluation metics.\n",
    "# predicted mask is the output of ScaleNASv2 Test and save predicted mask.ipynb\n",
    "# \n",
    "# cp -v /mnt/fast-data/mjc/AutoRECIST/Codes/ScaleNAS/ScaleNASv1/tools/utils_test.py .\n",
    "# \n",
    "# gt box are loaded from /cache/*gt_roidb.pkl\n",
    "# gt segmentation are loaded from Hao's Raw files\n",
    "# \n",
    "# predictions are all_boxes and all_segms which both are loaded from mask_1988 png files.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # This file is for segmetation metrics evaluation in 3D\n",
    "# Edited by Jingchen around 06/20/2021\n",
    "# This file is after ScaleNAS test which save predition into png images.\n",
    "# This file load png images as predicted contours in 2D\n",
    "# load cache pkl as gold-standard contours in 2D\n",
    "# The stack 2D based on dicom-header to get 3D\n",
    "# Evaluate 3D metics of dice, IoU, over-segmetation, and under-segmetation\n",
    "# \n",
    "get_ipython().magic('reload_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import _init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from utils_test import *\n",
    "from utils_test import __get_annotation__\n",
    "from utils_metrics_3d import *\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/')\n",
    "import weasis_raw_data_api as wr\n",
    "\n",
    "\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "HEIGHT , WIDTH = 512, 512\n",
    "def get_pred_vol(oneCT , site_list , D_z_index, union_mask = True):\n",
    "    slice_no_list =list ( oneCT.keys() )\n",
    "\n",
    "    V = D_z_index.values()\n",
    "    shape_z = np.max(list(V)) + 1\n",
    "    vol_shape = (shape_z , HEIGHT , WIDTH )\n",
    "    height = vol_shape[1]\n",
    "    width = vol_shape[2]\n",
    "\n",
    "    if len(slice_no_list):\n",
    "        slice_no_list.sort()\n",
    "        vol_gt = np.zeros(vol_shape, dtype = bool)\n",
    "        vol_pred = np.zeros(vol_shape, dtype = bool)\n",
    "\n",
    "        for s in slice_no_list:\n",
    "            aroidb , bboxes , segmentations = oneCT[s]\n",
    "\n",
    "            ix = [a for a,b in enumerate(aroidb['gt_classes']) if int(b) in site_list]\n",
    "            contours = [ aroidb['segms'][int(kk)] for kk in ix ]\n",
    "            \n",
    "            for c in contours:\n",
    "                if len(c): #gt\n",
    "                    new = polys_to_mask(c , height , width)\n",
    "                    vol_gt[D_z_index[s]][new>0] = 1 \n",
    "\n",
    "\n",
    "            for j in site_list:\n",
    "                contours = segmentations[j]\n",
    "                if union_mask:\n",
    "                    #contour should be numpy.array here. list cause error of no attribute 'flatten'\n",
    "                    cc = [ contour.flatten().tolist() for contour in contours if len(contour)!=0]\n",
    "                    contours = union_ploys(cc , height, width)\n",
    "\n",
    "                for c in contours:#union pred\n",
    "                    if len(c)>=6:\n",
    "                        new = polys_to_mask([c] , height , width) \n",
    "                        vol_pred[D_z_index[s]][new>0] = 1 \n",
    "                    elif len(c):\n",
    "                        print('len pred contour is %d'%len(c))\n",
    "    return vol_pred\n",
    "\n",
    "def seperate_vol(vol_pred , reduceFP = False):\n",
    "    # vol_dict = seperate_vol(vol_pred)\n",
    "    connectivity = 2\n",
    "    from skimage import measure\n",
    "    labels_pred=measure.label(vol_pred,connectivity=connectivity)\n",
    "    l_pred,c_pred = np.unique(labels_pred , return_counts=True)\n",
    "\n",
    "\n",
    "    ix2 = l_pred>0\n",
    "    l_pred = l_pred[ix2] #background pixels are labeled as 0, so we exclude them\n",
    "    c_pred = c_pred[ix2]\n",
    "\n",
    "    if reduceFP:\n",
    "        ix2 = l_pred>0\n",
    "        for i, p in enumerate(l_pred):\n",
    "            z = np.where(labels_pred == p)[0]\n",
    "            if len( set(z) )<=1:\n",
    "                ix2[i]=False\n",
    "\n",
    "        l_pred = l_pred[ix2] #background pixels are labeled as 0, so we exclude them\n",
    "        c_pred = c_pred[ix2]\n",
    "\n",
    "\n",
    "    vol_dict = {}\n",
    "\n",
    "    for p in l_pred:\n",
    "        vp = labels_pred == p\n",
    "        vol_dict[p] = vp\n",
    "\n",
    "    return vol_dict\n",
    "\n",
    "\n",
    "\n",
    "site_list_liver = [8]\n",
    "site_list_liver_lung_LNs = [2,4,6,8,9,10,11,14,17] \n",
    "site_list_LNs = [2,4,6,10,11,14,17] \n",
    "\n",
    "site_list = site_list_liver\n",
    "user_id = 'jm4669'\n",
    "\n",
    "cache_path = './cache/'\n",
    "name = 'inference'\n",
    "# name = 'lesion_train'\n",
    "\n",
    "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\n",
    "# print('Loading cached gt_roidb from %s', cache_filepath)\n",
    "with open(cache_filepath, 'rb') as fp:\n",
    "    cached_roidb = pickle.load(fp)\n",
    "    \n",
    "roidb = cached_roidb\n",
    "\n",
    "\n",
    "\n",
    "sv_dir = mask_name\n",
    "sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "\n",
    "all_boxes = [ [ np.zeros((0,5),dtype=\"float32\") for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "all_segms = [ [ [] for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "\n",
    "for i in range(len(roidb)):\n",
    "\n",
    "    one = roidb[i]\n",
    "    onename = one['image']\n",
    "    if not os.path.exists( os.path.join( sv_path, convert_name(onename) ) ):\n",
    "        print(os.path.join(sv_path, convert_name(onename) ) , 'not exists!')\n",
    "    pred_im = Image.open(os.path.join( sv_path, convert_name(onename) ))\n",
    "    pred = np.array(pred_im)\n",
    "    for j in range(cfg.DATASET.NUM_CLASSES):\n",
    "        mask = np.asarray( pred==j , dtype=np.uint8)\n",
    "        if np.sum(mask > 0) <= 3 :\n",
    "            continue\n",
    "        segmentation, bbox, area = __get_annotation__(mask , xywh = False , bbox_score=True)\n",
    "        if segmentation and bbox:\n",
    "            all_segms[j][i] = segmentation\n",
    "            all_boxes[j][i] = bbox\n",
    "\n",
    "\n",
    "D_CT = {}\n",
    "for i , aroidb in enumerate(roidb):\n",
    "    dicom_path , png_name = os.path.split(aroidb['image'])\n",
    "    slice_no , _= os.path.splitext(png_name)\n",
    "    slice_no = int(slice_no)\n",
    "    if slice_no != aroidb['slice_no']:\n",
    "        print('following slice numbers are not consistence.')\n",
    "        print(dicom_path,slice_no,aroidb['slice_no'])\n",
    "\n",
    "    segmentations = {}\n",
    "    bboxes = {}\n",
    "    for j in site_list:\n",
    "        segmentations[j] = all_segms[j][i]\n",
    "        bboxes[j] = all_boxes[j][i]\n",
    "\n",
    "    if dicom_path not in D_CT:\n",
    "        D_CT[dicom_path] = {}\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "    else:\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "\n",
    "name\n",
    "\n",
    "Metrics_vol = []\n",
    "keys = list(D_CT.keys())\n",
    "for k in keys:\n",
    "#     if 'COU-AA-302' in k:\n",
    "#         site_list = site_list_LNs\n",
    "#     else:\n",
    "#         site_list = site_list_liver_lung_LNs\n",
    "\n",
    "    image_series_path = k.replace('/Pngs/' , '/Inputs/')    \n",
    "\n",
    "    df_image = get_dicom_header_df( image_series_path )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "    oneCT = remove_single_slice_segms(D_CT[k])\n",
    "    vol_pred = get_pred_vol(oneCT , site_list , D_z_index, union_mask = False)\n",
    "    vol_dict = seperate_vol(vol_pred)\n",
    "\n",
    "\n",
    "\n",
    "    image_series = wr.dicom_header(image_series_path)\n",
    "    assert(len(image_series) == vol_pred.shape[0])\n",
    "\n",
    "    for tumor_index in vol_dict:\n",
    "        mask_volume = vol_dict[tumor_index]\n",
    "        weasis_raw_data = wr.create(image_series, mask_volume)\n",
    "\n",
    "        file_folder = os.path.join(SAVE_PATH , 'RawToWeasis')\n",
    "        if not os.path.exists(file_folder):\n",
    "            os.makedirs(file_folder)\n",
    "        file_name = wr.unique(image_series, tumor_index, user_id)\n",
    "        file_name = os.path.join(file_folder,file_name)\n",
    "        wr.write(weasis_raw_data, file_name)\n",
    "\n",
    "        Metrics_vol.append( [image_series_path , file_name , user_id ])\n",
    "\n",
    "\n",
    "\n",
    "    df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                              columns = ['Image File Path','Contour File Path','Uni']) \n",
    "    df_metrics.to_csv('RawToWeasis.csv' , index=False)\n",
    "    print('finished ', k )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

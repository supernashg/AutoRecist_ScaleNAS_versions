{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to load predicted mask for hard-disk and calculate Segmentation evaluation metics.\n",
    "predicted mask is the output of ScaleNASv2 Test and save predicted mask.ipynb\n",
    "\n",
    "cp -v /mnt/fast-data/mjc/AutoRECIST/Codes/ScaleNAS/ScaleNASv1/tools/utils_test.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # This file is for segmetation metrics evaluation in 3D\n",
    "# Edited by Jingchen around 06/20/2021\n",
    "# This file is after ScaleNAS test which save predition into png images.\n",
    "# This file load png images as predicted contours in 2D\n",
    "# load cache pkl as gold-standard contours in 2D\n",
    "# The stack 2D based on dicom-header to get 3D\n",
    "# Evaluate 3D metics of dice, IoU, over-segmetation, and under-segmetation\n",
    "# \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import _init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from utils_test import *\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, batchname = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                save_pred(pred, sv_path, batchname)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d images' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached gt_roidb from %s ./cache/Cougar302_80pts_test_gt_roidb.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/fast-data/mjc/envs/Lesions/lib/python3.6/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== 0\n",
      "======================================== 500\n",
      "======================================== 1000\n",
      "======================================== 1500\n",
      "FROC:FP in no-lesion-images:  238\n",
      "========================================\n",
      "Recall@0.5=28.99%\n",
      "Recall@0.6=35.13%\n",
      "Mean FROC is 32.06\n",
      "========================================\n",
      "FROC:FP in no-lesion-images:  238\n"
     ]
    }
   ],
   "source": [
    "site_ix =17\n",
    "# site_list = [2,4,6,10,11,14,17] # LN list\n",
    "site_list = list(range(1,22))\n",
    "cache_path = './cache/'\n",
    "name = 'Cougar302_80pts_test'\n",
    "# name = 'lesion_train'\n",
    "\n",
    "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\n",
    "print('Loading cached gt_roidb from %s', cache_filepath)\n",
    "with open(cache_filepath, 'rb') as fp:\n",
    "    cached_roidb = pickle.load(fp)\n",
    "    \n",
    "roidb = cached_roidb\n",
    "\n",
    "\n",
    "from utils_test import __get_annotation__\n",
    "\n",
    "sv_dir = mask_name = 'mask_1514'\n",
    "sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "\n",
    "all_boxes = [ [ np.zeros((0,5),dtype=\"float32\") for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "all_segms = [ [ [] for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "\n",
    "for i in range(len(roidb)):\n",
    "    if i%500==0:\n",
    "        print('='*40,i)\n",
    "\n",
    "    one = roidb[i]\n",
    "    onename = one['image']\n",
    "    pred_im = Image.open(os.path.join(sv_path, convert_name(onename) ))\n",
    "    pred = np.array(pred_im)\n",
    "    for j in range(cfg.DATASET.NUM_CLASSES):\n",
    "        mask = np.asarray( pred==j , dtype=np.uint8)\n",
    "        if np.sum(mask > 0) <= 3 :\n",
    "            continue\n",
    "        segmentation, bbox, area = __get_annotation__(mask , xywh = False , bbox_score=True)\n",
    "        if segmentation and bbox:\n",
    "            all_segms[j][i] = segmentation\n",
    "            all_boxes[j][i] = bbox\n",
    "\n",
    "\n",
    "gt_boxes = get_gt_boxes(cached_roidb,site_ix)\n",
    "avgFP=[0.5,1,2,3,4,8,16,32,64]\n",
    "iou_th=0.5\n",
    "\n",
    "stack_box = all_boxes[site_ix]\n",
    "result, valid_avgFP = sens_at_FP(stack_box, gt_boxes, avgFP, iou_th)\n",
    "print('='*40)\n",
    "for recall,fp in zip(result,valid_avgFP):\n",
    "    print('Recall@%.1f=%.2f%%' % (fp, recall*100))\n",
    "#TODO: when num of valid_avgFP < 6,is FROC correct?\n",
    "print('Mean FROC is %.2f'% np.mean(np.array(result[:6])*100))\n",
    "print('='*40)\n",
    "\n",
    "\n",
    "sens, fp_per_img, scores_th = FROC(stack_box, gt_boxes, iou_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.28994083,  0.35133136]), array([ 0.5      ,  0.6048913]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, valid_avgFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_box_allsite_merge = get_gt_boxes(cached_roidb,None)\n",
    "\n",
    "def get_pred_box_allsite_merge(all_boxes):\n",
    "    class_num = len(all_boxes)\n",
    "    lesion_num = len(all_boxes[0])\n",
    "    merge_boxes = [ np.zeros((0,5),dtype=\"float32\") for _ in range(lesion_num ) ] \n",
    "    for i in range(lesion_num):\n",
    "        box = []\n",
    "        for j in range(1,class_num):\n",
    "            box.extend(all_boxes[j][i])\n",
    "        merge_boxes[i] = box if box else np.zeros((0,5),dtype=\"float32\")\n",
    "    return merge_boxes\n",
    "            \n",
    "\n",
    "pred_box_allsite_merge = get_pred_box_allsite_merge(all_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROC:FP in no-lesion-images:  0\n",
      "========================================\n",
      "Recall@0.5=15.88%\n",
      "Recall@1.0=28.50%\n",
      "Recall@1.4=39.90%\n",
      "Mean FROC is 28.09\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "result, valid_avgFP = sens_at_FP(pred_box_allsite_merge, gt_box_allsite_merge , avgFP, 0.5)\n",
    "\n",
    "print('='*40)\n",
    "for recall,fp in zip(result,valid_avgFP):\n",
    "    print('Recall@%.1f=%.2f%%' % (fp, recall*100))\n",
    "#TODO: when num of valid_avgFP < 6,is FROC correct?\n",
    "print('Mean FROC is %.2f'% np.mean(np.array(result[:6])*100))\n",
    "print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.26613579,  0.51760268,  0.57795474]),\n",
       " array([ 0.5       ,  1.        ,  1.17771739]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, valid_avgFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROC:FP in no-lesion-images:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   4.19111484e-04,   8.38222967e-04, ...,\n",
       "         5.77535624e-01,   5.77954736e-01,   5.78373847e-01])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FROC(pred_box_allsite_merge, gt_box_allsite_merge , 0.25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_box == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-916a8342b5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     print(len(a))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_box_allsite_merge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/fast-data/mjc/envs/Lesions/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "# for a in pred_box_allsite_merge:\n",
    "#     print(len(a))\n",
    "\n",
    "a = np.vstack(pred_box_allsite_merge[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "D_CT = {}\n",
    "for i , aroidb in enumerate(roidb):\n",
    "    dicom_path , png_name = os.path.split(aroidb['image'])\n",
    "    slice_no , _= os.path.splitext(png_name)\n",
    "    slice_no = int(slice_no)\n",
    "    if slice_no != aroidb['slice_no']:\n",
    "        print(dicom_path,slice_no,aroidb['slice_no'])\n",
    "\n",
    "    segmentations = {}\n",
    "    bboxes = {}\n",
    "    for j in site_list:\n",
    "        segmentations[j] = all_segms[j][i]\n",
    "        bboxes[j] = all_boxes[j][i]\n",
    "\n",
    "    if dicom_path not in D_CT:\n",
    "        D_CT[dicom_path] = {}\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "    else:\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AUTO_RECIST CIA-LAB Image and Contour 2020-10-01.xlsx'\n",
    "# json_name = 'CUIMC20201027.json'\n",
    "\n",
    "# DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AMGEN_20020408_CIA-LAB_Image_And_Contour_2020-10-21.xlsx'\n",
    "# json_name = 'AMGEN_20020408_20201027.json'\n",
    "\n",
    "# DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AMGEN_PRIME_CIA-LAB_Image_And_Contour_2020-10-21.xlsx'\n",
    "# json_name = 'AMGEN_PRIME_20201027.json'\n",
    "\n",
    "DL_info = '/mnt/fast-data/mjc/AutoRECIST/Inputs/Prepare 100 Cougar 302 annotated cases for Jingchen.xlsx'\n",
    "df = pd.read_excel(DL_info)\n",
    "\n",
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instence should be str or list')\n",
    "\n",
    "pd_str_replace(df, ['Image File Path' , 'Contour File Path'], \"X:\" , \"/mnt/W-drive\")\n",
    "pd_str_replace(df, ['Image File Path' , 'Contour File Path'], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/W-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/W-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Contour File Path'], \"/mnt/W-drive/ConvWeasisToRaw\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "sys.path.append('/mnt/fast-data/mjc/DeepLesion/Codes/CollectData/')\n",
    "\n",
    "from print_weasis_raw_data import WeasisRawDataPrinter\n",
    "from read_weasis_raw_data import WeasisRawFileReader\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "data_path = \"\"\n",
    "metadata_path = \"/mnt/fast-data/mjc/AutoRECIST/Outputs/Dicom_header\"\n",
    "if not os.path.exists(metadata_path):\n",
    "    os.mkdir(metadata_path)\n",
    "\n",
    "\n",
    "D_dir2header_df = {}\n",
    "\n",
    "\n",
    "def get_dicom_header_df(image_dir , labels = []):\n",
    "    global D_dir2header_df\n",
    "    if image_dir in D_dir2header_df:\n",
    "        return D_dir2header_df[image_dir]\n",
    "\n",
    "    # image_dir = row['Image File Path']\n",
    "\n",
    "\n",
    "    labels = ['ImageName','InstanceNumber',\n",
    "            'BitsAllocated', 'BitsStored', 'Columns', 'HighBit', \n",
    "            'ImageOrientationPatient_0', 'ImageOrientationPatient_1', 'ImageOrientationPatient_2',\n",
    "            'ImageOrientationPatient_3', 'ImageOrientationPatient_4', 'ImageOrientationPatient_5',\n",
    "            'ImagePositionPatient_0', 'ImagePositionPatient_1', 'ImagePositionPatient_2',\n",
    "            'Modality', 'PatientID', 'PhotometricInterpretation', 'PixelRepresentation',\n",
    "            'PixelSpacing_0', 'PixelSpacing_1', 'RescaleIntercept', 'RescaleSlope', 'Rows', 'SOPInstanceUID',\n",
    "            'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID', 'StudyInstanceUID', \n",
    "            'WindowCenter', 'WindowWidth', \n",
    "        ] if not labels else labels\n",
    "\n",
    "    data = {l: [] for l in labels}\n",
    "    \n",
    "    ctList = os.listdir(image_dir)\n",
    "    ctList.sort()\n",
    "\n",
    "    for image in ctList:\n",
    "        if '.dcm' not in image:\n",
    "            continue\n",
    "        if os.path.getsize(os.path.join(image_dir, image)) < 5*1024:\n",
    "            print('%s size < 5kb skiped!'%os.path.join(image_dir, image) )\n",
    "            continue\n",
    "        data[\"ImageName\"].append(image)\n",
    "\n",
    "        ds = pydicom.dcmread(os.path.join(image_dir, image))\n",
    "        for metadata in ds.dir():\n",
    "            if metadata not in data and metadata not in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                continue\n",
    "            if metadata != \"PixelData\":\n",
    "                metadata_values = getattr(ds, metadata)\n",
    "                if type(metadata_values) == pydicom.multival.MultiValue and metadata not in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                    for i, v in enumerate(metadata_values):\n",
    "                        data[f\"{metadata}_{i}\"].append(v)  \n",
    "                else:\n",
    "                    if type(metadata_values) == pydicom.multival.MultiValue and metadata in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                        data[metadata].append(metadata_values[0])\n",
    "                    else:\n",
    "                        data[metadata].append(metadata_values)\n",
    "\n",
    "    df_image = pd.DataFrame(data).set_index(\"InstanceNumber\")\n",
    "    D_dir2header_df[image_dir] = df_image\n",
    "    return df_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Delete df row 76\n",
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "def compare_site(location , site_list):\n",
    "    for i in site_list:\n",
    "        if location == ix2labelname(i):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# site_list = [2,4,6,10,11,14,17]\n",
    "# site_list = list(range(1,22))\n",
    "from utils_metrics_3d import *\n",
    "Metrics_vol = []\n",
    "Missed_vol = []\n",
    "previous_CT_ss = ''\n",
    "for _,row in df.iterrows():\n",
    "    if _ in [76]:\n",
    "        print('Delete df row {}'.format(_))\n",
    "        continue\n",
    "\n",
    "    if _%100==0 or _<10:\n",
    "        print(_)\n",
    "    if not compare_site(row.Location , site_list):\n",
    "#         only calculate one lesion site\n",
    "        continue\n",
    "    \n",
    "    ## convert png numbers to dicom slice numbers.\n",
    "    df_image = get_dicom_header_df( row['Image File Path'] )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "    reader = WeasisRawFileReader()\n",
    "    weasis_raw_data = reader.read_weasis_raw_file(row['Contour File Path'])\n",
    "\n",
    "    ss = row['Image File Path']\n",
    "    ss = ss.replace('/Inputs/' , '/Pngs/')\n",
    "    if ss not in D_CT:\n",
    "        print(ss , 'not in D_CT')\n",
    "\n",
    "    mask_vol = initialize_mask_vol(weasis_raw_data , D_z_index)\n",
    "\n",
    "    slice_list = weasis_raw_data.get_instance_number_array()\n",
    "    for j, one in enumerate(slice_list):\n",
    "        file_name = InstanceNumber2file_name(df_image, one)\n",
    "        file_name = os.path.join( row['Image File Path'] , file_name)   \n",
    "        mask = weasis_raw_data.get_mask_image_2d(j)\n",
    "        mask_vol[D_z_index[one]] = mask\n",
    "\n",
    "    if ss != previous_CT_ss:\n",
    "        oneCT = D_CT[ss]\n",
    "        vol_gt , vol_pred = get_gt_and_pred_vols( oneCT, site_list, mask_vol.shape, D_z_index, union_mask=False )\n",
    "        previous_CT_ss = ss\n",
    "    hit = vols_seg_results(mask_vol , vol_pred, CTname=ss, gt_keep_largest=1)\n",
    "    Metrics_vol.extend(hit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 abdomen\n",
      "2 abdomen LN\n",
      "3 adrenal\n",
      "4 axillary LN\n",
      "5 bone\n",
      "6 inguinal LN\n",
      "7 kidney\n",
      "8 liver\n",
      "9 lung\n",
      "10 mediastinum LN\n",
      "11 neck LN\n",
      "12 ovary\n",
      "13 pancreas\n",
      "14 pelvic LN\n",
      "15 pelvis\n",
      "16 pleural\n",
      "17 retroperitoneal LN\n",
      "18 soft tissue\n",
      "19 spleen\n",
      "20 stomach\n",
      "21 thyroid\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,22):\n",
    "    print(i, ix2labelname(i) )\n",
    "\n",
    "site_list = [2,4,6,10,11,14,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cougar302_80pts_test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>igt</th>\n",
       "      <th>merge</th>\n",
       "      <th>#gt</th>\n",
       "      <th>#pred</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>over_seg</th>\n",
       "      <th>under_seg</th>\n",
       "      <th>area_gt</th>\n",
       "      <th>area_pred</th>\n",
       "      <th>intersection</th>\n",
       "      <th>union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>244.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.036885</td>\n",
       "      <td>0.321174</td>\n",
       "      <td>0.441328</td>\n",
       "      <td>0.812176</td>\n",
       "      <td>0.516757</td>\n",
       "      <td>4695.881148</td>\n",
       "      <td>5717.627049</td>\n",
       "      <td>2406.418033</td>\n",
       "      <td>8007.090164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.973913</td>\n",
       "      <td>0.226037</td>\n",
       "      <td>0.266369</td>\n",
       "      <td>1.972848</td>\n",
       "      <td>0.324516</td>\n",
       "      <td>6420.097325</td>\n",
       "      <td>10340.120107</td>\n",
       "      <td>3948.935971</td>\n",
       "      <td>12000.033140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033943</td>\n",
       "      <td>486.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>530.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.125368</td>\n",
       "      <td>0.222801</td>\n",
       "      <td>0.032323</td>\n",
       "      <td>0.224904</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>1470.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.295273</td>\n",
       "      <td>0.455923</td>\n",
       "      <td>0.146463</td>\n",
       "      <td>0.518942</td>\n",
       "      <td>2809.500000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>3795.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.511292</td>\n",
       "      <td>0.676619</td>\n",
       "      <td>0.584142</td>\n",
       "      <td>0.808045</td>\n",
       "      <td>5538.000000</td>\n",
       "      <td>5838.750000</td>\n",
       "      <td>2945.250000</td>\n",
       "      <td>8278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.683621</td>\n",
       "      <td>0.812084</td>\n",
       "      <td>4.368565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16636.200000</td>\n",
       "      <td>26592.000000</td>\n",
       "      <td>9737.000000</td>\n",
       "      <td>30827.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.821413</td>\n",
       "      <td>0.901952</td>\n",
       "      <td>15.988153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44658.000000</td>\n",
       "      <td>70282.000000</td>\n",
       "      <td>31006.000000</td>\n",
       "      <td>78041.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         igt  merge    #gt       #pred   iou_score  dice_score    over_seg  \\\n",
       "count  244.0  244.0  244.0  244.000000  244.000000  244.000000  244.000000   \n",
       "mean     1.0    0.0    1.0   18.036885    0.321174    0.441328    0.812176   \n",
       "std      0.0    0.0    0.0   13.973913    0.226037    0.266369    1.972848   \n",
       "min      1.0    0.0    1.0    0.000000    0.000000    0.000000    0.000000   \n",
       "5%       1.0    0.0    1.0    3.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.0    0.0    1.0    8.000000    0.125368    0.222801    0.032323   \n",
       "50%      1.0    0.0    1.0   13.000000    0.295273    0.455923    0.146463   \n",
       "75%      1.0    0.0    1.0   23.000000    0.511292    0.676619    0.584142   \n",
       "95%      1.0    0.0    1.0   45.000000    0.683621    0.812084    4.368565   \n",
       "max      1.0    0.0    1.0   58.000000    0.821413    0.901952   15.988153   \n",
       "\n",
       "        under_seg       area_gt     area_pred  intersection         union  \n",
       "count  244.000000    244.000000    244.000000    244.000000    244.000000  \n",
       "mean     0.516757   4695.881148   5717.627049   2406.418033   8007.090164  \n",
       "std      0.324516   6420.097325  10340.120107   3948.935971  12000.033140  \n",
       "min      0.003826     28.000000      0.000000      0.000000     28.000000  \n",
       "5%       0.033943    486.450000      0.000000      0.000000    530.450000  \n",
       "25%      0.224904   1122.000000    453.000000    298.000000   1470.750000  \n",
       "50%      0.518942   2809.500000   1680.000000   1012.000000   3795.500000  \n",
       "75%      0.808045   5538.000000   5838.750000   2945.250000   8278.000000  \n",
       "95%      1.000000  16636.200000  26592.000000   9737.000000  30827.800000  \n",
       "max      1.000000  44658.000000  70282.000000  31006.000000  78041.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[54]:\n",
    "\n",
    "print(name)\n",
    "df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                          columns = ['file_name','igt','merge','#gt','#pred',\n",
    "                                     'iou_score', 'dice_score', 'over_seg' , 'under_seg',\n",
    "                                     'area_gt','area_pred','intersection','union']) \n",
    "df_metrics.describe([.05, .25, .5, .75, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metrics.to_csv('%s_metrics_vol.csv'%name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cougar302_80pts_test'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SHOW_LABEL = True\n",
    "SHOW_BOX = False\n",
    "SHOW_MASK = True\n",
    "SHOW_UNION_MASK= False\n",
    "SHOW_MASK_LABEL = True\n",
    "SHOW_GT_MASK = True\n",
    "\n",
    "# site_list = range(1,len(all_boxes))\n",
    "site_list = range(1,22) #8 is liver\n",
    "savepath = '/mnt/fast-disk1/mjc/AutoRecist/Outputs/ScaleNAS_Q5/%s/Images_%s_allsites'%(mask_name,name)\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "for i , aroidb in enumerate(roidb):\n",
    "\n",
    "    image_path = os.path.join(aroidb['image'])\n",
    "    [HU1, HU2 ] = aroidb['windows']\n",
    "\n",
    "    image = load_image(image_path, HU1, HU2)\n",
    "    height,width = image.shape\n",
    "#     plt.imshow(image)\n",
    "    image = np.dstack((image,image,image))\n",
    "    if SHOW_GT_MASK:\n",
    "        ix = [a for a,b in enumerate(aroidb['gt_classes']) if int(b) in site_list]\n",
    "        contours = [ aroidb['segms'][int(kk)] for kk in ix ]\n",
    "        if not contours:\n",
    "            continue\n",
    "        colors = [0,0,255]\n",
    "        for c in contours:\n",
    "            c = [ np.int64( np.reshape(c,(-1,2)) ) for c in c]\n",
    "            if len(c):\n",
    "                image = cv2.drawContours(image, c, -1, colors, 1)\n",
    "#             c = np.reshape(c,(-1,2))\n",
    "#             if c.shape[0]:\n",
    "#                 image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "    \n",
    "    if SHOW_MASK:\n",
    "        for j in site_list:\n",
    "            contours = all_segms[j][i]\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            label = ix2labelname(j)\n",
    "            for c in contours:\n",
    "                c = np.reshape(c,(-1,2))\n",
    "                if c.shape[0]:\n",
    "                    image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "                    if SHOW_MASK_LABEL:\n",
    "                        x,y,_,_ =ploy2boxes(c)\n",
    "                        template = \"{}\"\n",
    "                        if len(label)>=9:\n",
    "                            label=label[:3]+label[-3:]\n",
    "            \n",
    "                        s = template.format(label)\n",
    "                        cv2.putText(\n",
    "                            image, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, .5, colors, 1\n",
    "                        )  \n",
    "    \n",
    "\n",
    "    if SHOW_UNION_MASK:\n",
    "        for j in site_list:\n",
    "            contours = all_segms[j][i]\n",
    "            cc = [ contour.flatten().tolist() for contour in contours if len(contour)!=0]\n",
    "            contours = union_ploys(cc , height, width)\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            label = ix2labelname(j)\n",
    "\n",
    "            for c in contours:\n",
    "                c = np.reshape(c,(-1,2))\n",
    "                if c.shape[0]:\n",
    "                    image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "                    if SHOW_MASK_LABEL:\n",
    "                        x,y,_,_ =ploy2boxes(c)\n",
    "                        template = \"{}\"\n",
    "                        if len(label)>=9:\n",
    "                            label=label[:3]+label[-3:]\n",
    "            \n",
    "                        s = template.format(label)\n",
    "                        cv2.putText(\n",
    "                            image, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, .5, colors, 1\n",
    "                        )        \n",
    "\n",
    "    if SHOW_BOX:\n",
    "        for j in site_list:\n",
    "            colors = compute_colors_for_labels(j)\n",
    "            for box in all_boxes[j][i]:\n",
    "                \n",
    "                if box.shape[0]:\n",
    "                    top_left, bottom_right = box[:2].tolist(), box[2:4].tolist()\n",
    "                    image = cv2.rectangle(image, tuple(np.int64(top_left).tolist()), tuple(np.int64(bottom_right).tolist()), colors, 1)\n",
    "                \n",
    "            \n",
    "    \n",
    "    cv2.imwrite( os.path.join(savepath, '%06d.png'%aroidb['id'] ), image )\n",
    "print('saved {} images to {}'.format(i+1,savepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd  /Users/jingchen/OneDrive/OneDrive - cumc.columbia.edu/AutoRECIST/ImageResults/ScaleNAS_Q5/mask_1514/\n",
    "rsync -avzh --progress jm4669@radio-gpu.cpmc.columbia.edu:/mnt/fast-disk1/mjc/AutoRecist/Outputs/ScaleNAS_Q5/mask_1514/Images_Cougar302_80pts_test_allsites . \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "case = 1668\n",
    "pname = 'BAILN'\n",
    "for aroidb in roidb:\n",
    "    if pname in aroidb['image']:\n",
    "        print(aroidb['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.iloc[76]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_lesions)",
   "language": "python",
   "name": "conda_lesions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

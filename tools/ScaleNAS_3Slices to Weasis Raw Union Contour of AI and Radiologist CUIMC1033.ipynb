{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CT_EXCEL_FILE = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AMGEN_20020408_CIA-LAB_Image_And_Contour_2022-01-10.xlsx'\n",
    "# CT_EXCEL_FILE = '/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS_AUTO_RECIST CIA-LAB Image and Contour 2020-10-01.xlsx'\n",
    "CT_EXCEL_FILE ='/mnt/fast-data/mjc/AutoRECIST/Inputs/PDS New 1033 CUIMC cases 2021-12-22.xlsx'\n",
    "SAVE_PATH = '/mnt/fast-disk1/refine_gt/'\n",
    "\n",
    "import pandas as pd\n",
    "df_all = pd.read_excel(CT_EXCEL_FILE)\n",
    "\n",
    "print(df_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_all # a liver lesions case\n",
    "\n",
    "df = df.drop_duplicates(subset=['Image File Path'], keep='first')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from math import ceil, floor\n",
    "import cv2\n",
    "import sys\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def window_image(img, window_center,window_width, intercept, slope):\n",
    "    \n",
    "#     window_center,window_width = 50 ,100\n",
    "    img = (img*slope +intercept)\n",
    "    img_min = window_center - window_width//2\n",
    "    img_max = window_center + window_width//2\n",
    "    img[img<img_min] = img_min\n",
    "    img[img>img_max] = img_max\n",
    "    return img \n",
    "\n",
    "\n",
    "def get_first_of_dicom_field_as_int(x):\n",
    "    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n",
    "    if type(x) == pydicom.multival.MultiValue:\n",
    "        return int(x[0])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def get_windowing(data):\n",
    "    dicom_fields = [data[('0028','1050')].value, #window center\n",
    "                    data[('0028','1051')].value, #window width\n",
    "                    data[('0028','1052')].value, #intercept\n",
    "                    data[('0028','1053')].value] #slope\n",
    "    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]\n",
    "\n",
    "def _normalize(img):\n",
    "    if img.max() == img.min():\n",
    "        return np.zeros(img.shape)-1\n",
    "    return 2 * (img - img.min())/(img.max() - img.min()) - 1\n",
    "\n",
    "def normalize_minmax(img):\n",
    "    mi, ma = img.min(), img.max()\n",
    "    if mi == ma:\n",
    "        return np.zeros(img.shape)-1\n",
    "    return 2*(img - mi) / (ma - mi) - 1\n",
    "\n",
    "def getName(s):\n",
    "    ix1 = s.rfind('/')\n",
    "    ix2 = s.rfind('.')\n",
    "    return s[ix1:ix2]\n",
    "\n",
    "\n",
    "def _read(path, desired_size = (512,512)):\n",
    "    \"\"\"Will be used in DataGenerator\"\"\"\n",
    "\n",
    "    try:\n",
    "        data = pydicom.read_file(path)\n",
    "        image = data.pixel_array\n",
    "        window_center , window_width, intercept, slope = get_windowing(data)\n",
    "        \n",
    "        image_windowed = window_image(image, window_center, window_width, intercept, slope)\n",
    "        img = normalize_minmax(image_windowed)\n",
    "\n",
    "    except:\n",
    "        img = np.zeros(desired_size[:2])-1\n",
    "    \n",
    "    if img.shape[:2] != desired_size[:2]:\n",
    "        print(\"image shape is not desired size. Interpolation is done.\")\n",
    "        img = cv2.resize(img, desired_size[:2], interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "\n",
    "D_dir2header_df = {}\n",
    "\n",
    "\n",
    "def get_dicom_header_df(image_dir , labels = []):\n",
    "    global D_dir2header_df\n",
    "    if image_dir in D_dir2header_df:\n",
    "        return D_dir2header_df[image_dir]\n",
    "\n",
    "    # image_dir = row['Image File Path']\n",
    "\n",
    "\n",
    "    labels = ['ImageName','InstanceNumber',\n",
    "            'BitsAllocated', 'BitsStored', 'Columns', 'HighBit', \n",
    "            'ImageOrientationPatient_0', 'ImageOrientationPatient_1', 'ImageOrientationPatient_2',\n",
    "            'ImageOrientationPatient_3', 'ImageOrientationPatient_4', 'ImageOrientationPatient_5',\n",
    "            'ImagePositionPatient_0', 'ImagePositionPatient_1', 'ImagePositionPatient_2',\n",
    "            'Modality', 'PatientID', 'PhotometricInterpretation', 'PixelRepresentation',\n",
    "            'PixelSpacing_0', 'PixelSpacing_1', 'RescaleIntercept', 'RescaleSlope', 'Rows', 'SOPInstanceUID',\n",
    "            'SamplesPerPixel', 'SeriesInstanceUID', 'StudyID', 'StudyInstanceUID', \n",
    "            'WindowCenter', 'WindowWidth', \n",
    "        ] if not labels else labels\n",
    "\n",
    "    data = {l: [] for l in labels}\n",
    "    \n",
    "    ctList = os.listdir(image_dir)\n",
    "    ctList.sort()\n",
    "\n",
    "    for image in ctList:\n",
    "        if '.dcm' not in image:\n",
    "            continue\n",
    "        if os.path.getsize(os.path.join(image_dir, image)) < 5*1024:\n",
    "            print('%s size < 5kb skiped!'%os.path.join(image_dir, image) )\n",
    "            continue\n",
    "        data[\"ImageName\"].append(image)\n",
    "\n",
    "        ds = pydicom.dcmread(os.path.join(image_dir, image))\n",
    "        for metadata in ds.dir():\n",
    "            if metadata not in data and metadata not in ['ImageOrientationPatient','ImagePositionPatient','PixelSpacing']:\n",
    "                continue\n",
    "            if metadata != \"PixelData\":\n",
    "                metadata_values = getattr(ds, metadata)\n",
    "                if type(metadata_values) == pydicom.multival.MultiValue and metadata not in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                    for i, v in enumerate(metadata_values):\n",
    "                        data[f\"{metadata}_{i}\"].append(v)  \n",
    "                else:\n",
    "                    if type(metadata_values) == pydicom.multival.MultiValue and metadata in [\"WindowCenter\", \"WindowWidth\"]:\n",
    "                        data[metadata].append(metadata_values[0])\n",
    "                    else:\n",
    "                        data[metadata].append(metadata_values)\n",
    "\n",
    "    df_image = pd.DataFrame(data).set_index(\"InstanceNumber\")\n",
    "    D_dir2header_df[image_dir] = df_image\n",
    "    return df_image\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "def InstanceNumber2file_name(df_image, num):\n",
    "    return df_image.loc[num,'ImageName']\n",
    "\n",
    "def InstanceNumber2data_element(df_image, num, label):\n",
    "    return df_image.loc[num , label]\n",
    "\n",
    "    \n",
    "def get_SliceThickness(df_image):\n",
    "    flag = False\n",
    "    L = df_image['ImagePositionPatient_2'].tolist()\n",
    "    thick = list( np.diff(L) )\n",
    "    res = float( max(set(thick), key=thick.count) )\n",
    "    res = -res if res < 0 else res\n",
    "    \n",
    "    L.sort()\n",
    "    thick2 = list( np.diff(L) )\n",
    "    res2 = float( max(set(thick2), key=thick2.count) )\n",
    "    if res2 ==0 and res==0:\n",
    "        result = 0\n",
    "        flag = True\n",
    "        print('Warning intv is 0')\n",
    "        print(df_image['ImagePositionPatient_2'])\n",
    "    if res2 == res:\n",
    "        result = res\n",
    "    else:\n",
    "        result = res\n",
    "        flag = True\n",
    "        print('Warning intv may wrong',res,res2)\n",
    "        print(df_image['ImagePositionPatient_2'])\n",
    "    \n",
    "    return result \n",
    "\n",
    "def InstanceNumber2windows_min_max(df_image,num):\n",
    "    try:     \n",
    "        WL = InstanceNumber2data_element(df_image, num, 'WindowCenter')\n",
    "        WW = InstanceNumber2data_element(df_image, num, 'WindowWidth')\n",
    "    except:\n",
    "        print(\"Warning! Window Center or Width is empty! Now use default values\")\n",
    "        WL , WW = 250 , 1500\n",
    "        \n",
    "    minHU = int( WL-WW/2 )\n",
    "    maxHU = minHU + int(WW)\n",
    "    return [minHU , maxHU]\n",
    "\n",
    "\n",
    "class ASerial:\n",
    "    P=-1\n",
    "    D=-1\n",
    "    S=-1\n",
    "    name = ''\n",
    "    def __init__(self, path_str):\n",
    "        self.path = path_str\n",
    "        self.getP()\n",
    "        self.getD()\n",
    "        self.getS()\n",
    "        self.convert_path()\n",
    "        \n",
    "    def getP(self, target = 'DeepLesion_', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.P = int(ss)\n",
    "        \n",
    "    def getD(self, target = '/D', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.D = int(ss)\n",
    "        \n",
    "    def getS(self, target = '/S', L=6):\n",
    "        ix = self.path.rfind(target) + len(target)\n",
    "        ss = self.path[ix:ix+L]\n",
    "        self.S = int(ss)\n",
    "        \n",
    "    def convert_path(self):\n",
    "        self.name = '%06d_%02d_%02d'%(self.P, self.D, self.S)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json, yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from collections import OrderedDict\n",
    "from pycocotools import mask as cocomask\n",
    "from pycocotools import coco as cocoapi\n",
    "\n",
    "\n",
    "\n",
    "def replacer(s, newstring, index, nofail=False):\n",
    "    # raise an error if index is outside of the string\n",
    "    if not nofail and index not in range(len(s)):\n",
    "        raise ValueError(\"index outside given string\")\n",
    "\n",
    "    # if not erroring, but the index is still not in the correct range..\n",
    "    if index < 0:  # add it to the beginning\n",
    "        return newstring + s\n",
    "    if index > len(s):  # add it to the end\n",
    "        return s + newstring\n",
    "\n",
    "    # insert the new string between \"slices\" of the original\n",
    "    return s[:index] + newstring + s[index + 1:]\n",
    "\n",
    "def convert_file_name(name,S='/'):\n",
    "    ix = name.rfind('_')\n",
    "    return replacer(name,S,ix)\n",
    "\n",
    "def file_name2id(name):\n",
    "    name.replace('.png','')\n",
    "    name.replace('_','')\n",
    "    return int('1' + name)\n",
    "    \n",
    "def get_image_size( s ):\n",
    "    num = list( map( int , s.split(',')))\n",
    "    return num[0] , num[1]\n",
    "\n",
    "def get_spacing( s ):\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[0] , num[1] , num[2]\n",
    "\n",
    "\n",
    "def get_z_position( df ):\n",
    "    s = df.loc['Normalized_lesion_location']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[2]\n",
    "    \n",
    "def get_slice_no( df ):\n",
    "    s = df.loc['Key_slice_index']\n",
    "    return int(s)\n",
    "\n",
    "def get_windows( df ):\n",
    "    s = df.loc[ 'DICOM_windows']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num\n",
    "\n",
    "\n",
    "def get_segmentation():\n",
    "    return []\n",
    "\n",
    "def get_bbox( df ):\n",
    "    s = df.loc['Bounding_boxes']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    num[2] = num[2]-num[0]\n",
    "    num[3] = num[3]-num[1]\n",
    "    return num \n",
    "\n",
    "def get_noise( df ):\n",
    "    s = df.loc['Possibly_noisy']\n",
    "    num = int(s)\n",
    "    return num\n",
    "\n",
    "def get_area( df ):\n",
    "    s = df.loc['Lesion_diameters_Pixel_']\n",
    "    num = list( map( float , s.split(',')))\n",
    "    return num[0]*num[1]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "newcats = [{'supercategory': 'DeepLesion', 'id': 1, 'name': 'abdomen'},\n",
    "           {'supercategory': 'DeepLN', 'id': 2, 'name': 'abdomen LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 3, 'name': 'adrenal'},\n",
    "           {'supercategory': 'DeepLN', 'id': 4, 'name': 'axillary LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 5, 'name': 'bone'},\n",
    "           {'supercategory': 'DeepLN', 'id': 6, 'name': 'inguinal LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 7, 'name': 'kidney'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 8, 'name': 'liver'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 9, 'name': 'lung'},\n",
    "           {'supercategory': 'DeepLN', 'id': 10, 'name': 'mediastinum LN'},\n",
    "           {'supercategory': 'DeepLN', 'id': 11, 'name': 'neck LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 12, 'name': 'ovary'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 13, 'name': 'pancreas'},\n",
    "           {'supercategory': 'DeepLN', 'id': 14, 'name': 'pelvic LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 15, 'name': 'pelvis'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 16, 'name': 'pleural'},\n",
    "           {'supercategory': 'DeepLN', 'id': 17, 'name': 'retroperitoneal LN'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 18, 'name': 'soft tissue'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 19, 'name': 'spleen'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 20, 'name': 'stomach'},\n",
    "           {'supercategory': 'DeepLesion', 'id': 21, 'name': 'thyroid'} ]\n",
    "\n",
    "def get_21_lesion_location_cls():\n",
    "    D_cls = {}\n",
    "    for d in newcats:\n",
    "        id_ = d['id']\n",
    "        name = d['name']\n",
    "        D_cls[name] = id_\n",
    "    return D_cls\n",
    "\n",
    "D_cls = get_21_lesion_location_cls()\n",
    "\n",
    "def get_category_id( location , Dict ):\n",
    "    return Dict[location]\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def replace_png_path(s):\n",
    "    cs = s.replace('AutoRecist/Inputs' , 'AutoRecist/Pngs')\n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json, yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from pycocotools import mask as cocomask\n",
    "from pycocotools import coco as cocoapi\n",
    "\n",
    "\n",
    "class DeepLesion():\n",
    "    \"\"\"\n",
    "        DL class to convert annotations to COCO Json format\n",
    "    \"\"\"\n",
    "    def __init__(self, df,image_id_start=0,annotation_id_start=0, savename='a.json'):\n",
    "        self.image_id_start = image_id_start\n",
    "        self.annotation_id_start = annotation_id_start\n",
    "        self.df = df \n",
    "        self.info = {\"year\" : 2021,\n",
    "                     \"version\" : \"2.0\",\n",
    "                     \"description\" : \"Covert Weasis to Json format\",\n",
    "                     \"contributor\" : \"HY,JM,BZ,LS,FSA\",\n",
    "                     \"url\" : \"http:// /\",\n",
    "                     \"date_created\" : \"20211129\"\n",
    "                    }\n",
    "        self.licenses = [{\"id\": 1,\n",
    "                          \"name\": \"Attribution-NonCommercial\",\n",
    "                          \"url\": \"http:// /\"\n",
    "                         }]\n",
    "\n",
    "        self.categories = newcats\n",
    "        \n",
    "        self.images, self.annotations = self.__get_image_annotation_pairs__(self.df)\n",
    "        json_data = {\"info\" : self.info,\n",
    "                     \"images\" : self.images,\n",
    "                     \"licenses\" : self.licenses,\n",
    "                     \"annotations\" : self.annotations,\n",
    "                     \"categories\" : self.categories}\n",
    "\n",
    "        with open(savename, \"w\") as jsonfile:\n",
    "            json.dump(json_data, jsonfile, sort_keys=True, indent=4)\n",
    "            \n",
    "    def change_df(self , df , savename = 'temp.json'):\n",
    "        self.df = df \n",
    "\n",
    "        self.images, self.annotations = self.__get_image_annotation_pairs__(self.df)\n",
    "        json_data = {\"info\" : self.info,\n",
    "                     \"images\" : self.images,\n",
    "                     \"licenses\" : self.licenses,\n",
    "                     \"annotations\" : self.annotations,\n",
    "                     \"categories\" : self.categories}\n",
    "\n",
    "        with open(savename, \"w\") as jsonfile:\n",
    "            json.dump(json_data, jsonfile, sort_keys=True, indent=4)\n",
    "            print( 'Saved %s'%savename )\n",
    "        \n",
    "            \n",
    "    def __get_image_annotation_pairs__(self,df):\n",
    "        images = []\n",
    "        annotations = []\n",
    "        self.file_name_dict = {}\n",
    "        for i , row in df.iterrows():\n",
    "            try:\n",
    "                print(i)\n",
    "                df_image = get_dicom_header_df( row['Image File Path'] )\n",
    "                png_folder = replace_png_path(row['Image File Path'] )\n",
    "                \n",
    "                for one in df_image.index.values.tolist():\n",
    "#                     file_name = InstanceNumber2file_name(df_image, one)\n",
    "#                     file_name = os.path.join( row['Image File Path'] , file_name)\n",
    "                    file_name = os.path.join(png_folder, '%03d.png'%one)\n",
    "                    file_name = file_name.replace('/mnt/fast-disk1/mjc/AutoRecist/','')\n",
    "\n",
    "                    if file_name in self.file_name_dict:\n",
    "                        oneimageid = self.file_name_dict[file_name]\n",
    "                    else:\n",
    "                        oneimage = {}\n",
    "                        oneimage['file_name'] = file_name\n",
    "                        self.image_id_start += 1\n",
    "                        oneimageid = self.image_id_start\n",
    "                        oneimage['id'] = oneimageid\n",
    "\n",
    "                        oneimage['height'] , oneimage['width'] = int(InstanceNumber2data_element(df_image,one,'Rows')), int( InstanceNumber2data_element(df_image,one,'Columns') )\n",
    "\n",
    "                        oneimage['slice_no'] = int(one)\n",
    "                        oneimage['spacing'] = float( InstanceNumber2data_element(df_image,one,'PixelSpacing_0') )\n",
    "                        oneimage['slice_intv'] = float( get_SliceThickness(df_image) )\n",
    "                        oneimage['z_position'] = 0.5\n",
    "                        oneimage['windows'] = InstanceNumber2windows_min_max(df_image,one)\n",
    "\n",
    "                        images.append(oneimage)\n",
    "                        self.file_name_dict[file_name] = oneimageid\n",
    "\n",
    "\n",
    "            except Exception as e: print(e)\n",
    "        \n",
    "        return images, annotations\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instance should be str or list')\n",
    "\n",
    "pd_str_replace(df, ['Image File Path' ], \"X:\" , \"/mnt/X-drive\")\n",
    "pd_str_replace(df, ['Image File Path' ], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "\n",
    "\n",
    "print('Initial Image Process')\n",
    "dataset = DeepLesion(df,savename='/mnt/fast-data/mjc/AutoRECIST/Annotations/inference.json')\n",
    "print('Image Process is Done')\n",
    "print('Total of {} slice images was Processed.'.format(len(dataset.images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This cell only use for CUIMC 1033 dataset because some dicom file reading issues.\n",
    "\n",
    "# targets = [\n",
    "#     'COU-AA-302_21460599/D2011_04_29/E5244/CT/S0002_4122',\n",
    "# ]\n",
    "\n",
    "\n",
    "targets = ['METNET0652/D2019_02_07/E5753/CT/S0002_2664',\n",
    "'METNET3195/D2015_06_30/E6772/CT/S0007_6775',\n",
    "'METNET3196/D2015_05_28/E0676/CT/S0006_0743',\n",
    "'METNET3199/D2015_08_27/E8663/CT/S0007_8666',\n",
    "'METNET3200/D2015_08_05/E0012/CT/S0009_0015',\n",
    "'METNET3201/D2015_09_01/E0653/CT/S0007_0656',\n",
    "'METNET2933/D2015_06_16/E7835/CT/S0004_7836',\n",
    "'METNET2934/D2015_04_24/E0185/CT/S0007_0188',\n",
    "'METNET2935/D2015_03_12/E1888/CT/S0007_2033',\n",
    "'METNET2936/D2015_08_20/E6259/CT/S0009_6823',\n",
    "'METNET2937/D2015_02_09/E2120/CT/S0010_2277',\n",
    "'METNET2938/D2015_05_21/E0892/CT/S0004_0895',\n",
    "'METNET2939/D2015_02_17/E0844/CT/S0004_0847',\n",
    "'METNET5124/D2014_09_16/E9455/CT/S0003_9458',\n",
    "'METNET5126/D2014_07_25/E5869/CT/S0003_5872',\n",
    "'METNET5127/D2014_04_09/E6205/CT/S0005_6545',\n",
    "'METNET5622/D2013_10_04/E2982/CT/S0010_2983',\n",
    "'METNET5624/D2013_09_10/E0668/CT/S0008_0671',\n",
    "'METNET5625/D2013_04_08/E7573/CT/S0003_7576',\n",
    "'METNET5629/D2013_11_21/E4705/CT/S0008_4708',\n",
    "'METNET5762/D2014_07_11/E2887/CT/S0004_2890',\n",
    "'METNET5763/D2014_12_12/E2180/CT/S0004_2183',\n",
    "'METNET5856/D2014_03_14/E2011/CT/S0002_2015',]\n",
    "\n",
    "def compare_str(a,b):\n",
    "    if a in b:\n",
    "        return True\n",
    "    if b in a:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def del_items(coco_images, ids , name_str = 'id'):\n",
    "    newimages = []\n",
    "    for image in coco_images:\n",
    "        file_id = image[name_str]\n",
    "        if file_id not in ids:\n",
    "            newimages.append(image)\n",
    "            \n",
    "    print ('previous length was {} but new length is {}'.format( len(coco_images) , len(newimages) ) )\n",
    "    return newimages\n",
    "\n",
    "\n",
    "import json\n",
    "json1_path = '/mnt/fast-data/mjc/AutoRECIST/Annotations/%s.json'\n",
    "\n",
    "\n",
    "cocos = []\n",
    "\n",
    "for oneset in ['inference']:\n",
    "    for path in [json1_path ]:\n",
    "        annotation_path = path%oneset\n",
    "        print(annotation_path)\n",
    "        json_file = open(annotation_path)\n",
    "        coco = json.load(json_file)\n",
    "        json_file.close()\n",
    "        print('images len: %d annotations len: %d' %( len(coco['images']) , len(coco['annotations']) ) )\n",
    "        cocos.append(coco)\n",
    "        \n",
    "image_ids = []\n",
    "for image in coco['images']:\n",
    "    file_name = image['file_name']\n",
    "    for t in targets:\n",
    "        if compare_str(t,file_name):\n",
    "            image_ids.append(image['id'])\n",
    "            \n",
    "print(image_ids)\n",
    "\n",
    "newimages = del_items(coco['images'] , image_ids , name_str='id')\n",
    "newannos = del_items(coco['annotations'] , image_ids , name_str='image_id')\n",
    "\n",
    "savename = '/mnt/fast-data/mjc/AutoRECIST/Annotations/inference.json'\n",
    "json_data = {\"info\" : coco['info'],\n",
    "             \"images\" : newimages,\n",
    "             \"licenses\" : coco['licenses'],\n",
    "             \"annotations\" : newannos,\n",
    "             \"categories\" : coco['categories']}\n",
    "with open(savename, \"w\") as jsonfile:\n",
    "    json.dump(json_data, jsonfile, sort_keys=True, indent=4)\n",
    "    print( 'Saved %s'%savename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "get_ipython().system('rm ./cache/inference_gt_roidb.pkl')\n",
    "\n",
    "get_ipython().magic('reload_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import _init_paths\n",
    "import models\n",
    "import dataset\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.seg_function import validate_seg_wo_loss as validate\n",
    "from core.oneshot_function import calib_bn_seg as calib_bn\n",
    "from utils.utils import get_model_summary\n",
    "from utils.utils import create_logger, FullModel\n",
    "\n",
    "from dataset.roidb import combined_roidb_for_training\n",
    "from roi_data.loader import RoiDataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, name = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.makedirs(sv_path)\n",
    "                save_pred(pred, sv_path, name)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d batches' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "#                 logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc\n",
    "\n",
    "\n",
    "def parse_args(l):\n",
    "    parser = argparse.ArgumentParser(description='Test segmentation network')\n",
    "\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        required=True,\n",
    "                        type=str)\n",
    "    parser.add_argument('opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "    parser.add_argument('--bn_calib',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--mask_path',\n",
    "                        help='the path of a mask.npy',\n",
    "                        default=None,\n",
    "                        type=str)\n",
    "    args = parser.parse_args(l)\n",
    "    update_config(cfg, args)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "# experiment_name = 'Lesion_Q5_9Slices_scalenet_seg_test'\n",
    "# mask_name = 'mask_1988'\n",
    "# arglist = ['--cfg', '../experiments/lesion_Q5/%s.yaml'%experiment_name ,  \n",
    "#            '--mask_path', '../evo_files/masks/%s.npy'%mask_name,  \n",
    "#            'TEST.MODEL_FILE', '../output/Lesion/superscalenet_seg/Lesion_Q5_9Slices_superscalenet/data_patch_train/best.pth',\n",
    "#            'DATASET.ROOT','',\n",
    "#            'TRAIN.USE_FLIPPED',False]\n",
    "\n",
    "experiment_name = 'Lesion_Q5_scalenet_seg_test'\n",
    "mask_name = 'mask_1514'\n",
    "arglist = ['--cfg', '../experiments/lesion_Q5/%s.yaml'%experiment_name ,  \n",
    "           '--mask_path', '../evo_files/masks/%s.npy'%mask_name,  \n",
    "           'TEST.MODEL_FILE', '../output/Lesion/superscalenet_seg/Lesion_Q5_superscalenet_base/data_patch_train/best.pth',\n",
    "           'DATASET.ROOT','../abababab/',\n",
    "           'TRAIN.USE_FLIPPED',False]\n",
    "\n",
    "args = parse_args(arglist)\n",
    "\n",
    "logger, final_output_dir, tb_log_dir = create_logger(\n",
    "    cfg, args.cfg, 'valtest')\n",
    "\n",
    "writer_dict = {\n",
    "    'writer': SummaryWriter(tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "cudnn.enabled = cfg.CUDNN.ENABLED\n",
    "\n",
    "# build model\n",
    "model = eval('models.' + cfg.MODEL.NAME +\n",
    "             '.get_seg_model')(cfg)\n",
    "\n",
    "\n",
    "if cfg.TEST.MODEL_FILE:\n",
    "    model_state_file = cfg.TEST.MODEL_FILE\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    model_state_file = os.path.join(final_output_dir,\n",
    "                                    'final_state.pth')\n",
    "# logger.info('=> loading model from {}'.format(model_state_file))\n",
    "\n",
    "pretrained_dict = torch.load(model_state_file)\n",
    "\n",
    "D2= {}\n",
    "for key in pretrained_dict.keys():\n",
    "    if key[:6] == 'model.':\n",
    "        new_key = key[6:]\n",
    "        D2[new_key] = pretrained_dict[key]\n",
    "    else:\n",
    "        # print(key)\n",
    "        D2[key] = pretrained_dict[key]\n",
    "\n",
    "pretrained_dict = D2      \n",
    "model_dict = model.state_dict()\n",
    "\n",
    "model_keys = set(model_dict.keys())\n",
    "pretrained_keys = set(pretrained_dict.keys())\n",
    "missing_keys = model_keys - pretrained_keys\n",
    "# logger.warn('Missing keys in pretrained_dict: {}'.format(missing_keys))\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )\n",
    "\n",
    "\n",
    "test_size = (cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "\n",
    "# manully select from below.\n",
    "# ('PDS_AMGEN_20020408_22Cat_test',)\n",
    "# ('PDS_Q2_A&C_22Cat_train',)\n",
    "# ('PDS_CUIMC_22Cat_test',)\n",
    "\n",
    "test_roidb, test_ratio_list, test_ratio_index = combined_roidb_for_training(\n",
    "        ('inference',) , cfg.VAL.PROPOSAL_FILES)\n",
    "\n",
    "test_dataset = RoiDataLoader(\n",
    "    test_roidb,\n",
    "    cfg.MODEL.NUM_CLASSES,\n",
    "    training=True)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.TEST.BATCH_SIZE_PER_GPU,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "\n",
    "\n",
    "\n",
    "gpus = list(cfg.GPUS)\n",
    "# logger.info('GPU list is {}'.format(gpus))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "if args.mask_path and os.path.exists(args.mask_path):\n",
    "    masks = np.load(args.mask_path, allow_pickle=True)\n",
    "    model.module.set_active_subnet(masks)\n",
    "    # logger.info('=> setting mask from {}'.format(args.mask_path))\n",
    "    # logger.info(masks)\n",
    "else:\n",
    "    masks=None\n",
    "    logger.info('No model mask')\n",
    "\n",
    "\n",
    "mean_IoU, IoU_array, pixel_acc, mean_acc = testval_lesion(cfg, \n",
    "                                                  test_dataset, \n",
    "                                                  testloader, \n",
    "                                                  model.cuda(),\n",
    "                                                  sv_dir=mask_name, \n",
    "                                                  device=None)\n",
    "\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instance should be str or list')\n",
    "pd_str_replace(df_all, ['Image File Path' , 'Contour File Path'], \"X:\" , \"/mnt/X-drive\")\n",
    "pd_str_replace(df_all, ['Image File Path' , 'Contour File Path'], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df_all, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df_all, ['Image File Path'], \"/mnt/X-drive/ClinicalTrialDone/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df_all, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "\n",
    "pd_str_replace(df_all, ['Contour File Path'], \"/mnt/X-drive/ConvWeasisToRaw/PDS_AUTO_RECIST\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw/PDS_AUTO_RECIST_RAW\")\n",
    "pd_str_replace(df_all, ['Contour File Path'], \"/mnt/X-drive/ConvWeasisToRaw\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n",
    "pd_str_replace(df_all, ['Contour File Path'], \"/mnt/X-drive/ConvWeasisToMatlab\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs/ConvWeasisToRaw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_ipython().magic('reload_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import _init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from utils_test import *\n",
    "from utils_test import __get_annotation__\n",
    "from utils_metrics_3d import *\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/fast-disk1/mjc/utils_codes/read_weasis_raw_v0.96/')\n",
    "import weasis_raw_data_api as wr\n",
    "\n",
    "\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "HEIGHT , WIDTH = 512, 512\n",
    "def get_pred_vol(oneCT , site_list , D_z_index, union_mask = True):\n",
    "    slice_no_list =list ( oneCT.keys() )\n",
    "\n",
    "    V = D_z_index.values()\n",
    "    shape_z = np.max(list(V)) + 1\n",
    "    vol_shape = (shape_z , HEIGHT , WIDTH )\n",
    "    height = vol_shape[1]\n",
    "    width = vol_shape[2]\n",
    "\n",
    "    if len(slice_no_list):\n",
    "        slice_no_list.sort()\n",
    "        vol_gt = np.zeros(vol_shape, dtype = bool)\n",
    "        vol_pred = np.zeros(vol_shape, dtype = bool)\n",
    "\n",
    "        for s in slice_no_list:\n",
    "            aroidb , bboxes , segmentations = oneCT[s]\n",
    "\n",
    "            ix = [a for a,b in enumerate(aroidb['gt_classes']) if int(b) in site_list]\n",
    "            contours = [ aroidb['segms'][int(kk)] for kk in ix ]\n",
    "            \n",
    "            for c in contours:\n",
    "                if len(c): #gt\n",
    "                    new = polys_to_mask(c , height , width)\n",
    "                    vol_gt[D_z_index[s]][new>0] = 1 \n",
    "\n",
    "\n",
    "            for j in site_list:\n",
    "                contours = segmentations[j]\n",
    "                if union_mask:\n",
    "                    #contour should be numpy.array here. list cause error of no attribute 'flatten'\n",
    "                    cc = [ contour.flatten().tolist() for contour in contours if len(contour)!=0]\n",
    "                    contours = union_ploys(cc , height, width)\n",
    "\n",
    "                for c in contours:#union pred\n",
    "                    if len(c)>=6:\n",
    "                        new = polys_to_mask([c] , height , width) \n",
    "                        vol_pred[D_z_index[s]][new>0] = 1 \n",
    "                    elif len(c):\n",
    "                        print('len pred contour is %d'%len(c))\n",
    "    return vol_pred\n",
    "\n",
    "def seperate_vol(vol_pred , reduceFP = False):\n",
    "    # vol_dict = seperate_vol(vol_pred)\n",
    "    connectivity = 2\n",
    "    from skimage import measure\n",
    "    labels_pred=measure.label(vol_pred,connectivity=connectivity)\n",
    "    l_pred,c_pred = np.unique(labels_pred , return_counts=True)\n",
    "\n",
    "\n",
    "    ix2 = l_pred>0\n",
    "    l_pred = l_pred[ix2] #background pixels are labeled as 0, so we exclude them\n",
    "    c_pred = c_pred[ix2]\n",
    "\n",
    "    if reduceFP:\n",
    "        ix2 = l_pred>0\n",
    "        for i, p in enumerate(l_pred):\n",
    "            z = np.where(labels_pred == p)[0]\n",
    "            if len( set(z) )<=1:\n",
    "                ix2[i]=False\n",
    "\n",
    "        l_pred = l_pred[ix2] #background pixels are labeled as 0, so we exclude them\n",
    "        c_pred = c_pred[ix2]\n",
    "\n",
    "\n",
    "    vol_dict = {}\n",
    "\n",
    "    for p in l_pred:\n",
    "        vp = labels_pred == p\n",
    "        vol_dict[p] = vp\n",
    "\n",
    "    return vol_dict\n",
    "\n",
    "\n",
    "\n",
    "site_list_liver = [8]\n",
    "site_list_liver_lung_LNs = [2,4,6,8,9,10,11,14,17] \n",
    "site_list_LNs = [2,4,6,10,11,14,17] \n",
    "\n",
    "site_list = site_list_liver\n",
    "user_id = 'jm4669'\n",
    "\n",
    "cache_path = './cache/'\n",
    "name = 'inference'\n",
    "# name = 'lesion_train'\n",
    "\n",
    "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\n",
    "# print('Loading cached gt_roidb from %s', cache_filepath)\n",
    "with open(cache_filepath, 'rb') as fp:\n",
    "    cached_roidb = pickle.load(fp)\n",
    "    \n",
    "roidb = cached_roidb\n",
    "\n",
    "\n",
    "\n",
    "sv_dir = mask_name\n",
    "sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "\n",
    "all_boxes = [ [ np.zeros((0,5),dtype=\"float32\") for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "all_segms = [ [ [] for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "\n",
    "for i in range(len(roidb)):\n",
    "\n",
    "    one = roidb[i]\n",
    "    onename = one['image']\n",
    "    if not os.path.exists( os.path.join( sv_path, convert_name(onename) ) ):\n",
    "        print(os.path.join(sv_path, convert_name(onename) ) , 'not exists!')\n",
    "    pred_im = Image.open(os.path.join( sv_path, convert_name(onename) ))\n",
    "    pred = np.array(pred_im)\n",
    "    for j in range(cfg.DATASET.NUM_CLASSES):\n",
    "        mask = np.asarray( pred==j , dtype=np.uint8)\n",
    "        if np.sum(mask > 0) <= 3 :\n",
    "            continue\n",
    "        segmentation, bbox, area = __get_annotation__(mask , xywh = False , bbox_score=True)\n",
    "        if segmentation and bbox:\n",
    "            all_segms[j][i] = segmentation\n",
    "            all_boxes[j][i] = bbox\n",
    "\n",
    "\n",
    "D_CT = {}\n",
    "for i , aroidb in enumerate(roidb):\n",
    "    dicom_path , png_name = os.path.split(aroidb['image'])\n",
    "    slice_no , _= os.path.splitext(png_name)\n",
    "    slice_no = int(slice_no)\n",
    "    if slice_no != aroidb['slice_no']:\n",
    "        print('following slice numbers are not consistence.')\n",
    "        print(dicom_path,slice_no,aroidb['slice_no'])\n",
    "\n",
    "    segmentations = {}\n",
    "    bboxes = {}\n",
    "    for j in site_list:\n",
    "        segmentations[j] = all_segms[j][i]\n",
    "        bboxes[j] = all_boxes[j][i]\n",
    "\n",
    "    if dicom_path not in D_CT:\n",
    "        D_CT[dicom_path] = {}\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "    else:\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "def initialize_mask_vol( D_z_index , height , width):\n",
    "    V = D_z_index.values()\n",
    "    shape_z = np.max(list(V)) + 1\n",
    "    mask_vol = np.zeros((shape_z , height , width ) , dtype=np.uint8 )\n",
    "    return mask_vol\n",
    "\n",
    "Metrics_vol = []\n",
    "keys = list(D_CT.keys())\n",
    "for k in keys:\n",
    "#     if 'COU-AA-302' in k:\n",
    "#         site_list = site_list_LNs\n",
    "#     else:\n",
    "#         site_list = site_list_liver_lung_LNs\n",
    "\n",
    "    image_series_path = k.replace('/Pngs/' , '/Inputs/')    \n",
    "\n",
    "    df_image = get_dicom_header_df( image_series_path )\n",
    "    instanceNumber_list = df_image.index.to_list()\n",
    "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\n",
    "\n",
    "\n",
    "    oneCT = remove_single_slice_segms(D_CT[k])\n",
    "    vol_pred = get_pred_vol(oneCT , site_list , D_z_index, union_mask = False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    image_series = wr.dicom_header(image_series_path)\n",
    "    if len(image_series):\n",
    "        height = image_series[0].Rows \n",
    "        width = image_series[0].Columns \n",
    "    else:\n",
    "        print('ERROR image_series has no len' , image_series_path)\n",
    "    assert(len(image_series) == vol_pred.shape[0])\n",
    "\n",
    "    mask_vol = initialize_mask_vol( D_z_index, height , width)\n",
    "\n",
    "    df_radiologist = df_all[(df_all['Image File Path'] == image_series_path) & (df_all['Location'].isin(['liver'])) ]\n",
    "    for _ , row in df_radiologist.iterrows():\n",
    "        radiologist_raw = wr.read(row['Contour File Path'])\n",
    "        slice_list = radiologist_raw.get_instance_number_array()\n",
    "        for j, one in enumerate(slice_list):\n",
    "            mask = radiologist_raw.get_mask_image(j)\n",
    "            mask_vol[D_z_index[one]] += mask\n",
    "\n",
    "\n",
    "    vol2 = vol_pred + mask_vol\n",
    "    vol2[vol2>1]=1\n",
    "    vol_dict = seperate_vol(vol2)\n",
    "    \n",
    "    for tumor_index in vol_dict:\n",
    "        mask_volume = vol_dict[tumor_index]\n",
    "        weasis_raw_data = wr.create(image_series, mask_volume)\n",
    "\n",
    "        file_folder = os.path.join(SAVE_PATH , 'RawToWeasis')\n",
    "        if not os.path.exists(file_folder):\n",
    "            os.makedirs(file_folder)\n",
    "        file_name = wr.unique(image_series, tumor_index, user_id)\n",
    "        file_name = os.path.join(file_folder,file_name)\n",
    "        wr.write(weasis_raw_data, file_name)\n",
    "\n",
    "        Metrics_vol.append( [image_series_path , file_name , user_id ])\n",
    "\n",
    "\n",
    "\n",
    "    df_metrics = pd.DataFrame(Metrics_vol, \n",
    "                              columns = ['Image File Path','Contour File Path','Uni']) \n",
    "    df_metrics.to_csv('RawToWeasisUnionAIRadiologist_1033.csv' , index=False)\n",
    "    print('finished ', k )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 46M\r\n",
      "-rw-r--r--. 1 jm4669 domain users  17K Apr 16 13:55 Display Weasis Raw.ipynb\r\n",
      "drwxr-x---. 2 jm4669 domain users  20K Apr 16 13:53 DisplayWeasisRaw\r\n",
      "-rw-r--r--. 1 jm4669 domain users 167K Mar 19 23:35 ScaleNAS_3Slices to Weasis Raw Union of AI and Rad Amgen.ipynb\r\n",
      "drwxr-xr-x. 2 jm4669 domain users  112 Mar 18 14:22 __pycache__\r\n",
      "-rw-r--r--. 1 jm4669 domain users  14K Mar 18 14:22 utils_metrics_3d.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users  28K Mar 16 22:25 Weasis cvs change str to X Drive.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users 406K Mar 16 20:15 RawToWeasisUnionAIRadiologist_AmgenatXdrive.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users 410K Mar 16 19:27 RawToWeasisUnionAIRadiologist_Amgen20020408.csv\r\n",
      "drwxrwxr-x. 2 jm4669 domain users  232 Mar 16 19:05 cache\r\n",
      "-rw-r--r--. 1 jm4669 domain users  49K Mar 16 18:58 ScaleNAS_3Slices to Weasis Raw Union Contour of AI and Radiologist CUIMC1033.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users 853K Mar 16 18:29 RawToWeasisUnionAIRadiologist_1033atXdrive.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users 867K Mar 16 15:06 RawToWeasisUnionAIRadiologist_1033.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users 167K Mar 16 12:20 RawToWeasisUnionAIRadiologist_299atXdrive.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users 6.7M Mar 15 22:58 test0028.png\r\n",
      "-rw-r--r--. 1 jm4669 domain users 1.7M Mar 15 22:51 test.png\r\n",
      "-rw-r--r--. 1 jm4669 domain users 171K Mar 15 18:05 RawToWeasisUnionAIRadiologist.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users 115K Mar 14 01:04 RawToWeasis.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users 1.5M Feb  9 13:10 Compare Images from MVP-Q1 MVP-Q2 and ScaleNAS_.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users  21K Jan 26 21:21 utils_test.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users  67K Jan 15 20:15 Search Find a png from json.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users  42K Dec  2 20:38 ScaleNAS_Q5 Predicted mask to Metrics Cougar302_80pts Allsites.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users  35K Dec  2 16:56 ScaleNAS_Q5 Predicted mask to Metrics Cougar302_80pts LNs.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users  46K Dec  1 22:24 ScaleNAS_Q5 Test and save predicted mask.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users  49K Nov 30 14:24 Cougar302_80pts_test_metrics_vol.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users  51K Nov 24 14:13 ScaleNAS_Q5 Predicted mask to Metrics Amgen Lung and LN.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users  49K Nov 19 11:23 ScaleNAS_Q5 Predicted mask to Metrics CUIMC Lung and LN.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users  51K Nov 19 00:58 ScaleNAS_Q5 Predicted mask to Metrics Amgen.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users 208K Nov 19 00:20 PDS_AMGEN_20020408_22Cat_test_lung_seg_metrics_vol_2021116.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users  76K Nov 18 21:12 PDS_CUIMC_22Cat_test_lung_seg_metrics_vol_20211116.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users  47K Nov 17 11:44 ScaleNAS_Q5 Predicted mask to Metrics CUIMC.ipynb\r\n",
      "-rw-r--r--. 1 jm4669 domain users 263K Nov 17 03:27 PDS_AMGEN_20020408_22Cat_test_liver_seg_metrics_vol_2021116.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users 101K Nov 17 01:40 PDS_CUIMC_22Cat_test_liver_seg_metrics_vol_20211116.csv\r\n",
      "drwxr-xr-x. 3 jm4669 domain users   38 Nov 16 23:22 mask_1514\r\n",
      "drwxr-xr-x. 3 jm4669 domain users   20 Nov 16 23:16 log\r\n",
      "drwxr-xr-x. 3 jm4669 domain users   20 Nov 16 23:16 output\r\n",
      "-rw-r--r--. 1 jm4669 domain users  11K Oct 26 12:39 train_teacher_model.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users 101K Jul 19  2021 PDS_CUIMC_22Cat_test_liver_seg_metrics_vol_20210719.csv\r\n",
      "-rw-r--r--. 1 jm4669 domain users 262K Jul 19  2021 PDS_AMGEN_20020408_22Cat_test_liver_seg_metrics_vol_20210719.csv\r\n",
      "-rw-rw-r--. 1 jm4669 domain users 9.4K Jul 11  2021 lesion_test.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users 5.1K Jul  9  2021 evo_server.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users 6.9K Jul  8  2021 Lesion_evo_seg_test.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users 7.0K Jul  8  2021 Lesion_random_seg_test.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users 6.9K Jul  6  2021 evo_seg_test.py\r\n",
      "drwxrwxr-x. 2 jm4669 domain users 580K Jun 17  2021 test_val_results\r\n",
      "-rw-rw-r--. 1 jm4669 domain users 9.0K Jun 17  2021 teacher_model_test.py\r\n",
      "-rw-rw-r--. 1 jm4669 domain users 1.4K Jun 11  2021 change_path.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users  12K Jun  6  2021 train_teacher_model_DP.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users  13K May 27  2021 train_superscalenet_seg_Lesion.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users  21M May 21  2021 1.png\r\n",
      "-rw-r--r--. 1 jm4669 domain users 9.7M May 21  2021 montage.png\r\n",
      "-rw-r--r--. 1 jm4669 domain users  606 Nov 24  2020 _init_paths.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users 6.9K Nov 24  2020 random_seg_test.py\r\n",
      "-rwxr-xr-x. 1 jm4669 domain users 4.8K Nov 24  2020 scalenet_pose_test.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users 4.4K Nov 24  2020 scalenet_seg_test.py\r\n",
      "-rw-r--r--. 1 jm4669 domain users  14K Nov 24  2020 train_superscalenet_seg.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lht"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

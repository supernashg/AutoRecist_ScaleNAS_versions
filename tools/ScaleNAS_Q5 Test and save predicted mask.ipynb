{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating output/Lesion/superscalenet_seg/Lesion_Q5_scalenet_seg_test/data_patch_valtest\n",
      "=> creating log/Lesion/superscalenet_seg/data_patch_valtest/Lesion_Q5_scalenet_seg_test_2021-12-01-21-58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> init weights from normal distribution\n",
      "=> loading model from ../output/Lesion/superscalenet_seg/Lesion_Q5_superscalenet_base/data_patch_train/best.pth\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/ipykernel/__main__.py:240: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "Missing keys in pretrained_dict: set()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.criterion.weight\n",
      "Current time cost is 8.868932485580444 sec\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Licensed under the MIT License.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import _init_paths\n",
    "import models\n",
    "import dataset\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.seg_function import validate_seg_wo_loss as validate\n",
    "from core.oneshot_function import calib_bn_seg as calib_bn\n",
    "from utils.utils import get_model_summary\n",
    "from utils.utils import create_logger, FullModel\n",
    "\n",
    "from dataset.roidb import combined_roidb_for_training\n",
    "from roi_data.loader import RoiDataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, name = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.makedirs(sv_path)\n",
    "                save_pred(pred, sv_path, name)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d batches' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc\n",
    "\n",
    "\n",
    "def parse_args(l):\n",
    "    parser = argparse.ArgumentParser(description='Test segmentation network')\n",
    "\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        required=True,\n",
    "                        type=str)\n",
    "    parser.add_argument('opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "    parser.add_argument('--bn_calib',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--mask_path',\n",
    "                        help='the path of a mask.npy',\n",
    "                        default=None,\n",
    "                        type=str)\n",
    "    args = parser.parse_args(l)\n",
    "    update_config(cfg, args)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# arglist = ['--cfg', '../experiments/cityscapes/scalenet_seg_w32_test.yaml' ,  \n",
    "#            '--bn_calib',\n",
    "#            '--mask_path', '../experiments/searched_masks/cityscapes/seg_w32_S1.npy' ,  \n",
    "#            'TEST.MODEL_FILE', '../models/pytorch/seg_cityscapes/superscalenet_seg_w32.pth',\n",
    "#            'DATASET.ROOT','../data/']\n",
    "\n",
    "# mask_1661\t23.05\t34.50\t0.2345\n",
    "# mask_1730\t23.34\t34.43\t0.2339\n",
    "# mask_1861\t24.44\t34.21\t0.2333\n",
    "# mask_1539\t23.35\t34.79\t0.2333\n",
    "# mask_1037\t31.14\t42.65\t0.2333\n",
    "# mask_1168\t27.21\t40.27\t0.2329\n",
    "# mask_1474\t29.62\t40.18\t0.2325\n",
    "# f0.8_d45_121706\t40.07\t51.93\t0.2324\n",
    "# mask_1636\t29.90\t39.30\t0.2322\n",
    "# mask_1316\t31.46\t42.81\t0.2321\n",
    "# f0.65_d45_70317\t37.69\t49.64\t0.2320\n",
    "# f0.65_d34_442370\t30.66\t42.60\t0.2319\n",
    "# f0.65_d45_711100\t36.42\t51.84\t0.2319\n",
    "\n",
    "experiment_name = 'Lesion_Q5_scalenet_seg_test'\n",
    "mask_name = 'mask_1514'\n",
    "arglist = ['--cfg', '../experiments/lesion_Q5/%s.yaml'%experiment_name ,  \n",
    "           '--mask_path', '../evo_files/masks/%s.npy'%mask_name,  \n",
    "           'TEST.MODEL_FILE', '../output/Lesion/superscalenet_seg/Lesion_Q5_superscalenet_base/data_patch_train/best.pth',\n",
    "           'DATASET.ROOT','../abababab/',\n",
    "           'TRAIN.USE_FLIPPED',False]\n",
    "\n",
    "args = parse_args(arglist)\n",
    "\n",
    "logger, final_output_dir, tb_log_dir = create_logger(\n",
    "    cfg, args.cfg, 'valtest')\n",
    "\n",
    "writer_dict = {\n",
    "    'writer': SummaryWriter(tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "cudnn.enabled = cfg.CUDNN.ENABLED\n",
    "\n",
    "# build model\n",
    "model = eval('models.' + cfg.MODEL.NAME +\n",
    "             '.get_seg_model')(cfg)\n",
    "\n",
    "input_shape = (1, 3, cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "dump_input = torch.rand(\n",
    "    input_shape\n",
    ")\n",
    "\n",
    "if cfg.TEST.MODEL_FILE:\n",
    "    model_state_file = cfg.TEST.MODEL_FILE\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    model_state_file = os.path.join(final_output_dir,\n",
    "                                    'final_state.pth')\n",
    "logger.info('=> loading model from {}'.format(model_state_file))\n",
    "\n",
    "pretrained_dict = torch.load(model_state_file)\n",
    "\n",
    "D2= {}\n",
    "for key in pretrained_dict.keys():\n",
    "    if key[:6] == 'model.':\n",
    "        new_key = key[6:]\n",
    "        D2[new_key] = pretrained_dict[key]\n",
    "    else:\n",
    "        print(key)\n",
    "        D2[key] = pretrained_dict[key]\n",
    "\n",
    "pretrained_dict = D2      \n",
    "model_dict = model.state_dict()\n",
    "\n",
    "model_keys = set(model_dict.keys())\n",
    "pretrained_keys = set(pretrained_dict.keys())\n",
    "missing_keys = model_keys - pretrained_keys\n",
    "logger.warn('Missing keys in pretrained_dict: {}'.format(missing_keys))\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "\n",
    "# do stuff\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time cost is 4.744529724121094e-05 sec\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached gt_roidb from /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_Q5/tools/cache/PDS_AMGEN_20020408_22Cat_test_gt_roidb.pkl\n",
      "Loaded dataset: PDS_AMGEN_20020408_22Cat_test\n",
      "Filtered 0 roidb entries: 9077 -> 9077\n",
      "Computing image aspect ratios and ordering the ratios...\n",
      "done\n",
      "Computing bounding-box regression targets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 9077\n",
      "2 9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done\n",
      "GPU list is [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 9077\n",
      "class_weights are:\n",
      "tensor([0.4000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> setting mask from ../evo_files/masks/mask_1514.npy\n",
      "[{'d': array([[4],\n",
      "       [4]]), 'f': array([[list([1, 1]), list([1, 0]), list([1, 1]), list([1, 1]),\n",
      "        list([0, 0])],\n",
      "       [list([1, 1]), list([0, 1]), list([0, 1]), list([1, 1]),\n",
      "        list([0, 0])]], dtype=object)}\n",
      " {'d': array([[3],\n",
      "       [3],\n",
      "       [2]]), 'f': array([[list([1, 1, 0]), list([1, 0, 1]), list([1, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1, 0]), list([1, 1, 1]), list([1, 1, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 1, 1]), list([0, 1, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[3],\n",
      "       [2],\n",
      "       [3]]), 'f': array([[list([1, 0, 1]), list([1, 1, 0]), list([1, 0, 1]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 1, 1]), list([0, 1, 0]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1, 1]), list([1, 0, 1]), list([0, 1, 1]), array([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[2],\n",
      "       [3],\n",
      "       [3]]), 'f': array([[list([1, 0, 0]), list([1, 0, 0]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 1, 0]), list([1, 1, 1]), list([1, 1, 1]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 1, 1]), list([0, 1, 1]), list([0, 1, 1]), array([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[2],\n",
      "       [3],\n",
      "       [2]]), 'f': array([[list([1, 1, 1]), list([1, 0, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([0, 1, 1]), list([0, 1, 1]), list([1, 1, 0]), array([0, 0]),\n",
      "        array([0, 0])],\n",
      "       [list([1, 0, 1]), list([0, 1, 1]), list([0, 0, 0]), array([0, 0]),\n",
      "        array([0, 0])]], dtype=object)}\n",
      " {'d': array([[2],\n",
      "       [3],\n",
      "       [2],\n",
      "       [2]]), 'f': array([[list([1, 1, 1, 1]), list([1, 0, 0, 1]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 1, 1, 0]), list([0, 1, 0, 1]), list([0, 1, 1, 1]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 1, 1, 1]), list([1, 1, 1, 0]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([0, 1, 1, 1]), list([0, 1, 0, 1]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])]], dtype=object)}\n",
      " {'d': array([[3],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2]]), 'f': array([[list([1, 1, 0, 0]), list([1, 1, 0, 0]), list([1, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([0, 1, 0, 1]), list([1, 1, 1, 1]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([1, 1, 1, 0]), list([0, 0, 1, 0]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])],\n",
      "       [list([0, 1, 1, 1]), list([0, 1, 0, 1]), list([0, 0, 0, 0]),\n",
      "        array([0, 0]), array([0, 0])]], dtype=object)}\n",
      " {'d': array([[4],\n",
      "       [5],\n",
      "       [4],\n",
      "       [5]]), 'f': array([[list([1, 1, 0, 0]), list([1, 1, 0, 0]), list([1, 1, 0, 0]),\n",
      "        list([1, 1, 0, 0]), list([0, 0, 0, 0])],\n",
      "       [list([0, 1, 1, 0]), list([0, 1, 0, 0]), list([1, 1, 0, 0]),\n",
      "        list([1, 1, 0, 0]), list([0, 1, 0, 0])],\n",
      "       [list([0, 1, 1, 0]), list([0, 0, 1, 0]), list([1, 0, 1, 0]),\n",
      "        list([0, 1, 1, 0]), list([0, 0, 0, 0])],\n",
      "       [list([0, 0, 0, 1]), list([0, 0, 0, 1]), list([0, 0, 0, 1]),\n",
      "        list([0, 1, 0, 1]), list([0, 0, 0, 1])]], dtype=object)}]\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "INFO: profile from hrnet: Model superscalenet_seg: params 22.7 M, flops 34.7 G (with input size (1, 3, 512, 512))\n",
      "processing: 0 batches\n",
      "mIoU: 0.0948\n",
      "processing: 100 batches\n",
      "mIoU: 0.1814\n",
      "processing: 200 batches\n",
      "mIoU: 0.2393\n",
      "processing: 300 batches\n",
      "mIoU: 0.2296\n",
      "processing: 400 batches\n",
      "mIoU: 0.2378\n",
      "processing: 500 batches\n",
      "mIoU: 0.2376\n",
      "MeanIU:  0.2352, Pixel_Acc:  0.9919,    Mean_Acc:  0.3418, Class IoU: \n",
      "[0.9921232  0.13682819 0.03545958 0.30965979 0.41237699 0.04403581\n",
      " 0.30980922 0.40666204 0.68472571 0.48603551 0.36041024 0.13951524\n",
      " 0.         0.01290946 0.14715941 0.29427403 0.         0.18381745\n",
      " 0.10555434 0.01272144 0.         0.10074159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time cost is 1466.5901374816895 sec\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "test_size = (cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "\n",
    "# manully select from below.\n",
    "# ('PDS_AMGEN_20020408_22Cat_test',)\n",
    "# ('PDS_Q2_A&C_22Cat_train',)\n",
    "# ('PDS_CUIMC_22Cat_test',)\n",
    "\n",
    "test_roidb, test_ratio_list, test_ratio_index = combined_roidb_for_training(\n",
    "        ('PDS_AMGEN_20020408_22Cat_test',) , cfg.VAL.PROPOSAL_FILES)\n",
    "\n",
    "test_dataset = RoiDataLoader(\n",
    "    test_roidb,\n",
    "    cfg.MODEL.NUM_CLASSES,\n",
    "    training=True)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.TEST.BATCH_SIZE_PER_GPU,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "\n",
    "\n",
    "\n",
    "gpus = list(cfg.GPUS)\n",
    "logger.info('GPU list is {}'.format(gpus))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "if args.mask_path and os.path.exists(args.mask_path):\n",
    "    masks = np.load(args.mask_path, allow_pickle=True)\n",
    "    model.module.set_active_subnet(masks)\n",
    "    logger.info('=> setting mask from {}'.format(args.mask_path))\n",
    "    logger.info(masks)\n",
    "else:\n",
    "    masks=None\n",
    "    logger.info('No model mask')\n",
    "\n",
    "# if args.bn_calib:\n",
    "#     calib_bn(cfg, model, 0, masks)\n",
    "params, flops, details = get_model_summary(model.module, dump_input.cuda())\n",
    "logger.info('INFO: profile from hrnet: Model {}: params {:.1f} M, flops {:.1f} G (with input size {})'.\n",
    "            format(cfg.MODEL.NAME, params / 1e6, flops, input_shape))\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "mean_IoU, IoU_array, pixel_acc, mean_acc = testval_lesion(cfg, \n",
    "                                                  test_dataset, \n",
    "                                                  testloader, \n",
    "                                                  model.cuda(),\n",
    "                                                  sv_dir=mask_name, \n",
    "                                                  device=None)\n",
    "\n",
    "msg = 'MeanIU: {: 4.4f}, Pixel_Acc: {: 4.4f},    Mean_Acc: {: 4.4f}, Class IoU: '.format(mean_IoU, \n",
    "   pixel_acc, mean_acc)\n",
    "logging.info(msg)\n",
    "logging.info(IoU_array)\n",
    "\n",
    "# do stuff\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache ground truth roidb to /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_Q5/tools/cache/PDS_CUIMC_22Cat_test_gt_roidb.pkl\n",
      "Loaded dataset: PDS_CUIMC_22Cat_test\n",
      "Filtered 0 roidb entries: 4808 -> 4808\n",
      "Computing image aspect ratios and ordering the ratios...\n",
      "done\n",
      "Computing bounding-box regression targets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4808\n",
      "2 4808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4808\n",
      "class_weights are:\n",
      "tensor([0.4000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 0 batches\n",
      "mIoU: 0.1038\n",
      "processing: 100 batches\n",
      "mIoU: 0.1503\n",
      "processing: 200 batches\n",
      "mIoU: 0.2021\n",
      "processing: 300 batches\n",
      "mIoU: 0.2146\n",
      "MeanIU:  0.2146, Pixel_Acc:  0.9932,    Mean_Acc:  0.3533, Class IoU: \n",
      "[0.99388489 0.16798487 0.06616382 0.0555681  0.29434327 0.03081651\n",
      " 0.         0.64624692 0.57607746 0.3551555  0.18988545 0.\n",
      " 0.         0.22169956 0.03897751 0.15958367 0.0170697  0.17937742\n",
      " 0.24203038 0.28544974 0.         0.19982808]\n"
     ]
    }
   ],
   "source": [
    "# prepare external test data\n",
    "\n",
    "# manully select from below.\n",
    "# ('PDS_AMGEN_20020408_22Cat_test',)\n",
    "# ('PDS_Q2_A&C_22Cat_train',)\n",
    "# ('PDS_CUIMC_22Cat_test',)\n",
    "\n",
    "test2_roidb, test2_ratio_list, test2_ratio_index = combined_roidb_for_training(\n",
    "        ('PDS_CUIMC_22Cat_test',) , cfg.VAL.PROPOSAL_FILES)\n",
    "\n",
    "test2_dataset = RoiDataLoader(\n",
    "    test2_roidb,\n",
    "    cfg.MODEL.NUM_CLASSES,\n",
    "    training=True)\n",
    "\n",
    "\n",
    "test2_loader = torch.utils.data.DataLoader(\n",
    "    test2_dataset,\n",
    "    batch_size=cfg.TEST.BATCH_SIZE_PER_GPU,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "\n",
    "           \n",
    "\n",
    "mean_IoU2, IoU_array2, pixel_acc2, mean_acc2 = testval_lesion(cfg, \n",
    "                                                  test2_dataset, \n",
    "                                                  test2_loader, \n",
    "                                                  model.cuda(),\n",
    "                                                  sv_dir=mask_name, \n",
    "                                                  device=None)\n",
    "\n",
    "msg2 = 'MeanIU: {: 4.4f}, Pixel_Acc: {: 4.4f},    Mean_Acc: {: 4.4f}, Class IoU: '.format(mean_IoU2, \n",
    "   pixel_acc2, mean_acc2)\n",
    "logging.info(msg2)\n",
    "logging.info(IoU_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached gt_roidb from /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_Q5/tools/cache/Cougar302_80pts_test_gt_roidb.pkl\n",
      "Loaded dataset: Cougar302_80pts_test\n",
      "Filtered 0 roidb entries: 1840 -> 1840\n",
      "Computing image aspect ratios and ordering the ratios...\n",
      "done\n",
      "Computing bounding-box regression targets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1840\n",
      "2 1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done\n",
      "GPU list is [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1840\n",
      "class_weights are:\n",
      "tensor([0.4000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000, 9.6000,\n",
      "        9.6000, 9.6000, 9.6000, 9.6000])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataParallel' object has no attribute 'set_active_subnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-80b7ef48b0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_path\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_active_subnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=> setting mask from {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/fast-data/mjc/envs/scalenas/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 539\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'set_active_subnet'"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "test_size = (cfg.TEST.IMAGE_SIZE[1], cfg.TEST.IMAGE_SIZE[0])\n",
    "\n",
    "# manully select from below.\n",
    "# ('PDS_AMGEN_20020408_22Cat_test',)\n",
    "# ('PDS_Q2_A&C_22Cat_train',)\n",
    "# ('PDS_CUIMC_22Cat_test',)\n",
    "\n",
    "test_roidb, test_ratio_list, test_ratio_index = combined_roidb_for_training(\n",
    "        ('Cougar302_80pts_test',) , cfg.VAL.PROPOSAL_FILES)\n",
    "\n",
    "test_dataset = RoiDataLoader(\n",
    "    test_roidb,\n",
    "    cfg.MODEL.NUM_CLASSES,\n",
    "    training=True)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.TEST.BATCH_SIZE_PER_GPU,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "\n",
    "\n",
    "\n",
    "gpus = list(cfg.GPUS)\n",
    "logger.info('GPU list is {}'.format(gpus))\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "if args.mask_path and os.path.exists(args.mask_path):\n",
    "    masks = np.load(args.mask_path, allow_pickle=True)\n",
    "    model.module.set_active_subnet(masks)\n",
    "    logger.info('=> setting mask from {}'.format(args.mask_path))\n",
    "    logger.info(masks)\n",
    "else:\n",
    "    masks=None\n",
    "    logger.info('No model mask')\n",
    "\n",
    "# if args.bn_calib:\n",
    "#     calib_bn(cfg, model, 0, masks)\n",
    "params, flops, details = get_model_summary(model.module, dump_input.cuda())\n",
    "logger.info('INFO: profile from hrnet: Model {}: params {:.1f} M, flops {:.1f} G (with input size {})'.\n",
    "            format(cfg.MODEL.NAME, params / 1e6, flops, input_shape))\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "mean_IoU, IoU_array, pixel_acc, mean_acc = testval_lesion(cfg, \n",
    "                                                  test_dataset, \n",
    "                                                  testloader, \n",
    "                                                  model.cuda(),\n",
    "                                                  sv_dir=mask_name, \n",
    "                                                  device=None)\n",
    "\n",
    "msg = 'MeanIU: {: 4.4f}, Pixel_Acc: {: 4.4f},    Mean_Acc: {: 4.4f}, Class IoU: '.format(mean_IoU, \n",
    "   pixel_acc, mean_acc)\n",
    "logging.info(msg)\n",
    "logging.info(IoU_array)\n",
    "\n",
    "# do stuff\n",
    "elapsed = time.time() - t\n",
    "print('Current time cost is {} sec'.format(elapsed) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm /mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_Q5/tools/cache/Cougar302_80pts_test_gt_roidb.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /mnt/fast-data/mjc/envs/scalenas:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_libgcc_mutex             0.1                        main    defaults\r\n",
      "argon2-cffi               20.1.0           py36h27cfd23_1    defaults\r\n",
      "async_generator           1.10               pyhd3eb1b0_0    defaults\r\n",
      "attrs                     20.3.0             pyhd3eb1b0_0    defaults\r\n",
      "backcall                  0.2.0              pyhd3eb1b0_0    defaults\r\n",
      "blas                      1.0                         mkl    defaults\r\n",
      "bleach                    3.3.0              pyhd3eb1b0_0    defaults\r\n",
      "blosc                     1.19.0               hd408876_0    defaults\r\n",
      "brotli                    1.0.9                he6710b0_2    defaults\r\n",
      "bzip2                     1.0.8                h7b6447c_0    defaults\r\n",
      "ca-certificates           2021.4.13            h06a4308_1    defaults\r\n",
      "certifi                   2020.12.5        py36h06a4308_0    defaults\r\n",
      "cffi                      1.14.5           py36h261ae71_0    defaults\r\n",
      "charls                    2.1.0                he6710b0_2    defaults\r\n",
      "cloudpickle               1.6.0                      py_0    defaults\r\n",
      "cudatoolkit               9.0                  h13b8566_0    defaults\r\n",
      "cycler                    0.10.0                   py36_0    defaults\r\n",
      "cycler                    0.10.0                    <pip>\r\n",
      "Cython                    0.29.22                   <pip>\r\n",
      "cytoolz                   0.11.0           py36h7b6447c_0    defaults\r\n",
      "dask-core                 2021.3.0           pyhd3eb1b0_0    defaults\r\n",
      "dbus                      1.13.18              hb2f20db_0    defaults\r\n",
      "decorator                 5.0.6              pyhd3eb1b0_0    defaults\r\n",
      "decorator                 4.4.2                     <pip>\r\n",
      "defusedxml                0.7.1              pyhd3eb1b0_0    defaults\r\n",
      "easydict                  1.7                       <pip>\r\n",
      "entrypoints               0.3                      py36_0    defaults\r\n",
      "expat                     2.3.0                h2531618_2    defaults\r\n",
      "fontconfig                2.13.1               h6c09931_0    defaults\r\n",
      "freetype                  2.10.4               h5ab3b9f_0    defaults\r\n",
      "giflib                    5.1.4                h14c3975_1    defaults\r\n",
      "glib                      2.68.1               h36276a3_0    defaults\r\n",
      "gst-plugins-base          1.14.0               h8213a91_2    defaults\r\n",
      "gstreamer                 1.14.0               h28cd5cc_2    defaults\r\n",
      "icu                       58.2                 he6710b0_3    defaults\r\n",
      "imagecodecs               2020.5.30        py36h567f118_1    defaults\r\n",
      "imageio                   2.9.0              pyhd3eb1b0_0    defaults\r\n",
      "importlib-metadata        3.10.0           py36h06a4308_0    defaults\r\n",
      "importlib_metadata        3.10.0               hd3eb1b0_0    defaults\r\n",
      "intel-openmp              2019.4                      243    defaults\r\n",
      "ipykernel                 5.3.4            py36h5ca1d4c_0    defaults\r\n",
      "ipython                   7.16.1           py36h5ca1d4c_0    defaults\r\n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1    defaults\r\n",
      "ipywidgets                7.6.3              pyhd3eb1b0_1    defaults\r\n",
      "jedi                      0.17.0                   py36_0    defaults\r\n",
      "jinja2                    2.11.3             pyhd3eb1b0_0    defaults\r\n",
      "jpeg                      9b                   h024ee3a_2    defaults\r\n",
      "json-tricks               3.15.5                    <pip>\r\n",
      "jsonschema                3.2.0                      py_2    defaults\r\n",
      "jupyter                   1.0.0                    py36_7    defaults\r\n",
      "jupyter_client            6.1.12             pyhd3eb1b0_0    defaults\r\n",
      "jupyter_console           6.4.0              pyhd3eb1b0_0    defaults\r\n",
      "jupyter_core              4.7.1            py36h06a4308_0    defaults\r\n",
      "jupyterlab_pygments       0.1.2                      py_0    defaults\r\n",
      "jupyterlab_widgets        1.0.0              pyhd3eb1b0_1    defaults\r\n",
      "jxrlib                    1.1                  h7b6447c_2    defaults\r\n",
      "kiwisolver                1.3.1            py36h2531618_0    defaults\r\n",
      "lcms2                     2.12                 h3be6417_0    defaults\r\n",
      "ld_impl_linux-64          2.33.1               h53a641e_7    defaults\r\n",
      "libaec                    1.0.4                he6710b0_1    defaults\r\n",
      "libffi                    3.3                  he6710b0_2    defaults\r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0    defaults\r\n",
      "libgfortran-ng            7.3.0                hdf63c60_0    defaults\r\n",
      "libpng                    1.6.37               hbc83047_0    defaults\r\n",
      "libsodium                 1.0.18               h7b6447c_0    defaults\r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0    defaults\r\n",
      "libtiff                   4.1.0                h2733197_1    defaults\r\n",
      "libuuid                   1.0.3                h1bed415_2    defaults\r\n",
      "libwebp                   1.0.1                h8e7db2f_0    defaults\r\n",
      "libxcb                    1.14                 h7b6447c_0    defaults\r\n",
      "libxml2                   2.9.10               hb55368b_3    defaults\r\n",
      "libzopfli                 1.0.3                he6710b0_0    defaults\r\n",
      "lz4-c                     1.9.3                h2531618_0    defaults\r\n",
      "markupsafe                1.1.1            py36h7b6447c_0    defaults\r\n",
      "matplotlib                3.2.2                     <pip>\r\n",
      "matplotlib-base           3.3.4            py36h62a2d02_0    defaults\r\n",
      "mistune                   0.8.4            py36h7b6447c_0    defaults\r\n",
      "mkl                       2019.4                      243    defaults\r\n",
      "mkl-service               2.3.0            py36he8ac12f_0    defaults\r\n",
      "mkl_fft                   1.0.14           py36hd81dba3_0    r\r\n",
      "mkl_random                1.0.4            py36hd81dba3_0    r\r\n",
      "nbclient                  0.5.3              pyhd3eb1b0_0    defaults\r\n",
      "nbconvert                 6.0.7                    py36_0    defaults\r\n",
      "nbformat                  5.1.3              pyhd3eb1b0_0    defaults\r\n",
      "ncurses                   6.2                  he6710b0_1    defaults\r\n",
      "nest-asyncio              1.5.1              pyhd3eb1b0_0    defaults\r\n",
      "networkx                  2.5.1                     <pip>\r\n",
      "networkx                  2.5                        py_0    defaults\r\n",
      "ninja                     1.10.2           py36hff7bd54_0    defaults\r\n",
      "notebook                  6.3.0            py36h06a4308_0    defaults\r\n",
      "numpy                     1.17.0           py36h7e9f1db_0    r\r\n",
      "numpy                     1.19.5                    <pip>\r\n",
      "numpy-base                1.17.0           py36hde5b4d6_0    r\r\n",
      "olefile                   0.46                       py_0    defaults\r\n",
      "opencv-python             3.4.1.15                  <pip>\r\n",
      "openjpeg                  2.3.0                h05c96fa_1    defaults\r\n",
      "openssl                   1.1.1k               h27cfd23_0    defaults\r\n",
      "packaging                 20.9               pyhd3eb1b0_0    defaults\r\n",
      "pandas                    1.1.5                     <pip>\r\n",
      "pandoc                    2.12                 h06a4308_0    defaults\r\n",
      "pandocfilters             1.4.3            py36h06a4308_1    defaults\r\n",
      "parso                     0.8.2              pyhd3eb1b0_0    defaults\r\n",
      "pcre                      8.44                 he6710b0_0    defaults\r\n",
      "pexpect                   4.8.0              pyhd3eb1b0_3    defaults\r\n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003    defaults\r\n",
      "pillow                    8.2.0            py36he98fc37_0    defaults\r\n",
      "Pillow                    8.0.1                     <pip>\r\n",
      "pip                       21.0.1           py36h06a4308_0    defaults\r\n",
      "prometheus_client         0.10.1             pyhd3eb1b0_0    defaults\r\n",
      "prompt-toolkit            3.0.17             pyh06a4308_0    defaults\r\n",
      "prompt_toolkit            3.0.17               hd3eb1b0_0    defaults\r\n",
      "protobuf                  3.15.7                    <pip>\r\n",
      "ptyprocess                0.7.0              pyhd3eb1b0_2    defaults\r\n",
      "pycocotools               2.0.2                     <pip>\r\n",
      "pycparser                 2.20                       py_2    defaults\r\n",
      "pygments                  2.8.1              pyhd3eb1b0_0    defaults\r\n",
      "pyparsing                 2.4.7              pyhd3eb1b0_0    defaults\r\n",
      "pyqt                      5.9.2            py36h05f1152_2    defaults\r\n",
      "pyrsistent                0.17.3           py36h7b6447c_0    defaults\r\n",
      "python                    3.6.13               hdb3f193_0    defaults\r\n",
      "python-dateutil           2.8.1              pyhd3eb1b0_0    defaults\r\n",
      "pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch\r\n",
      "pytz                      2021.1                    <pip>\r\n",
      "pywavelets                1.1.1            py36h7b6447c_2    defaults\r\n",
      "pyyaml                    5.4.1            py36h27cfd23_1    defaults\r\n",
      "PyYAML                    5.4.1                     <pip>\r\n",
      "pyzmq                     20.0.0           py36h2531618_1    defaults\r\n",
      "qt                        5.9.7                h5867ecd_1    defaults\r\n",
      "qtconsole                 5.0.3              pyhd3eb1b0_0    defaults\r\n",
      "qtpy                      1.9.0                      py_0    defaults\r\n",
      "readline                  8.1                  h27cfd23_0    defaults\r\n",
      "scikit-image              0.17.2           py36hdf5156a_0    defaults\r\n",
      "scikit-image              0.17.2                    <pip>\r\n",
      "scipy                     1.4.1                     <pip>\r\n",
      "scipy                     1.5.2            py36h0b6359f_0    defaults\r\n",
      "send2trash                1.5.0              pyhd3eb1b0_1    defaults\r\n",
      "setuptools                50.3.2                    <pip>\r\n",
      "setuptools                52.0.0           py36h06a4308_0    defaults\r\n",
      "Shapely                   1.6.4                     <pip>\r\n",
      "sip                       4.19.8           py36hf484d3e_0    defaults\r\n",
      "six                       1.15.0             pyhd3eb1b0_0    defaults\r\n",
      "snappy                    1.1.8                he6710b0_0    defaults\r\n",
      "sqlite                    3.35.4               hdfb4753_0    defaults\r\n",
      "tensorboardX              2.2                       <pip>\r\n",
      "terminado                 0.9.4            py36h06a4308_0    defaults\r\n",
      "testpath                  0.4.4              pyhd3eb1b0_0    defaults\r\n",
      "tifffile                  2020.9.3                  <pip>\r\n",
      "tifffile                  2021.3.31          pyhd3eb1b0_1    defaults\r\n",
      "tk                        8.6.10               hbc83047_0    defaults\r\n",
      "toolz                     0.11.1             pyhd3eb1b0_0    defaults\r\n",
      "torchvision               0.3.0           py36_cu9.0.176_1    pytorch\r\n",
      "tornado                   6.1              py36h27cfd23_0    defaults\r\n",
      "tqdm                      4.60.0                    <pip>\r\n",
      "traitlets                 4.3.3                    py36_0    defaults\r\n",
      "typing_extensions         3.7.4.3            pyha847dfd_0    defaults\r\n",
      "wcwidth                   0.2.5                      py_0    defaults\r\n",
      "webencodings              0.5.1                    py36_1    defaults\r\n",
      "wheel                     0.36.2             pyhd3eb1b0_0    defaults\r\n",
      "widgetsnbextension        3.5.1                    py36_0    defaults\r\n",
      "xz                        5.2.5                h7b6447c_0    defaults\r\n",
      "yacs                      0.1.8                     <pip>\r\n",
      "yaml                      0.2.5                h7b6447c_0    defaults\r\n",
      "zeromq                    4.3.4                h2531618_0    defaults\r\n",
      "zipp                      3.4.1              pyhd3eb1b0_0    defaults\r\n",
      "zlib                      1.2.11               h7b6447c_3    defaults\r\n",
      "zstd                      1.4.9                haebb681_0    defaults\r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to load predicted mask for hard-disk and calculate Segmentation evaluation metics.\n",
    "predicted mask is the output of ScaleNASv2 Test and save predicted mask.ipynb\n",
    "\n",
    "cp -v /mnt/fast-data/mjc/AutoRECIST/Codes/ScaleNAS/ScaleNASv1/tools/utils_test.py .\n",
    "\n",
    "gt box are loaded from /cache/*gt_roidb.pkl\n",
    "gt segmentation are loaded from Hao's Raw files\n",
    "\n",
    "predictions are all_boxes and all_segms which both are loaded from mask_1988 png files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # This file is for segmetation metrics evaluation in 3D\n",
    "# Edited by Jingchen around 06/20/2021\n",
    "# This file is after ScaleNAS test which save predition into png images.\n",
    "# This file load png images as predicted contours in 2D\n",
    "# load cache pkl as gold-standard contours in 2D\n",
    "# The stack 2D based on dicom-header to get 3D\n",
    "# Evaluate 3D metics of dice, IoU, over-segmetation, and under-segmetation\n",
    "# \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import _init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from utils_test import *\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from utils.utils import get_confusion_matrix\n",
    "def convert_name(name):\n",
    "    new = name.replace('/','_')\n",
    "    return new\n",
    "\n",
    "def get_palette(n):\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "    \n",
    "# def save_pred(preds, sv_path, name):\n",
    "\n",
    "#     preds = preds.cpu().numpy().copy()\n",
    "#     preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         cv2.imwrite(os.path.join(sv_path, convert_name(name[i])) , preds[i])\n",
    "\n",
    "        \n",
    "def save_pred( preds, sv_path, name):\n",
    "    palette = get_palette(256)\n",
    "    preds = preds.cpu().numpy().copy()\n",
    "    preds = np.asarray(np.argmax(preds, axis=1), dtype=np.uint8)\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i]\n",
    "        save_img = Image.fromarray(pred)\n",
    "        save_img.putpalette(palette)\n",
    "        save_img.save(os.path.join(sv_path, convert_name(name[i]) ))\n",
    "        \n",
    "\n",
    "def testval_lesion(config, test_dataset, testloader, model,\n",
    "            sv_dir='', sv_pred=True, device = None):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(testloader):\n",
    "            image, label, _, batchname = batch\n",
    "            size = label.size()\n",
    "            if device is None:\n",
    "                image = image.cuda()\n",
    "                label = label.long().cuda()\n",
    "            else:\n",
    "                image = image.to(device)\n",
    "                label = label.long().to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.upsample(pred, (size[-2], size[-1]),\n",
    "                                  mode='bilinear')\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                save_pred(pred, sv_path, batchname)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d images' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum() / pos.sum()\n",
    "    mean_acc = (tp / np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached gt_roidb from %s ./cache/inference_gt_roidb.pkl\n",
      "======================================== 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "site_list = [2,4,6,8,9,10,11,14,17] \n",
    "\n",
    "cache_path = './cache/'\n",
    "name = 'inference'\n",
    "# name = 'lesion_train'\n",
    "\n",
    "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\n",
    "print('Loading cached gt_roidb from %s', cache_filepath)\n",
    "with open(cache_filepath, 'rb') as fp:\n",
    "    cached_roidb = pickle.load(fp)\n",
    "    \n",
    "roidb = cached_roidb\n",
    "\n",
    "\n",
    "from utils_test import __get_annotation__\n",
    "\n",
    "sv_dir = mask_name = 'mask_1988'\n",
    "sv_path = os.path.join(sv_dir, 'test_val_results')\n",
    "\n",
    "all_boxes = [ [ np.zeros((0,5),dtype=\"float32\") for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "all_segms = [ [ [] for _ in range(len(roidb)) ] for _ in range( cfg.DATASET.NUM_CLASSES) ]\n",
    "\n",
    "for i in range(len(roidb)):\n",
    "    if i%500==0:\n",
    "        print('='*40,i)\n",
    "\n",
    "    one = roidb[i]\n",
    "    onename = one['image']\n",
    "    if not os.path.exists( os.path.join( sv_path, convert_name(onename) ) ):\n",
    "        print(os.path.join(sv_path, convert_name(onename) ) , 'not exists!')\n",
    "    pred_im = Image.open(os.path.join( sv_path, convert_name(onename) ))\n",
    "    pred = np.array(pred_im)\n",
    "    for j in range(cfg.DATASET.NUM_CLASSES):\n",
    "        mask = np.asarray( pred==j , dtype=np.uint8)\n",
    "        if np.sum(mask > 0) <= 3 :\n",
    "            continue\n",
    "        segmentation, bbox, area = __get_annotation__(mask , xywh = False , bbox_score=True)\n",
    "        if segmentation and bbox:\n",
    "            all_segms[j][i] = segmentation\n",
    "            all_boxes[j][i] = bbox\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_CT = {}\n",
    "for i , aroidb in enumerate(roidb):\n",
    "    dicom_path , png_name = os.path.split(aroidb['image'])\n",
    "    slice_no , _= os.path.splitext(png_name)\n",
    "    slice_no = int(slice_no)\n",
    "    if slice_no != aroidb['slice_no']:\n",
    "        print('following slice numbers are not consistence.')\n",
    "        print(dicom_path,slice_no,aroidb['slice_no'])\n",
    "\n",
    "    segmentations = {}\n",
    "    bboxes = {}\n",
    "    for j in site_list:\n",
    "        segmentations[j] = all_segms[j][i]\n",
    "        bboxes[j] = all_boxes[j][i]\n",
    "\n",
    "    if dicom_path not in D_CT:\n",
    "        D_CT[dicom_path] = {}\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\n",
    "    else:\n",
    "        D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0006/D2018_12_11/E8314/CT/S0002_5268\n",
      "/mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0028/D2019_07_12/E6851/CT/S0006_8606\n",
      "/mnt/fast-disk1/mjc/AutoRecist/Pngs/PDS_AUTO_RECIST/METNET0195/D2019_04_08/E6219/CT/S0003_8373\n"
     ]
    }
   ],
   "source": [
    "SHOW_LABEL = True\n",
    "SHOW_BOX = False\n",
    "SHOW_MASK = True\n",
    "SHOW_UNION_MASK= False\n",
    "SHOW_MASK_LABEL = True\n",
    "SHOW_GT_MASK = False\n",
    "from utils_metrics_3d import *\n",
    "\n",
    "\n",
    "def get_proper_CT_windowing(segmentations):\n",
    "\n",
    "    if 8 in segmentations and segmentations[8] :\n",
    "        return -160 , 240\n",
    "    if 7 in segmentations and segmentations[7] :\n",
    "        return -160 , 240    \n",
    "    if 9 in segmentations and segmentations[9] :\n",
    "        return -1250 , 250\n",
    "    return None\n",
    "\n",
    "keys = list(D_CT.keys())\n",
    "\n",
    "for k in keys:\n",
    "    \n",
    "    oneCT = remove_single_slice_segms(D_CT[k])\n",
    "    savepath = '/mnt/fast-disk1/demo/%s/CTs_%s_allsites/%s'%(mask_name,name,convert_name_compact(k))\n",
    "    if not os.path.exists(savepath):\n",
    "        os.makedirs(savepath)\n",
    "    \n",
    "    for s in oneCT:\n",
    "        aroidb , bboxes , segmentations = oneCT[s]\n",
    "\n",
    "        image_path = os.path.join(aroidb['image'])\n",
    "    \n",
    "        CT_windowing = get_proper_CT_windowing(segmentations)\n",
    "        if CT_windowing:\n",
    "            HU1, HU2 = CT_windowing\n",
    "        else:\n",
    "            [HU1, HU2 ] = aroidb['windows']\n",
    "            \n",
    "\n",
    "        image = load_image(image_path, HU1, HU2)\n",
    "        height,width = image.shape\n",
    "    #     plt.imshow(image)\n",
    "        image = np.dstack((image,image,image))\n",
    "        \n",
    "        if SHOW_MASK:\n",
    "            for j in site_list:\n",
    "                contours = segmentations[j]\n",
    "                colors = compute_colors_for_labels(j)\n",
    "                label = ix2labelname(j)\n",
    "                for c in contours:\n",
    "                    c = np.reshape(c,(-1,2))\n",
    "                    if c.shape[0]:\n",
    "                        image = cv2.drawContours(image, [np.int64( c  )], -1, colors, 1)\n",
    "                        if SHOW_MASK_LABEL:\n",
    "                            x,y,_,_ =ploy2boxes(c)\n",
    "                            template = \"{}\"\n",
    "                            if len(label)>=9:\n",
    "                                label=label[:3]+label[-3:]\n",
    "                \n",
    "                            s = template.format(label)\n",
    "                            cv2.putText(\n",
    "                                image, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, .5, colors, 1\n",
    "                            )  \n",
    "        \n",
    "\n",
    "        cv2.imwrite( os.path.join(savepath, convert_name_compact( aroidb['image'] ) ) , image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd  /Users/jingchen/OneDrive/OneDrive - cumc.columbia.edu/AutoRECIST/ImageResults/ScaleNAS_Q5/mask_1514/\n",
    "rsync -avzh --progress jm4669@radio-gpu.cpmc.columbia.edu:/mnt/fast-disk1/mjc/AutoRecist/Outputs/ScaleNAS_Q5/mask_1514/Images_Cougar302_80pts_test_allsites . \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "case = 1668\n",
    "pname = 'BAILN'\n",
    "for aroidb in roidb:\n",
    "    if pname in aroidb['image']:\n",
    "        print(aroidb['id'])\n",
    "\n",
    "convert_name( aroidb['image'] )\n",
    "\n",
    "aroidb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_lesions)",
   "language": "python",
   "name": "conda_lesions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

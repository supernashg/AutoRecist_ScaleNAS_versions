{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an Excel spreadsheet of CT file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CT_EXCEL_FILE = '/mnt/fast-disk1/demo/Demo_inference.xlsx'\n",
    "CT_EXCEL_FILE = '/mnt/fast-data/mjc/AutoRECIST/Inputs/AutoRECIST_Evaluation_Image_And_Contour_20221013.xlsx'\n",
    "SAVE_PATH = '/mnt/fast-disk1/demo/'\n",
    "\n",
    "import pandas as pd\n",
    "df_all = pd.read_excel(CT_EXCEL_FILE)\n",
    "\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pd_str_replace(df , col, ori, new):\n",
    "    if isinstance(col , str):\n",
    "        df[col] = df[col].str.replace(ori,new, case = False) \n",
    "    elif isinstance(col, list):\n",
    "        for one in col:\n",
    "            pd_str_replace(df , one, ori, new)\n",
    "    else:\n",
    "        raise('col instance should be str or list')\n",
    "\n",
    "df = df_all\n",
    "pd_str_replace(df, ['Image File Path' ], \"X:\" , \"/mnt/X-drive\")\n",
    "pd_str_replace(df, ['Image File Path' ], r\"\\\\\" , \"/\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials/FNIH_VOLPACK\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "pd_str_replace(df, ['Image File Path'], \"/mnt/X-drive/ClinicalTrials\", \"/mnt/fast-disk1/mjc/AutoRecist/Inputs\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i Demo_Read_CT.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI model analyze the CT images to segment cancer lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘./cache/inference_gt_roidb.pkl’: No such file or directory\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_init_paths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/mnt/fast-disk1/mjc/AutoRecist/Codes/ScaleNAS_Q5/release/Demo_AI_inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m_init_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_init_paths'"
     ]
    }
   ],
   "source": [
    "%run -i Demo_AI_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the AI results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i Demo_Save_Raw_To_Weasis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def boxes_segms_to_CTs(all_boxes,all_segms):\r\n",
      "    D_CT = {}\r\n",
      "    for i , aroidb in enumerate(roidb):\r\n",
      "        dicom_path , png_name = os.path.split(aroidb['image'])\r\n",
      "        slice_no , _= os.path.splitext(png_name)\r\n",
      "        slice_no = int(slice_no)\r\n",
      "        if slice_no != aroidb['slice_no']:\r\n",
      "            print('following slice numbers are not consistence.')\r\n",
      "            print(dicom_path,slice_no,aroidb['slice_no'])\r\n",
      "\r\n",
      "        segmentations = {}\r\n",
      "        bboxes = {}\r\n",
      "        for j in site_list:\r\n",
      "            segmentations[j] = all_segms[j][i]\r\n",
      "            bboxes[j] = all_boxes[j][i]\r\n",
      "\r\n",
      "        if dicom_path not in D_CT:\r\n",
      "            D_CT[dicom_path] = {}\r\n",
      "            D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\r\n",
      "        else:\r\n",
      "            D_CT[dicom_path][slice_no] = [aroidb , bboxes , segmentations]\r\n",
      "    return D_CT\r\n",
      "\r\n",
      "\r\n",
      "site_list_liver_lung_LNs = [2,4,6,8,9,10,11,14,17] \r\n",
      "site_list_LNs = [2,4,6,10,11,14,17] \r\n",
      "\r\n",
      "site_list = [8]\r\n",
      "user_id = 'jm4669'\r\n",
      "\r\n",
      "cache_path = './cache/'\r\n",
      "name = 'inference'\r\n",
      "sv_dir = mask_name\r\n",
      "sv_path = os.path.join(sv_dir, 'test_val_results')\r\n",
      "\r\n",
      "SAVE_PATH = '/mnt/fast-disk1/refine_gt/'\r\n",
      "SAVE_NAME = 'ScaleNAS3Slices_525pts'\r\n",
      "\r\n",
      "cache_filepath = os.path.join(cache_path, name+'_gt_roidb.pkl')\r\n",
      "print('Loading cached gt_roidb from %s', cache_filepath)\r\n",
      "with open(cache_filepath, 'rb') as fp:\r\n",
      "    roidb = pickle.load(fp)\r\n",
      "    \r\n",
      "\r\n",
      "all_boxes, all_segms = saved_png_to_boxes_segms(roidb , sv_dir , cfg.DATASET.NUM_CLASSES)\r\n",
      "D_CT = boxes_segms_to_CTs(all_boxes, all_segms)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Metrics_vol = []\r\n",
      "keys = list(D_CT.keys())\r\n",
      "for k in keys:\r\n",
      "\r\n",
      "    image_series_path = k.replace('/Pngs/' , '/Inputs/')    \r\n",
      "\r\n",
      "    df_image = get_dicom_header_df( image_series_path )\r\n",
      "    instanceNumber_list = df_image.index.to_list()\r\n",
      "    D_z_index = instanceNumber2Matrix_z_index(instanceNumber_list)\r\n",
      "\r\n",
      "\r\n",
      "    oneCT = remove_single_slice_segms(D_CT[k])\r\n",
      "    vol_pred = get_pred_vol(oneCT , site_list , D_z_index, union_mask = False)\r\n",
      "    \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "    image_series = wr.dicom_header(image_series_path)\r\n",
      "    if len(image_series):\r\n",
      "        height = image_series[0].Rows \r\n",
      "        width = image_series[0].Columns \r\n",
      "    else:\r\n",
      "        print('ERROR image_series has no len' , image_series_path)\r\n",
      "    assert(len(image_series) == vol_pred.shape[0])\r\n",
      "\r\n",
      "    vol2 = vol_pred\r\n",
      "    vol2[vol2>1]=1\r\n",
      "    vol_dict = seperate_vol(vol2)\r\n",
      "    \r\n",
      "    for tumor_index in vol_dict:\r\n",
      "        mask_volume = vol_dict[tumor_index]\r\n",
      "        weasis_raw_data = wr.create(image_series, mask_volume)\r\n",
      "\r\n",
      "        file_folder = os.path.join(SAVE_PATH , SAVE_NAME)\r\n",
      "        if not os.path.exists(file_folder):\r\n",
      "            os.makedirs(file_folder)\r\n",
      "        file_name = wr.unique(image_series, tumor_index, user_id)\r\n",
      "        file_name = os.path.join(file_folder,file_name)\r\n",
      "        wr.write(weasis_raw_data, file_name)\r\n",
      "\r\n",
      "        Metrics_vol.append( [image_series_path , file_name , user_id ])\r\n",
      "\r\n",
      "    print('finished of ', k )\r\n",
      "\r\n",
      "\r\n",
      "df_metrics = pd.DataFrame(Metrics_vol, \r\n",
      "                          columns = ['Image File Path','Contour File Path','Uni']) \r\n",
      "df_metrics.to_csv('%s.csv'%SAVE_NAME , index=False)\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 100 Demo_Save_Raw_To_Weasis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "whos -type str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_scalenas)",
   "language": "python",
   "name": "conda_scalenas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
